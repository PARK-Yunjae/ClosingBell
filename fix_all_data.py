"""
ClosingBell ë°ì´í„° ìˆ˜ì • í†µí•© ìŠ¤í¬ë¦½íŠ¸
======================================

1. ì˜¤ëŠ˜ì ìœ ëª©ë¯¼ í›„ë³´ ì¬ìˆ˜ì§‘ (ê¸°ì¡´ 10ê°œ â†’ 40ê°œ+)
2. TOP5 ì—…ì¢… ë°ì´í„° ë°±í•„ (2026-01-27 ì´ì „)
3. news_count ë™ê¸°í™”

ì‹¤í–‰:
    python fix_all_data.py
"""

import sqlite3
import logging
from pathlib import Path
from datetime import date
import pandas as pd

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
)
logger = logging.getLogger(__name__)

# ê²½ë¡œ ì„¤ì •
DB_PATH = Path(__file__).parent / 'data' / 'screener.db'
OHLCV_DIR = Path("C:/Coding/data/ohlcv")
STOCK_MAPPING_PATH = Path("C:/Coding/data/stock_mapping.csv")

# ìƒìˆ˜
LIMIT_UP_THRESHOLD = 29.5
VOLUME_EXPLOSION_THRESHOLD = 10_000_000

EXCLUDE_PATTERNS = [
    'KODEX', 'TIGER', 'KBSTAR', 'ARIRANG', 'HANARO',
    'SOL', 'KOSEF', 'KINDEX', 'SMART', 'ACE', 'TIMEFOLIO',
    'ETF', 'ETN', 'ì¸ë²„ìŠ¤', 'ë ˆë²„ë¦¬ì§€', 'ì„ ë¬¼', 'ìŠ¤íŒ©',
]


def load_stock_mapping():
    """ì¢…ëª© ë§¤í•‘ ë¡œë“œ"""
    mapping = {}
    sector_mapping = {}
    
    if STOCK_MAPPING_PATH.exists():
        try:
            df = pd.read_csv(STOCK_MAPPING_PATH, dtype={'code': str})
            for _, row in df.iterrows():
                code = str(row['code']).zfill(6)
                mapping[code] = row.get('name', code)
                if 'sector' in df.columns:
                    sector_mapping[code] = row.get('sector', '')
        except Exception as e:
            logger.warning(f"stock_mapping.csv ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return mapping, sector_mapping


def fix_nomad_candidates_today():
    """ì˜¤ëŠ˜ì ìœ ëª©ë¯¼ í›„ë³´ ì¬ìˆ˜ì§‘ - ì´ë¯¸ ìˆìœ¼ë©´ ìŠ¤í‚µ"""
    logger.info("=" * 60)
    logger.info("ğŸ“š ì˜¤ëŠ˜ì ìœ ëª©ë¯¼ í›„ë³´ í™•ì¸")
    logger.info("=" * 60)
    
    today_str = date.today().isoformat()
    
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # 1. ê¸°ì¡´ ë°ì´í„° ê°œìˆ˜ í™•ì¸
    cursor.execute("SELECT COUNT(*) as cnt FROM nomad_candidates WHERE study_date = ?", (today_str,))
    existing = cursor.fetchone()['cnt']
    
    # ì´ë¯¸ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
    if existing >= 30:
        logger.info(f"ì˜¤ëŠ˜({today_str}) ì´ë¯¸ {existing}ê°œ ìˆìŒ â†’ ìŠ¤í‚µ")
        logger.info(f"ì¬ìˆ˜ì§‘í•˜ë ¤ë©´: python main.py --run-nomad --force")
        conn.close()
        return {'old': existing, 'new': existing, 'skipped': True}
    
    # ë°ì´í„°ê°€ ì ìœ¼ë©´ ì‚­ì œ í›„ ì¬ìˆ˜ì§‘
    if existing > 0:
        logger.info(f"ê¸°ì¡´ {today_str} ë°ì´í„°: {existing}ê°œ (ë¶€ì¡±) â†’ ì‚­ì œ í›„ ì¬ìˆ˜ì§‘")
        cursor.execute("DELETE FROM nomad_candidates WHERE study_date = ?", (today_str,))
        cursor.execute("DELETE FROM nomad_news WHERE study_date = ?", (today_str,))
        conn.commit()
        logger.info(f"ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
    else:
        logger.info(f"ì˜¤ëŠ˜({today_str}) ë°ì´í„° ì—†ìŒ â†’ ìˆ˜ì§‘")
    
    # 2. ì¢…ëª© ë§¤í•‘ ë¡œë“œ
    stock_mapping, sector_mapping = load_stock_mapping()
    logger.info(f"ì¢…ëª© ë§¤í•‘: {len(stock_mapping)}ê°œ")
    
    # 4. OHLCV í´ë” ìŠ¤ìº”
    if not OHLCV_DIR.exists():
        logger.error(f"OHLCV í´ë” ì—†ìŒ: {OHLCV_DIR}")
        conn.close()
        return {'old': existing, 'new': 0}
    
    csv_files = list(OHLCV_DIR.glob("*.csv"))
    logger.info(f"CSV íŒŒì¼: {len(csv_files)}ê°œ ìŠ¤ìº”")
    
    candidates = []
    limit_up_count = 0
    volume_count = 0
    
    for csv_file in csv_files:
        try:
            stock_code = csv_file.stem
            stock_name = stock_mapping.get(stock_code, stock_code)
            
            # ETF ì œì™¸
            skip = False
            for pattern in EXCLUDE_PATTERNS:
                if pattern.lower() in stock_name.lower():
                    skip = True
                    break
            if skip:
                continue
            
            # CSV ì½ê¸°
            df = pd.read_csv(csv_file)
            df.columns = df.columns.str.lower()
            
            if 'date' not in df.columns:
                if 'unnamed: 0' in df.columns:
                    df = df.rename(columns={'unnamed: 0': 'date'})
                else:
                    continue
            
            df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
            today_df = df[df['date'] == today_str]
            
            if today_df.empty:
                continue
            
            today_row = today_df.iloc[-1]
            volume = int(today_row.get('volume', 0))
            close = int(today_row.get('close', 0))
            
            # ì „ì¼ ë°ì´í„°
            prev_df = df[df['date'] < today_str]
            if prev_df.empty:
                continue
            
            prev_row = prev_df.iloc[-1]
            prev_close = int(prev_row.get('close', 0))
            
            if prev_close == 0:
                continue
            
            change_rate = ((close - prev_close) / prev_close) * 100
            trading_value = (close * volume) / 100_000_000
            
            is_limit_up = change_rate >= LIMIT_UP_THRESHOLD
            is_volume_explosion = volume >= VOLUME_EXPLOSION_THRESHOLD
            
            if not (is_limit_up or is_volume_explosion):
                continue
            
            if is_limit_up and is_volume_explosion:
                reason = 'ìƒí•œê°€+ê±°ë˜ëŸ‰'
            elif is_limit_up:
                reason = 'ìƒí•œê°€'
            else:
                reason = 'ê±°ë˜ëŸ‰ì²œë§Œ'
            
            candidates.append({
                'study_date': today_str,
                'stock_code': stock_code,
                'stock_name': stock_name,
                'reason_flag': reason,
                'close_price': close,
                'change_rate': round(change_rate, 2),
                'volume': volume,
                'trading_value': round(trading_value, 2),
                'sector': sector_mapping.get(stock_code, ''),
                'data_source': 'fix_script',
            })
            
            if is_limit_up:
                limit_up_count += 1
            if is_volume_explosion:
                volume_count += 1
                
        except Exception as e:
            continue
    
    # 5. DB ì €ì¥
    saved = 0
    for c in candidates:
        try:
            cursor.execute("""
                INSERT INTO nomad_candidates 
                (study_date, stock_code, stock_name, reason_flag, close_price, change_rate, volume, trading_value, sector, data_source)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (c['study_date'], c['stock_code'], c['stock_name'], c['reason_flag'], 
                  c['close_price'], c['change_rate'], c['volume'], c['trading_value'], 
                  c['sector'], c['data_source']))
            saved += 1
        except Exception as e:
            pass
    
    conn.commit()
    conn.close()
    
    logger.info(f"âœ… ì¬ìˆ˜ì§‘ ì™„ë£Œ: ìƒí•œê°€ {limit_up_count}, ê±°ë˜ëŸ‰ì²œë§Œ {volume_count}, ì´ {saved}ê°œ ì €ì¥")
    
    return {'old': existing, 'new': saved, 'limit_up': limit_up_count, 'volume': volume_count}


def fix_top5_sectors():
    """TOP5 ì—…ì¢… ë°ì´í„° ë°±í•„"""
    logger.info("=" * 60)
    logger.info("ğŸ“Š TOP5 ì—…ì¢… ë°ì´í„° ë°±í•„")
    logger.info("=" * 60)
    
    _, sector_mapping = load_stock_mapping()
    logger.info(f"ì—…ì¢… ë§¤í•‘: {len(sector_mapping)}ê°œ")
    
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # ì—…ì¢…ì´ ì—†ëŠ” TOP5 ì¡°íšŒ
    cursor.execute("""
        SELECT id, stock_code, stock_name, screen_date
        FROM closing_top5_history
        WHERE sector IS NULL OR sector = ''
    """)
    missing_sectors = cursor.fetchall()
    
    logger.info(f"ì—…ì¢… ëˆ„ë½: {len(missing_sectors)}ê°œ")
    
    updated = 0
    for row in missing_sectors:
        sector = sector_mapping.get(row['stock_code'], '')
        if sector:
            cursor.execute("""
                UPDATE closing_top5_history
                SET sector = ?
                WHERE id = ?
            """, (sector, row['id']))
            updated += 1
    
    conn.commit()
    
    # ê²°ê³¼ í™•ì¸
    cursor.execute("""
        SELECT COUNT(*) as cnt FROM closing_top5_history WHERE sector IS NULL OR sector = ''
    """)
    still_missing = cursor.fetchone()['cnt']
    
    conn.close()
    
    logger.info(f"âœ… ì—…ì¢… ë°±í•„ ì™„ë£Œ: {updated}ê°œ ì—…ë°ì´íŠ¸, {still_missing}ê°œ ì—¬ì „íˆ ëˆ„ë½")
    
    return {'updated': updated, 'still_missing': still_missing}


def fix_news_count():
    """news_count ë™ê¸°í™”"""
    logger.info("=" * 60)
    logger.info("ğŸ“° news_count ë™ê¸°í™”")
    logger.info("=" * 60)
    
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # nomad_newsì—ì„œ ì‹¤ì œ ê°œìˆ˜ ì¡°íšŒ
    cursor.execute("""
        SELECT study_date, stock_code, COUNT(*) as cnt
        FROM nomad_news
        GROUP BY study_date, stock_code
    """)
    news_counts = {(r['study_date'], r['stock_code']): r['cnt'] for r in cursor.fetchall()}
    
    # nomad_candidates ì—…ë°ì´íŠ¸
    cursor.execute("SELECT id, study_date, stock_code FROM nomad_candidates")
    candidates = cursor.fetchall()
    
    updated = 0
    for c in candidates:
        key = (c['study_date'], c['stock_code'])
        count = news_counts.get(key, 0)
        
        if count > 0:
            cursor.execute("""
                UPDATE nomad_candidates 
                SET news_count = ?, news_status = 'collected'
                WHERE id = ?
            """, (count, c['id']))
            updated += 1
    
    conn.commit()
    conn.close()
    
    logger.info(f"âœ… news_count ë™ê¸°í™” ì™„ë£Œ: {updated}ê°œ ì—…ë°ì´íŠ¸")
    
    return {'updated': updated}


def verify_all():
    """ì „ì²´ ë°ì´í„° ê²€ì¦"""
    logger.info("=" * 60)
    logger.info("ğŸ” ì „ì²´ ë°ì´í„° ê²€ì¦")
    logger.info("=" * 60)
    
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # ìœ ëª©ë¯¼ í›„ë³´ ë‚ ì§œë³„ ì¹´ìš´íŠ¸
    cursor.execute("""
        SELECT study_date, COUNT(*) as cnt
        FROM nomad_candidates
        GROUP BY study_date
        ORDER BY study_date DESC
        LIMIT 7
    """)
    nomad_stats = cursor.fetchall()
    
    print("\nğŸ“š ìœ ëª©ë¯¼ í›„ë³´ (ìµœê·¼ 7ì¼):")
    for r in nomad_stats:
        print(f"  {r['study_date']} | {r['cnt']}ê°œ")
    
    # TOP5 ì—…ì¢… ìƒíƒœ
    cursor.execute("""
        SELECT 
            COUNT(*) as total,
            SUM(CASE WHEN sector IS NOT NULL AND sector != '' THEN 1 ELSE 0 END) as with_sector
        FROM closing_top5_history
    """)
    top5_stats = cursor.fetchone()
    
    print(f"\nğŸ“Š TOP5 ì—…ì¢… ìƒíƒœ:")
    print(f"  ì „ì²´: {top5_stats['total']}ê°œ")
    print(f"  ì—…ì¢… ìˆìŒ: {top5_stats['with_sector']}ê°œ")
    print(f"  ì—…ì¢… ì—†ìŒ: {top5_stats['total'] - top5_stats['with_sector']}ê°œ")
    
    # news_count ìƒíƒœ
    cursor.execute("""
        SELECT 
            COUNT(*) as total,
            SUM(CASE WHEN news_count > 0 THEN 1 ELSE 0 END) as with_news
        FROM nomad_candidates
    """)
    news_stats = cursor.fetchone()
    
    print(f"\nğŸ“° ë‰´ìŠ¤ ìƒíƒœ:")
    print(f"  ì „ì²´: {news_stats['total']}ê°œ")
    print(f"  ë‰´ìŠ¤ ìˆìŒ: {news_stats['with_news']}ê°œ")
    
    conn.close()
    
    return True


def main():
    print("=" * 60)
    print("ğŸ”§ ClosingBell ë°ì´í„° ìˆ˜ì • ì‹œì‘")
    print("=" * 60)
    
    # 1. ì˜¤ëŠ˜ì ìœ ëª©ë¯¼ ì¬ìˆ˜ì§‘
    nomad_result = fix_nomad_candidates_today()
    
    # 2. TOP5 ì—…ì¢… ë°±í•„
    sector_result = fix_top5_sectors()
    
    # 3. news_count ë™ê¸°í™”
    news_result = fix_news_count()
    
    # 4. ê²€ì¦
    verify_all()
    
    print("\n" + "=" * 60)
    print("âœ… ëª¨ë“  ìˆ˜ì • ì™„ë£Œ!")
    print("=" * 60)
    print(f"ìœ ëª©ë¯¼ ì¬ìˆ˜ì§‘: {nomad_result['old']}ê°œ â†’ {nomad_result['new']}ê°œ")
    print(f"TOP5 ì—…ì¢… ë°±í•„: {sector_result['updated']}ê°œ ì—…ë°ì´íŠ¸")
    print(f"news_count ë™ê¸°í™”: {news_result['updated']}ê°œ ì—…ë°ì´íŠ¸")


if __name__ == "__main__":
    main()
