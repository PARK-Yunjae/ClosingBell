#!/usr/bin/env python3
"""
=============================================================================
ìœ ëª©ë¯¼ ë°±í…ŒìŠ¤íŠ¸ v3.0 - Professional Grade
=============================================================================

ğŸ“š ìœ ëª©ë¯¼ 1ê¶Œ ê¸°ë°˜ ì¢…í•© ë°±í…ŒìŠ¤íŒ… ì‹œìŠ¤í…œ

[í•µì‹¬ 3ì¶•]
1. ì§€ì§€/ì €í•­ (ê°€ê²© ë ˆë²¨)
2. ê±°ë˜ëŸ‰ (í­ì¦/ê¸‰ê°)
3. ì´ë™í‰ê· ì„  (3/7/8/15/20/33/45/120/360ì¼)

[êµ¬í˜„ ì „ëµ]
- S1: ê±°ë˜ëŸ‰ ê¸‰ê° + ìŒë´‰ + MA5 ê·¼ì ‘
- S2: ê±°ë˜ëŸ‰ í­ì¦ â†’ ê¸‰ê° + MA5 ê·¼ì ‘ (ê±°ê°ìŒë´‰)
- S3: ê¸‰ë“± ì´ë ¥ + 3ì¼ì„  ì§€ì§€
- S4: 7/8ì¼ì„  ëˆŒë¦¼ëª© (í„°ì¹˜í˜•/ì´ê²©í˜•)
- S5: 45ì¼ì„  ë‚™ì£¼ë§¤ë§¤ (ì²« í„°ì¹˜ + ê±°ë˜ëŸ‰ ê°ì†Œ)
- S6: 33ì¼ì„  ì •ì°°ë³‘ â†’ 45ì¼ì„  ë³¸ì§„ì…
- S7: 360ì¼ì„  ê¸‰ë½ë°˜ë“±

[ë¶„ì„ ê¸°ëŠ¥]
- D+1 ~ D+20 ìˆ˜ìµë¥ /ìŠ¹ë¥ 
- ì†ì ˆ/ìµì ˆ ì‹œë®¬ë ˆì´ì…˜
- ìˆ˜ìˆ˜ë£Œ/ì„¸ê¸ˆ ë°˜ì˜
- ì†ìµë¹„/MDD ê³„ì‚°
- ì›”ë³„/ë¶„ê¸°ë³„/ìš”ì¼ë³„ ì‹œì¦Œì„± ë¶„ì„
- ê¸°ê°„ ë¶„í•  ê²€ì¦ (In-Sample / Out-of-Sample)
- ë©€í‹°ì½”ì–´ ë³‘ë ¬ ì²˜ë¦¬

Author: Claude (Anthropic)
Version: 3.0
Date: 2026-01-27
=============================================================================
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, field
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp
import warnings
import argparse
import time
from datetime import datetime

warnings.filterwarnings('ignore')

# =============================================================================
# ì„¤ì • (Configuration)
# =============================================================================

@dataclass
class BacktestConfig:
    """ë°±í…ŒìŠ¤íŠ¸ ì„¤ì •"""
    # ë°ì´í„° ê²½ë¡œ
    ohlcv_dir: Path = Path(r"C:\Coding\data\ohlcv")
    
    # ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„
    start_date: str = '2016-06-01'
    end_date: str = '2026-01-26'
    
    # ê¸°ê°„ ë¶„í•  ê²€ì¦
    split_date: str = '2022-01-01'  # In-Sample / Out-of-Sample êµ¬ë¶„
    
    # ì´ë™í‰ê· ì„  ê¸°ê°„
    ma_periods: List[int] = field(default_factory=lambda: [3, 5, 7, 8, 10, 15, 20, 33, 45, 60, 120, 360])
    
    # ìˆ˜ìµë¥  ê³„ì‚° ê¸°ê°„
    return_periods: List[int] = field(default_factory=lambda: [1, 2, 3, 5, 7, 10, 15, 20])
    
    # ê±°ë˜ ë¹„ìš©
    commission: float = 0.00015  # ë§¤ë§¤ ìˆ˜ìˆ˜ë£Œ (0.015% Ã— 2 = í¸ë„ 0.015%)
    tax: float = 0.0018  # ê±°ë˜ì„¸ (ì½”ìŠ¤í”¼ 0.18%, ì½”ìŠ¤ë‹¥ 0.18%)
    slippage: float = 0.001  # ìŠ¬ë¦¬í”¼ì§€ (0.1%)
    
    # ì†ì ˆ/ìµì ˆ
    stop_loss: float = -0.05  # -5% ì†ì ˆ
    take_profit: float = 0.10  # +10% ìµì ˆ
    
    # ë©€í‹°ì½”ì–´
    use_multicore: bool = True
    num_workers: int = field(default_factory=lambda: max(1, mp.cpu_count() - 2))
    
    # ê±°ë˜ëŸ‰ ê¸°ì¤€
    volume_10m: int = 10_000_000  # 1000ë§Œì£¼
    
    # ì›Œë°ì—… ê¸°ê°„ (360ì¼ì„ ìš©)
    warmup_days: int = 400


# ì „ì—­ ì„¤ì •
CONFIG = BacktestConfig()


# =============================================================================
# 1. ë°ì´í„° ë¡œë”© (ë©€í‹°ì½”ì–´ ì§€ì›)
# =============================================================================

def load_single_ohlcv(file_path: Path) -> Optional[pd.DataFrame]:
    """ë‹¨ì¼ ì¢…ëª© OHLCV ë¡œë“œ (CSV í˜•ì‹)"""
    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        
        # ì»¬ëŸ¼ ì •ê·œí™”
        df.columns = df.columns.str.lower()
        
        # ì»¬ëŸ¼ ë§¤í•‘ (í•œê¸€ â†’ ì˜ë¬¸)
        column_map = {
            'ë‚ ì§œ': 'date', 'ì¼ì': 'date',
            'ì‹œê°€': 'open',
            'ê³ ê°€': 'high',
            'ì €ê°€': 'low',
            'ì¢…ê°€': 'close',
            'ê±°ë˜ëŸ‰': 'volume',
            'ê±°ë˜ëŒ€ê¸ˆ': 'trading_value',
            'tradingvalue': 'trading_value',
        }
        df = df.rename(columns=column_map)
        
        required = ['date', 'open', 'high', 'low', 'close', 'volume']
        if not all(col in df.columns for col in required):
            return None
        
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').reset_index(drop=True)
        
        # ì¢…ëª©ì½”ë“œ ì¶”ì¶œ
        code = file_path.stem
        df['code'] = code
        
        # ê¸°ë³¸ ê²€ì¦
        if len(df) < CONFIG.warmup_days:
            return None
        
        return df
        
    except Exception as e:
        return None


def _load_worker(file_path: Path) -> Tuple[str, Optional[pd.DataFrame]]:
    """ë©€í‹°ì½”ì–´ìš© ì›Œì»¤ í•¨ìˆ˜"""
    df = load_single_ohlcv(file_path)
    code = file_path.stem
    return (code, df)


def load_all_ohlcv(
    ohlcv_dir: Path,
    start_date: str,
    end_date: str,
    use_multicore: bool = True,
    num_workers: int = None,
) -> Dict[str, pd.DataFrame]:
    """ì „ì²´ OHLCV ë°ì´í„° ë¡œë“œ (ë©€í‹°ì½”ì–´ ì§€ì›)"""
    
    ohlcv_dir = Path(ohlcv_dir)
    if not ohlcv_dir.exists():
        print(f"âŒ ê²½ë¡œ ì—†ìŒ: {ohlcv_dir}")
        return {}
    
    files = list(ohlcv_dir.glob("*.csv"))
    if not files:
        print(f"âŒ CSV íŒŒì¼ ì—†ìŒ: {ohlcv_dir}")
        return {}
    
    print(f"ğŸ“‚ ë°ì´í„° ë¡œë”©: {len(files)}ê°œ íŒŒì¼")
    
    start_dt = pd.to_datetime(start_date)
    end_dt = pd.to_datetime(end_date)
    
    ohlcv_data = {}
    
    if use_multicore and len(files) > 100:
        workers = num_workers or CONFIG.num_workers
        print(f"   ğŸš€ ë©€í‹°ì½”ì–´ ëª¨ë“œ: {workers} workers")
        
        with ProcessPoolExecutor(max_workers=workers) as executor:
            futures = {executor.submit(_load_worker, f): f for f in files}
            
            for i, future in enumerate(as_completed(futures)):
                if (i + 1) % 500 == 0:
                    print(f"   ì§„í–‰: {i+1}/{len(files)}")
                
                try:
                    code, df = future.result()
                    if df is not None:
                        # ê¸°ê°„ í•„í„°ë§
                        df = df[(df['date'] >= start_dt) & (df['date'] <= end_dt)]
                        if len(df) >= 60:  # ìµœì†Œ 60ì¼
                            ohlcv_data[code] = df
                except Exception:
                    continue
    else:
        print(f"   ğŸ“ ì‹±ê¸€ì½”ì–´ ëª¨ë“œ")
        for i, file_path in enumerate(files):
            if (i + 1) % 500 == 0:
                print(f"   ì§„í–‰: {i+1}/{len(files)}")
            
            df = load_single_ohlcv(file_path)
            if df is not None:
                df = df[(df['date'] >= start_dt) & (df['date'] <= end_dt)]
                if len(df) >= 60:
                    ohlcv_data[file_path.stem] = df
    
    print(f"âœ… ë¡œë“œ ì™„ë£Œ: {len(ohlcv_data)}ê°œ ì¢…ëª©")
    return ohlcv_data


# =============================================================================
# 2. ì§€í‘œ ê³„ì‚° (Indicators)
# =============================================================================

def calculate_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """
    ëª¨ë“  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    
    [ì´ë™í‰ê· ì„ ]
    - MA: 3, 5, 7, 8, 10, 15, 20, 33, 45, 60, 120, 360
    - MA ì´ê²©ë„: (close - ma) / ma
    - MA ê¸°ìš¸ê¸°: ma[t] - ma[t-1]
    
    [ê±°ë˜ëŸ‰]
    - vol_ratio_1d: ì „ì¼ ëŒ€ë¹„
    - vol_ratio_ma5: 5ì¼ í‰ê·  ëŒ€ë¹„
    - vol_ratio_ma20: 20ì¼ í‰ê·  ëŒ€ë¹„
    
    [ìº”ë“¤/ê°€ê²©]
    - is_bullish / is_bearish
    - change_rate: ì¼ê°„ ìˆ˜ìµë¥ 
    - volatility: (high - low) / close
    - body_ratio: ëª¸í†µ í¬ê¸°
    
    [ê¸‰ë“± ì´ë ¥]
    - had_surge_Nd: ìµœê·¼ Nì¼ ë‚´ 20%+ ê¸‰ë“±
    - had_limit_up_Nd: ìµœê·¼ Nì¼ ë‚´ ìƒí•œê°€(29%+)
    
    [ê°€ê²© ìœ„ì¹˜]
    - position_Nd: Nì¼ ì¤‘ í˜„ì¬ ìœ„ì¹˜ (0~100%)
    """
    df = df.copy()
    
    # =========================================================================
    # 2-1. ì´ë™í‰ê· ì„ 
    # =========================================================================
    for p in CONFIG.ma_periods:
        # MA ê°’
        df[f'ma{p}'] = df['close'].rolling(p, min_periods=p).mean()
        
        # ì´ê²©ë„ (ì–‘ìˆ˜: ìœ„, ìŒìˆ˜: ì•„ë˜)
        df[f'ma{p}_dist'] = (df['close'] - df[f'ma{p}']) / df[f'ma{p}']
        
        # ê¸°ìš¸ê¸° (ì¶”ì„¸ ê°•ë„)
        df[f'ma{p}_slope'] = df[f'ma{p}'] - df[f'ma{p}'].shift(1)
        df[f'ma{p}_slope_pct'] = df[f'ma{p}_slope'] / df[f'ma{p}'].shift(1)
    
    # =========================================================================
    # 2-2. í„°ì¹˜ íŒì • (low â‰¤ ma â‰¤ high)
    # =========================================================================
    for p in CONFIG.ma_periods:
        df[f'ma{p}_touch'] = (df['low'] <= df[f'ma{p}']) & (df[f'ma{p}'] <= df['high'])
    
    # =========================================================================
    # 2-3. ê±°ë˜ëŸ‰ ì§€í‘œ
    # =========================================================================
    df['vol_ratio_1d'] = df['volume'] / df['volume'].shift(1)
    df['vol_ma5'] = df['volume'].rolling(5).mean()
    df['vol_ma20'] = df['volume'].rolling(20).mean()
    df['vol_ratio_ma5'] = df['volume'] / df['vol_ma5']
    df['vol_ratio_ma20'] = df['volume'] / df['vol_ma20']
    
    # ì „ì¼ ê±°ë˜ëŸ‰ ë¹„ìœ¨ (í­ì¦ íŒë‹¨ìš©)
    df['vol_ratio_prev'] = df['vol_ratio_1d'].shift(1)
    df['volume_prev'] = df['volume'].shift(1)
    
    # =========================================================================
    # 2-4. ìº”ë“¤ & ê°€ê²© ì§€í‘œ
    # =========================================================================
    df['is_bullish'] = df['close'] > df['open']
    df['is_bearish'] = df['close'] < df['open']
    df['change_rate'] = df['close'].pct_change()
    df['change_rate_pct'] = df['change_rate'] * 100
    
    # ë³€ë™í­ (ë³€ë™ì„±)
    df['volatility'] = (df['high'] - df['low']) / df['close']
    
    # ëª¸í†µ í¬ê¸°
    df['body'] = abs(df['close'] - df['open'])
    df['body_ratio'] = df['body'] / df['close']
    
    # ìœ—ê¼¬ë¦¬ / ì•„ë«ê¼¬ë¦¬
    df['upper_shadow'] = df['high'] - df[['open', 'close']].max(axis=1)
    df['lower_shadow'] = df[['open', 'close']].min(axis=1) - df['low']
    
    # =========================================================================
    # 2-5. ê¸‰ë“± ì´ë ¥
    # =========================================================================
    for n in [5, 10, 20]:
        df[f'max_change_{n}d'] = df['change_rate'].rolling(n).max()
        df[f'had_surge_{n}d'] = df[f'max_change_{n}d'] >= 0.20  # 20%+
        df[f'had_limit_up_{n}d'] = df[f'max_change_{n}d'] >= 0.29  # ìƒí•œê°€
    
    # =========================================================================
    # 2-6. ê°€ê²© ìœ„ì¹˜ (Nì¼ ì¤‘ í˜„ì¬ ìœ„ì¹˜)
    # =========================================================================
    for n in [20, 60, 120]:
        high_n = df['high'].rolling(n).max()
        low_n = df['low'].rolling(n).min()
        df[f'position_{n}d'] = (df['close'] - low_n) / (high_n - low_n) * 100
    
    # =========================================================================
    # 2-7. 120ì¼ì„  ì˜¤ë²„í—¤ë“œ (45ì¼ì„  ë§¤ë§¤ìš©)
    # =========================================================================
    df['ma120_overhead'] = df['ma120'] > df['ma45']
    
    # =========================================================================
    # 2-8. ê±°ë˜ëŸ‰ 1000ë§Œ ì´ìƒ
    # =========================================================================
    df['vol_over_10m'] = df['volume'] >= CONFIG.volume_10m
    df['vol_prev_over_10m'] = df['volume_prev'] >= CONFIG.volume_10m
    
    return df


# =============================================================================
# 3. ìˆ˜ìµë¥  ê³„ì‚° (ì†ì ˆ/ìµì ˆ/ìˆ˜ìˆ˜ë£Œ ë°˜ì˜)
# =============================================================================

def calculate_returns(
    df: pd.DataFrame,
    include_costs: bool = True,
    include_stoploss: bool = False,
) -> pd.DataFrame:
    """
    ìˆ˜ìµë¥  ê³„ì‚°
    
    Parameters:
        include_costs: ìˆ˜ìˆ˜ë£Œ/ì„¸ê¸ˆ/ìŠ¬ë¦¬í”¼ì§€ ë°˜ì˜ ì—¬ë¶€
        include_stoploss: ì†ì ˆ/ìµì ˆ ì‹œë®¬ë ˆì´ì…˜ ì—¬ë¶€
    """
    df = df.copy()
    
    # ë¹„ìš© ê³„ì‚°
    total_cost = 0
    if include_costs:
        total_cost = CONFIG.commission * 2 + CONFIG.tax + CONFIG.slippage
    
    # =========================================================================
    # 3-1. ë‹¨ìˆœ ë³´ìœ  ìˆ˜ìµë¥  (D+1 ~ D+20)
    # =========================================================================
    for d in CONFIG.return_periods:
        # ë‹¹ì¼ ì¢…ê°€ ë§¤ìˆ˜ â†’ D+N ì¢…ê°€ ë§¤ë„
        raw_return = df['close'].shift(-d) / df['close'] - 1
        df[f'ret_D{d}'] = raw_return - total_cost
    
    # =========================================================================
    # 3-2. ì†ì ˆ/ìµì ˆ ì‹œë®¬ë ˆì´ì…˜
    # =========================================================================
    if include_stoploss:
        # ê° ë‚ ì§œë³„ í–¥í›„ 20ì¼ê°„ ê³ ê°€/ì €ê°€
        for i in range(1, 21):
            df[f'future_high_{i}'] = df['high'].shift(-i)
            df[f'future_low_{i}'] = df['low'].shift(-i)
            df[f'future_close_{i}'] = df['close'].shift(-i)
        
        # ì†ì ˆ/ìµì ˆ ë°œìƒì¼ ë° ìµœì¢… ìˆ˜ìµë¥  ê³„ì‚°
        def calc_stoploss_return(row):
            entry_price = row['close']
            
            for day in range(1, 21):
                high = row.get(f'future_high_{day}', np.nan)
                low = row.get(f'future_low_{day}', np.nan)
                close = row.get(f'future_close_{day}', np.nan)
                
                if pd.isna(high) or pd.isna(low):
                    break
                
                # ì¼ì¤‘ ì†ì ˆ/ìµì ˆ ì²´í¬
                low_return = (low - entry_price) / entry_price
                high_return = (high - entry_price) / entry_price
                
                # ì†ì ˆ ë¨¼ì € ì²´í¬ (ë³´ìˆ˜ì )
                if low_return <= CONFIG.stop_loss:
                    return CONFIG.stop_loss - total_cost, day, 'stop_loss'
                
                # ìµì ˆ ì²´í¬
                if high_return >= CONFIG.take_profit:
                    return CONFIG.take_profit - total_cost, day, 'take_profit'
            
            # 20ì¼ í›„ ì¢…ê°€ ì²­ì‚°
            final_close = row.get('future_close_20', np.nan)
            if pd.notna(final_close):
                final_return = (final_close - entry_price) / entry_price - total_cost
                return final_return, 20, 'hold'
            
            return np.nan, np.nan, 'na'
        
        # ì ìš© (ëŠë¦¬ë¯€ë¡œ ì‹œê·¸ë„ ë°œìƒ í–‰ì—ë§Œ ë‚˜ì¤‘ì— ì ìš©)
        # df[['ret_sl', 'exit_day', 'exit_type']] = df.apply(
        #     lambda row: pd.Series(calc_stoploss_return(row)), axis=1
        # )
        
        # ì„ì‹œ ì»¬ëŸ¼ ì •ë¦¬
        for i in range(1, 21):
            df.drop(columns=[f'future_high_{i}', f'future_low_{i}', f'future_close_{i}'], 
                   inplace=True, errors='ignore')
    
    return df


def calculate_stoploss_return_for_signals(signals_df: pd.DataFrame) -> pd.DataFrame:
    """
    ì‹œê·¸ë„ DataFrameì— ëŒ€í•´ ì†ì ˆ/ìµì ˆ ìˆ˜ìµë¥  ê³„ì‚°
    (ì „ì²´ ë°ì´í„°ê°€ ì•„ë‹Œ ì‹œê·¸ë„ì—ë§Œ ì ìš©í•˜ì—¬ ì†ë„ í–¥ìƒ)
    """
    if len(signals_df) == 0:
        return signals_df
    
    signals_df = signals_df.copy()
    
    total_cost = CONFIG.commission * 2 + CONFIG.tax + CONFIG.slippage
    
    results = []
    for idx, row in signals_df.iterrows():
        entry_price = row['close']
        exit_return = np.nan
        exit_day = np.nan
        exit_type = 'na'
        
        for day in range(1, 21):
            ret_col = f'ret_D{day}'
            if ret_col not in row.index:
                continue
            
            # ë‹¨ìˆœí™”: ret_D{day}ì—ì„œ ì—­ì‚°
            if pd.notna(row.get(ret_col)):
                day_return = row[ret_col] + total_cost  # ë¹„ìš© ì œì™¸í•œ ì›ë˜ ìˆ˜ìµë¥ 
                
                # ì†ì ˆ ì²´í¬
                if day_return <= CONFIG.stop_loss:
                    exit_return = CONFIG.stop_loss - total_cost
                    exit_day = day
                    exit_type = 'stop_loss'
                    break
                
                # ìµì ˆ ì²´í¬  
                if day_return >= CONFIG.take_profit:
                    exit_return = CONFIG.take_profit - total_cost
                    exit_day = day
                    exit_type = 'take_profit'
                    break
        
        # 20ì¼ ë³´ìœ 
        if pd.isna(exit_return) and 'ret_D20' in row.index and pd.notna(row['ret_D20']):
            exit_return = row['ret_D20']
            exit_day = 20
            exit_type = 'hold'
        
        results.append({
            'ret_sl': exit_return,
            'exit_day': exit_day,
            'exit_type': exit_type,
        })
    
    result_df = pd.DataFrame(results, index=signals_df.index)
    signals_df = pd.concat([signals_df, result_df], axis=1)
    
    return signals_df


# =============================================================================
# 4. ì „ëµ ëª¨ë“ˆ (Strategy Signals)
# =============================================================================

def detect_all_signals(df: pd.DataFrame) -> pd.DataFrame:
    """
    ëª¨ë“  ì „ëµ ì‹œê·¸ë„ íƒì§€
    
    [ì „ëµ ëª©ë¡]
    - S1_vol_drop: ê±°ë˜ëŸ‰ ê¸‰ê° + ìŒë´‰ + MA5 ê·¼ì ‘
    - S2_vol_spike_drop: ê±°ë˜ëŸ‰ í­ì¦â†’ê¸‰ê° + MA5 ê·¼ì ‘ (ê±°ê°ìŒë´‰)
    - S3_ma3_support: ê¸‰ë“± í›„ 3ì¼ì„  ì§€ì§€
    - S4_ma78_pullback: 7/8ì¼ì„  ëˆŒë¦¼ëª© (ì´ê²©í˜•)
    - S4_ma78_touch: 7/8ì¼ì„  ëˆŒë¦¼ëª© (í„°ì¹˜í˜•)
    - S5_ma45_first: 45ì¼ì„  ë‚™ì£¼ë§¤ë§¤ (ì²« í„°ì¹˜)
    - S6_ma33_scout: 33ì¼ì„  ì •ì°°ë³‘
    - S7_ma360_bounce: 360ì¼ì„  ê¸‰ë½ë°˜ë“±
    """
    df = df.copy()
    
    # =========================================================================
    # S1: ê±°ë˜ëŸ‰ ê¸‰ê° + ìŒë´‰ + MA5 ê·¼ì ‘
    # =========================================================================
    # ì „ì¼ ëŒ€ë¹„ ê±°ë˜ëŸ‰ 36% ì´í•˜ (ê¸‰ê°)
    vol_drop = df['vol_ratio_1d'] <= 0.36
    bearish = df['is_bearish']
    ma5_near = df['ma5_dist'].abs() <= 0.03  # 3% ì´ë‚´
    
    df['S1_vol_drop'] = vol_drop & bearish & ma5_near
    
    # =========================================================================
    # S2: ê±°ë˜ëŸ‰ í­ì¦â†’ê¸‰ê° + MA5 ê·¼ì ‘ (ê±°ê°ìŒë´‰) â­í•µì‹¬
    # =========================================================================
    # ì „ì¼ ê±°ë˜ëŸ‰ 5ë°° ì´ìƒ í­ì¦
    vol_spike_prev = df['vol_ratio_prev'] >= 5.0
    # ë‹¹ì¼ ê±°ë˜ëŸ‰ 25% ì´í•˜ë¡œ ê¸‰ê°
    vol_drop_today = df['vol_ratio_1d'] <= 0.25
    
    df['S2_vol_spike_drop'] = vol_spike_prev & vol_drop_today & ma5_near
    df['S2_vol_spike_drop_bearish'] = df['S2_vol_spike_drop'] & bearish  # ê±°ê°ìŒë´‰
    df['S2_vol_spike_drop_10m'] = df['S2_vol_spike_drop'] & df['vol_prev_over_10m']  # 1000ë§Œ+
    
    # =========================================================================
    # S3: ê¸‰ë“± ì´ë ¥ + 3ì¼ì„  ì§€ì§€
    # =========================================================================
    # ìµœê·¼ 5ì¼ ë‚´ 20%+ ê¸‰ë“± ì´ë ¥
    had_surge = df['had_surge_5d']
    # 3ì¼ì„  í„°ì¹˜ ë˜ëŠ” ê·¼ì ‘
    ma3_support = df['ma3_touch'] | (df['ma3_dist'].abs() <= 0.02)
    # 5ì¼ì„  ìœ„ ìœ ì§€
    above_ma5 = df['close'] > df['ma5']
    
    df['S3_ma3_support'] = had_surge & ma3_support & above_ma5
    
    # =========================================================================
    # S4: 7/8ì¼ì„  ëˆŒë¦¼ëª©
    # =========================================================================
    # ì¡°ê±´: ìµœê·¼ 10ì¼ ë‚´ ê¸‰ë“± + 5ì¼ì„  ì•„ë˜ + 7/8ì¼ì„  ì§€ì§€ + 10ì¼ì„  ìœ„
    had_surge_10d = df['had_surge_10d']
    below_ma5 = df['close'] < df['ma5']
    above_ma10 = df['close'] > df['ma10']
    
    # ì´ê²©í˜• (2% ì´ë‚´)
    ma7_near = df['ma7_dist'].abs() <= 0.02
    ma8_near = df['ma8_dist'].abs() <= 0.02
    
    df['S4_ma7_pullback'] = had_surge_10d & below_ma5 & ma7_near & above_ma10
    df['S4_ma8_pullback'] = had_surge_10d & below_ma5 & ma8_near & above_ma10
    df['S4_ma78_pullback'] = df['S4_ma7_pullback'] | df['S4_ma8_pullback']
    
    # í„°ì¹˜í˜• (low â‰¤ ma â‰¤ high)
    df['S4_ma7_touch'] = had_surge_10d & below_ma5 & df['ma7_touch'] & above_ma10
    df['S4_ma8_touch'] = had_surge_10d & below_ma5 & df['ma8_touch'] & above_ma10
    df['S4_ma78_touch'] = df['S4_ma7_touch'] | df['S4_ma8_touch']
    
    # =========================================================================
    # S5: 45ì¼ì„  ë‚™ì£¼ë§¤ë§¤ (ì²« í„°ì¹˜) â­í•µì‹¬
    # =========================================================================
    # ì¡°ê±´: ìƒí•œê°€ ì´ë ¥ + 45ì¼ì„  ì²« í„°ì¹˜ + ê±°ë˜ëŸ‰ ê°ì†Œ + 120ì¼ì„  ì£¼ì˜
    had_limit_up = df['had_limit_up_20d']
    ma45_touch = df['ma45_touch'] | (df['ma45_dist'].abs() <= 0.02)
    vol_decreased = df['vol_ratio_ma20'] <= 0.8  # 20ì¼ í‰ê· ì˜ 80% ì´í•˜
    
    # "ì²« í„°ì¹˜" íŒì •: ì´ì „ 10ì¼ê°„ 45ì¼ì„  í„°ì¹˜ ì—†ì—ˆìŒ
    ma45_touch_history = df['ma45_touch'].rolling(10, min_periods=1).sum().shift(1)
    is_first_touch = (ma45_touch_history == 0) | ma45_touch_history.isna()
    
    df['S5_ma45_first'] = had_limit_up & ma45_touch & vol_decreased & is_first_touch
    df['S5_ma45_first_safe'] = df['S5_ma45_first'] & ~df['ma120_overhead']  # 120ì¼ì„  ì•„ë˜ì¼ ë•Œ
    df['S5_ma45_first_caution'] = df['S5_ma45_first'] & df['ma120_overhead']  # 120ì¼ì„  ì£¼ì˜
    
    # =========================================================================
    # S6: 33ì¼ì„  ì •ì°°ë³‘ â†’ 45ì¼ì„  ë³¸ì§„ì…
    # =========================================================================
    # 33ì¼ì„  í„°ì¹˜ (45ì¼ì„  ì „ì— ê°€ëŠ” ê²½ìš°)
    ma33_touch = df['ma33_touch'] | (df['ma33_dist'].abs() <= 0.02)
    above_ma45 = df['close'] > df['ma45']
    
    df['S6_ma33_scout'] = had_limit_up & ma33_touch & vol_decreased & above_ma45
    
    # =========================================================================
    # S7: 360ì¼ì„  ê¸‰ë½ë°˜ë“±
    # =========================================================================
    # 60ì¼ ì¤‘ í•˜ìœ„ 20% ìœ„ì¹˜ + 360ì¼ì„  ê·¼ì ‘ + ê±°ë˜ëŸ‰ ì¦ê°€
    low_position = df['position_60d'] <= 20
    ma360_near = df['ma360_dist'].abs() <= 0.03  # 3% ì´ë‚´
    vol_increased = df['vol_ratio_ma20'] >= 1.5
    
    df['S7_ma360_bounce'] = low_position & (ma360_near | df['ma360_touch']) & vol_increased
    
    # =========================================================================
    # S8: 15ì¼ì„  ëˆŒë¦¼ëª© (ì™¸ì¸ ì„ í˜¸)
    # =========================================================================
    below_ma10 = df['close'] < df['ma10']
    above_ma20 = df['close'] > df['ma20']
    ma15_near = df['ma15_dist'].abs() <= 0.02
    
    df['S8_ma15_pullback'] = had_surge_10d & below_ma10 & ma15_near & above_ma20
    
    # =========================================================================
    # S9: 20ì¼ì„  ìƒëª…ì„ 
    # =========================================================================
    ma20_near = df['ma20_dist'].abs() <= 0.02
    above_ma60 = df['close'] > df['ma60']
    
    df['S9_ma20_lifeline'] = had_surge_10d & ma20_near & above_ma60
    
    return df


# =============================================================================
# 5. ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
# =============================================================================

# ì „ëµ ëª©ë¡ ì •ì˜
STRATEGIES = [
    'S1_vol_drop',
    'S2_vol_spike_drop',
    'S2_vol_spike_drop_bearish',
    'S2_vol_spike_drop_10m',
    'S3_ma3_support',
    'S4_ma7_pullback',
    'S4_ma8_pullback',
    'S4_ma78_pullback',
    'S4_ma7_touch',
    'S4_ma8_touch',
    'S4_ma78_touch',
    'S5_ma45_first',
    'S5_ma45_first_safe',
    'S5_ma45_first_caution',
    'S6_ma33_scout',
    'S7_ma360_bounce',
    'S8_ma15_pullback',
    'S9_ma20_lifeline',
]


def process_single_stock(args: Tuple[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:
    """ë‹¨ì¼ ì¢…ëª© ì²˜ë¦¬ (ë©€í‹°ì½”ì–´ìš©)"""
    code, df = args
    
    try:
        # ì§€í‘œ ê³„ì‚°
        df = calculate_indicators(df)
        
        # ìˆ˜ìµë¥  ê³„ì‚°
        df = calculate_returns(df, include_costs=True, include_stoploss=False)
        
        # ì‹œê·¸ë„ íƒì§€
        df = detect_all_signals(df)
        
        # ì›Œë°ì—… ê¸°ê°„ ì œì™¸
        df = df.iloc[CONFIG.warmup_days:].copy()
        
        # ì „ëµë³„ ì‹œê·¸ë„ ì¶”ì¶œ
        results = {}
        for strategy in STRATEGIES:
            if strategy in df.columns:
                signals = df[df[strategy] == True].copy()
                if len(signals) > 0:
                    signals['strategy'] = strategy
                    results[strategy] = signals
        
        return results
        
    except Exception as e:
        return {}


def run_backtest(
    ohlcv_data: Dict[str, pd.DataFrame],
    use_multicore: bool = True,
) -> Dict[str, pd.DataFrame]:
    """
    ì „ì²´ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    
    Returns:
        ì „ëµë³„ ì‹œê·¸ë„ DataFrame ë”•ì…”ë„ˆë¦¬
    """
    print(f"\n{'='*70}")
    print(f"ğŸš€ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    print(f"{'='*70}")
    print(f"   ì¢…ëª© ìˆ˜: {len(ohlcv_data)}")
    print(f"   ì „ëµ ìˆ˜: {len(STRATEGIES)}")
    print(f"   ë©€í‹°ì½”ì–´: {use_multicore}")
    
    start_time = time.time()
    
    # ì „ëµë³„ ì‹œê·¸ë„ ìˆ˜ì§‘
    all_signals = {s: [] for s in STRATEGIES}
    
    if use_multicore and len(ohlcv_data) > 100:
        print(f"   ğŸš€ ë©€í‹°ì½”ì–´ ëª¨ë“œ: {CONFIG.num_workers} workers")
        
        items = list(ohlcv_data.items())
        
        with ProcessPoolExecutor(max_workers=CONFIG.num_workers) as executor:
            futures = {executor.submit(process_single_stock, item): item[0] for item in items}
            
            for i, future in enumerate(as_completed(futures)):
                if (i + 1) % 500 == 0:
                    print(f"   ì§„í–‰: {i+1}/{len(items)}")
                
                try:
                    results = future.result()
                    for strategy, signals in results.items():
                        if len(signals) > 0:
                            all_signals[strategy].append(signals)
                except Exception:
                    continue
    else:
        print(f"   ğŸ“ ì‹±ê¸€ì½”ì–´ ëª¨ë“œ")
        
        for i, (code, df) in enumerate(ohlcv_data.items()):
            if (i + 1) % 500 == 0:
                print(f"   ì§„í–‰: {i+1}/{len(ohlcv_data)}")
            
            results = process_single_stock((code, df))
            for strategy, signals in results.items():
                if len(signals) > 0:
                    all_signals[strategy].append(signals)
    
    # ì‹œê·¸ë„ í•©ì¹˜ê¸°
    final_signals = {}
    for strategy in STRATEGIES:
        if all_signals[strategy]:
            combined = pd.concat(all_signals[strategy], ignore_index=True)
            final_signals[strategy] = combined
            print(f"   {strategy}: {len(combined):,}ê°œ ì‹œê·¸ë„")
        else:
            final_signals[strategy] = pd.DataFrame()
    
    elapsed = time.time() - start_time
    print(f"\nâœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ({elapsed:.1f}ì´ˆ)")
    
    return final_signals


# =============================================================================
# 6. ì„±ê³¼ ë¶„ì„ (Performance Metrics)
# =============================================================================

def calculate_metrics(signals_df: pd.DataFrame, strategy_name: str = '') -> Dict[str, Any]:
    """
    ì „ëµ ì„±ê³¼ ì§€í‘œ ê³„ì‚°
    
    [ì§€í‘œ]
    - ì‹œê·¸ë„ ìˆ˜, ì¢…ëª© ìˆ˜
    - í‰ê· /ì¤‘ì•™ê°’ ìˆ˜ìµë¥  (D+1 ~ D+20)
    - ìŠ¹ë¥  (D+1 ~ D+20)
    - ì†ìµë¹„ (Profit Factor)
    - ìµœëŒ€ ìˆ˜ìµ/ì†ì‹¤
    - MDD (ìµœëŒ€ë‚™í­)
    """
    if len(signals_df) == 0:
        return {'strategy': strategy_name, 'signals': 0}
    
    metrics = {
        'strategy': strategy_name,
        'signals': len(signals_df),
        'unique_stocks': signals_df['code'].nunique() if 'code' in signals_df.columns else 0,
    }
    
    # ë³´ìœ ê¸°ê°„ë³„ ìˆ˜ìµë¥ /ìŠ¹ë¥ 
    for d in CONFIG.return_periods:
        col = f'ret_D{d}'
        if col in signals_df.columns:
            returns = signals_df[col].dropna()
            if len(returns) > 0:
                metrics[f'D{d}_mean'] = returns.mean() * 100
                metrics[f'D{d}_median'] = returns.median() * 100
                metrics[f'D{d}_win'] = (returns > 0).mean() * 100
                metrics[f'D{d}_max'] = returns.max() * 100
                metrics[f'D{d}_min'] = returns.min() * 100
                metrics[f'D{d}_std'] = returns.std() * 100
    
    # ì†ìµë¹„ (Profit Factor) - D+5 ê¸°ì¤€
    if 'ret_D5' in signals_df.columns:
        returns = signals_df['ret_D5'].dropna()
        wins = returns[returns > 0]
        losses = returns[returns < 0]
        
        if len(wins) > 0 and len(losses) > 0:
            avg_win = wins.mean()
            avg_loss = abs(losses.mean())
            metrics['profit_factor'] = avg_win / avg_loss if avg_loss > 0 else np.inf
            metrics['avg_win'] = avg_win * 100
            metrics['avg_loss'] = avg_loss * 100
        
        # ì†ìµë¹„ (ì´ì•¡ ê¸°ì¤€)
        total_profit = wins.sum() if len(wins) > 0 else 0
        total_loss = abs(losses.sum()) if len(losses) > 0 else 0
        metrics['profit_ratio'] = total_profit / total_loss if total_loss > 0 else np.inf
    
    # ì†ì ˆ/ìµì ˆ ìˆ˜ìµë¥ 
    if 'ret_sl' in signals_df.columns:
        sl_returns = signals_df['ret_sl'].dropna()
        if len(sl_returns) > 0:
            metrics['sl_mean'] = sl_returns.mean() * 100
            metrics['sl_win'] = (sl_returns > 0).mean() * 100
            
            # Exit type ë¶„í¬
            if 'exit_type' in signals_df.columns:
                exit_counts = signals_df['exit_type'].value_counts()
                metrics['exit_stop_loss'] = exit_counts.get('stop_loss', 0)
                metrics['exit_take_profit'] = exit_counts.get('take_profit', 0)
                metrics['exit_hold'] = exit_counts.get('hold', 0)
    
    return metrics


def calculate_mdd(returns: pd.Series) -> float:
    """
    MDD (Maximum Drawdown) ê³„ì‚°
    
    ëˆ„ì  ìˆ˜ìµë¥  ê¸°ì¤€ ìµœëŒ€ ë‚™í­
    """
    if len(returns) == 0:
        return 0.0
    
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.cummax()
    drawdown = (cumulative - running_max) / running_max
    
    return drawdown.min() * 100


def generate_performance_report(
    all_signals: Dict[str, pd.DataFrame],
    output_path: Optional[Path] = None,
) -> pd.DataFrame:
    """
    ì „ì²´ ì„±ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
    """
    print(f"\n{'='*70}")
    print(f"ğŸ“Š ì„±ê³¼ ë¶„ì„ ë¦¬í¬íŠ¸")
    print(f"{'='*70}")
    
    results = []
    
    for strategy, signals_df in all_signals.items():
        if len(signals_df) == 0:
            continue
        
        metrics = calculate_metrics(signals_df, strategy)
        
        # MDD ê³„ì‚°
        if 'ret_D5' in signals_df.columns:
            metrics['mdd'] = calculate_mdd(signals_df['ret_D5'].dropna())
        
        results.append(metrics)
    
    if not results:
        print("ê²°ê³¼ ì—†ìŒ")
        return pd.DataFrame()
    
    report_df = pd.DataFrame(results)
    
    # ì»¬ëŸ¼ ì •ë ¬
    priority_cols = ['strategy', 'signals', 'unique_stocks']
    return_cols = [c for c in report_df.columns if c.startswith('D') and '_mean' in c]
    win_cols = [c for c in report_df.columns if c.startswith('D') and '_win' in c]
    other_cols = [c for c in report_df.columns if c not in priority_cols + return_cols + win_cols]
    
    ordered_cols = priority_cols + sorted(return_cols) + sorted(win_cols) + other_cols
    ordered_cols = [c for c in ordered_cols if c in report_df.columns]
    report_df = report_df[ordered_cols]
    
    # ì†Œìˆ˜ì  ì •ë¦¬
    for col in report_df.columns:
        if report_df[col].dtype in ['float64', 'float32']:
            report_df[col] = report_df[col].round(2)
    
    # ì¶œë ¥
    print(f"\nğŸ“ˆ ì „ëµë³„ ì„±ê³¼ ìš”ì•½:")
    print(report_df.to_string(index=False))
    
    # D+5 ìˆ˜ìµë¥  ìˆœìœ„
    if 'D5_mean' in report_df.columns:
        print(f"\nğŸ† D+5 ìˆ˜ìµë¥  TOP 10:")
        top10 = report_df.nlargest(10, 'D5_mean')[['strategy', 'signals', 'D5_mean', 'D5_win', 'profit_factor']]
        print(top10.to_string(index=False))
    
    # D+5 ìŠ¹ë¥  ìˆœìœ„ (ì‹œê·¸ë„ 100ê°œ ì´ìƒ)
    if 'D5_win' in report_df.columns:
        print(f"\nğŸ¯ D+5 ìŠ¹ë¥  TOP 10 (ì‹œê·¸ë„â‰¥100):")
        filtered = report_df[report_df['signals'] >= 100]
        if len(filtered) > 0:
            top10_win = filtered.nlargest(10, 'D5_win')[['strategy', 'signals', 'D5_mean', 'D5_win', 'profit_factor']]
            print(top10_win.to_string(index=False))
    
    # CSV ì €ì¥
    if output_path:
        report_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")
    
    return report_df


# =============================================================================
# 7. ì‹œê°„ëŒ€ë³„ ë¶„ì„ (ì›”ë³„/ë¶„ê¸°ë³„/ìš”ì¼ë³„)
# =============================================================================

def analyze_by_time(
    signals_df: pd.DataFrame,
    strategy_name: str = '',
    save_csv: bool = True,
) -> Dict[str, pd.DataFrame]:
    """
    ì‹œê°„ëŒ€ë³„ ì„±ê³¼ ë¶„ì„
    
    - ì—°ë„ë³„
    - ì›”ë³„ (ê°ì‚¬ì˜ê²¬ ì‹œì¦Œ 2~3ì›” í‘œì‹œ)
    - ë¶„ê¸°ë³„
    - ìš”ì¼ë³„
    """
    if len(signals_df) == 0:
        return {}
    
    signals_df = signals_df.copy()
    signals_df['date'] = pd.to_datetime(signals_df['date'])
    signals_df['year'] = signals_df['date'].dt.year
    signals_df['month'] = signals_df['date'].dt.month
    signals_df['quarter'] = signals_df['date'].dt.quarter
    signals_df['weekday'] = signals_df['date'].dt.dayofweek
    
    results = {}
    
    print(f"\n{'='*70}")
    print(f"â° ì‹œê°„ëŒ€ë³„ ë¶„ì„: {strategy_name}")
    print(f"{'='*70}")
    
    # =========================================================================
    # ì—°ë„ë³„
    # =========================================================================
    by_year = signals_df.groupby('year').agg({
        'code': 'count',
        'ret_D5': ['mean', lambda x: (x > 0).mean()],
    }).round(4)
    by_year.columns = ['signals', 'D5_mean', 'D5_win']
    by_year['D5_mean'] = by_year['D5_mean'] * 100
    by_year['D5_win'] = by_year['D5_win'] * 100
    
    print(f"\nğŸ“… ì—°ë„ë³„:")
    print(by_year.round(2).to_string())
    results['year'] = by_year
    
    # =========================================================================
    # ì›”ë³„ (ê°ì‚¬ì˜ê²¬ ì‹œì¦Œ)
    # =========================================================================
    by_month = signals_df.groupby('month').agg({
        'code': 'count',
        'ret_D1': 'mean',
        'ret_D5': ['mean', lambda x: (x > 0).mean()],
        'ret_D10': 'mean',
    }).round(4)
    by_month.columns = ['signals', 'D1', 'D5', 'D5_win', 'D10']
    
    for col in ['D1', 'D5', 'D10']:
        by_month[col] = by_month[col] * 100
    by_month['D5_win'] = by_month['D5_win'] * 100
    
    month_names = {
        1: '1ì›”(ìƒˆí•´)', 2: '2ì›”(ê°ì‚¬âš ï¸)', 3: '3ì›”(ê°ì‚¬âš ï¸)',
        4: '4ì›”', 5: '5ì›”', 6: '6ì›”',
        7: '7ì›”', 8: '8ì›”(íœ´ê°€)', 9: '9ì›”',
        10: '10ì›”', 11: '11ì›”(ì„¸ê¸ˆ)', 12: '12ì›”(ìœˆë„ìš°)'
    }
    by_month.index = by_month.index.map(lambda x: month_names.get(x, f'{x}ì›”'))
    
    print(f"\nğŸ“† ì›”ë³„:")
    print(by_month.round(2).to_string())
    results['month'] = by_month
    
    # ê°ì‚¬ì˜ê²¬ ì‹œì¦Œ vs ë¹„ì‹œì¦Œ
    signals_df['is_audit'] = signals_df['month'].isin([2, 3])
    audit = signals_df[signals_df['is_audit']]
    non_audit = signals_df[~signals_df['is_audit']]
    
    if len(audit) >= 10 and len(non_audit) >= 10:
        print(f"\nâš ï¸ ê°ì‚¬ì˜ê²¬ ì‹œì¦Œ (2~3ì›”) vs ë¹„ì‹œì¦Œ:")
        print(f"   2~3ì›”:  D+5 {audit['ret_D5'].mean()*100:+.2f}%  ìŠ¹ë¥  {(audit['ret_D5']>0).mean()*100:.1f}%  ({len(audit)}ê°œ)")
        print(f"   ê·¸ ì™¸:  D+5 {non_audit['ret_D5'].mean()*100:+.2f}%  ìŠ¹ë¥  {(non_audit['ret_D5']>0).mean()*100:.1f}%  ({len(non_audit)}ê°œ)")
    
    # =========================================================================
    # ë¶„ê¸°ë³„
    # =========================================================================
    by_quarter = signals_df.groupby('quarter').agg({
        'code': 'count',
        'ret_D5': ['mean', lambda x: (x > 0).mean()],
    }).round(4)
    by_quarter.columns = ['signals', 'D5', 'D5_win']
    by_quarter['D5'] = by_quarter['D5'] * 100
    by_quarter['D5_win'] = by_quarter['D5_win'] * 100
    
    quarter_names = {1: 'Q1', 2: 'Q2', 3: 'Q3', 4: 'Q4'}
    by_quarter.index = by_quarter.index.map(lambda x: quarter_names.get(x, f'Q{x}'))
    
    print(f"\nğŸ“Š ë¶„ê¸°ë³„:")
    print(by_quarter.round(2).to_string())
    results['quarter'] = by_quarter
    
    # =========================================================================
    # ìš”ì¼ë³„
    # =========================================================================
    by_weekday = signals_df.groupby('weekday').agg({
        'code': 'count',
        'ret_D1': 'mean',
        'ret_D5': ['mean', lambda x: (x > 0).mean()],
    }).round(4)
    by_weekday.columns = ['signals', 'D1', 'D5', 'D5_win']
    
    for col in ['D1', 'D5']:
        by_weekday[col] = by_weekday[col] * 100
    by_weekday['D5_win'] = by_weekday['D5_win'] * 100
    
    weekday_names = {0: 'ì›”', 1: 'í™”', 2: 'ìˆ˜', 3: 'ëª©', 4: 'ê¸ˆ'}
    by_weekday.index = by_weekday.index.map(lambda x: weekday_names.get(x, str(x)))
    
    print(f"\nğŸ“… ìš”ì¼ë³„:")
    print(by_weekday.round(2).to_string())
    results['weekday'] = by_weekday
    
    # =========================================================================
    # CSV ì €ì¥
    # =========================================================================
    if save_csv:
        safe_name = strategy_name.replace('/', '_').replace('\\', '_')
        
        # ì›”ë³„ ì €ì¥ (ê°€ì¥ ìœ ìš©)
        by_month.to_csv(f'nomad_v3_{safe_name}_monthly.csv', encoding='utf-8-sig')
        print(f"\nğŸ’¾ ì›”ë³„ ë¶„ì„ ì €ì¥: nomad_v3_{safe_name}_monthly.csv")
        
        # ì—°ë„ë³„ ì €ì¥
        by_year.to_csv(f'nomad_v3_{safe_name}_yearly.csv', encoding='utf-8-sig')
        
        # Excel ì €ì¥ ì‹œë„ (openpyxl í•„ìš”)
        try:
            with pd.ExcelWriter(f'nomad_v3_{safe_name}_time_analysis.xlsx', engine='openpyxl') as writer:
                by_year.to_excel(writer, sheet_name='ì—°ë„ë³„')
                by_month.to_excel(writer, sheet_name='ì›”ë³„')
                by_quarter.to_excel(writer, sheet_name='ë¶„ê¸°ë³„')
                by_weekday.to_excel(writer, sheet_name='ìš”ì¼ë³„')
            print(f"ğŸ’¾ ì‹œê°„ëŒ€ë³„ ë¶„ì„ ì €ì¥: nomad_v3_{safe_name}_time_analysis.xlsx")
        except Exception:
            # openpyxl ì—†ìœ¼ë©´ CSVë¡œ ê°ê° ì €ì¥
            by_quarter.to_csv(f'nomad_v3_{safe_name}_quarterly.csv', encoding='utf-8-sig')
            by_weekday.to_csv(f'nomad_v3_{safe_name}_weekday.csv', encoding='utf-8-sig')
            print(f"ğŸ’¾ CSVë¡œ ì €ì¥ ì™„ë£Œ (xlsx ìƒëµ)")
    
    return results


# =============================================================================
# 8. ê¸°ê°„ ë¶„í•  ê²€ì¦ (In-Sample / Out-of-Sample)
# =============================================================================

def split_sample_analysis(
    signals_df: pd.DataFrame,
    split_date: str,
    strategy_name: str = '',
    save_csv: bool = True,
) -> Dict[str, Dict]:
    """
    ê¸°ê°„ ë¶„í•  ê²€ì¦
    
    - In-Sample (í•™ìŠµìš©): split_date ì´ì „
    - Out-of-Sample (ê²€ì¦ìš©): split_date ì´í›„
    """
    if len(signals_df) == 0:
        return {}
    
    signals_df = signals_df.copy()
    signals_df['date'] = pd.to_datetime(signals_df['date'])
    split_dt = pd.to_datetime(split_date)
    
    in_sample = signals_df[signals_df['date'] < split_dt]
    out_sample = signals_df[signals_df['date'] >= split_dt]
    
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ ê¸°ê°„ ë¶„í•  ê²€ì¦: {strategy_name}")
    print(f"   ë¶„í• ì¼: {split_date}")
    print(f"{'='*70}")
    
    results = {}
    
    for name, sample_df in [('In-Sample', in_sample), ('Out-of-Sample', out_sample)]:
        if len(sample_df) < 10:
            print(f"\n{name}: ì‹œê·¸ë„ ë¶€ì¡± ({len(sample_df)}ê°œ)")
            continue
        
        metrics = {
            'period': name,
            'signals': len(sample_df),
            'start': sample_df['date'].min().strftime('%Y-%m-%d'),
            'end': sample_df['date'].max().strftime('%Y-%m-%d'),
        }
        
        for d in [1, 5, 10]:
            col = f'ret_D{d}'
            if col in sample_df.columns:
                returns = sample_df[col].dropna()
                metrics[f'D{d}_mean'] = returns.mean() * 100
                metrics[f'D{d}_win'] = (returns > 0).mean() * 100
        
        results[name] = metrics
        
        print(f"\nğŸ“Š {name} ({metrics['start']} ~ {metrics['end']}):")
        print(f"   ì‹œê·¸ë„: {metrics['signals']:,}ê°œ")
        if 'D5_mean' in metrics:
            print(f"   D+5 í‰ê· : {metrics['D5_mean']:+.2f}%")
            print(f"   D+5 ìŠ¹ë¥ : {metrics['D5_win']:.1f}%")
    
    # ë¹„êµ
    if 'In-Sample' in results and 'Out-of-Sample' in results:
        in_d5 = results['In-Sample'].get('D5_mean', 0)
        out_d5 = results['Out-of-Sample'].get('D5_mean', 0)
        
        print(f"\nğŸ“ˆ ê²€ì¦ ê²°ê³¼:")
        if out_d5 >= in_d5 * 0.7:  # Out-of-Sampleì´ In-Sampleì˜ 70% ì´ìƒì´ë©´ ì–‘í˜¸
            print(f"   âœ… ì–‘í˜¸: Out-of-Sample({out_d5:+.2f}%) â‰¥ 70% of In-Sample({in_d5:+.2f}%)")
        else:
            print(f"   âš ï¸ ì£¼ì˜: Out-of-Sample({out_d5:+.2f}%) < 70% of In-Sample({in_d5:+.2f}%)")
            print(f"   ê³¼ìµœì í™” ê°€ëŠ¥ì„± ìˆìŒ")
    
    # CSV ì €ì¥
    if save_csv and results:
        safe_name = strategy_name.replace('/', '_').replace('\\', '_')
        split_df = pd.DataFrame([results.get('In-Sample', {}), results.get('Out-of-Sample', {})])
        split_df.to_csv(f'nomad_v3_{safe_name}_split.csv', index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ê¸°ê°„ë¶„í•  ê²€ì¦ ì €ì¥: nomad_v3_{safe_name}_split.csv")
    
    return results


# =============================================================================
# 9. ë³´ìœ ê¸°ê°„ë³„ ì„±ê³¼ ë§¤íŠ¸ë¦­ìŠ¤
# =============================================================================

def holding_period_matrix(
    signals_df: pd.DataFrame,
    strategy_name: str = '',
    save_csv: bool = True,
) -> pd.DataFrame:
    """
    ë³´ìœ ê¸°ê°„ë³„ ì„±ê³¼ ë§¤íŠ¸ë¦­ìŠ¤
    
    D+1 ~ D+20ê¹Œì§€ ìˆ˜ìµë¥ /ìŠ¹ë¥  í•œëˆˆì—
    """
    if len(signals_df) == 0:
        return pd.DataFrame()
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š ë³´ìœ ê¸°ê°„ë³„ ì„±ê³¼ ë§¤íŠ¸ë¦­ìŠ¤: {strategy_name}")
    print(f"{'='*70}")
    
    matrix_data = []
    
    for d in CONFIG.return_periods:
        col = f'ret_D{d}'
        if col not in signals_df.columns:
            continue
        
        returns = signals_df[col].dropna()
        if len(returns) == 0:
            continue
        
        matrix_data.append({
            'ë³´ìœ ê¸°ê°„': f'D+{d}',
            'í‰ê· ': returns.mean() * 100,
            'ì¤‘ì•™ê°’': returns.median() * 100,
            'ìŠ¹ë¥ ': (returns > 0).mean() * 100,
            'í‘œì¤€í¸ì°¨': returns.std() * 100,
            'ìµœëŒ€': returns.max() * 100,
            'ìµœì†Œ': returns.min() * 100,
            'ìƒ˜í”Œ': len(returns),
        })
    
    matrix_df = pd.DataFrame(matrix_data)
    
    for col in ['í‰ê· ', 'ì¤‘ì•™ê°’', 'ìŠ¹ë¥ ', 'í‘œì¤€í¸ì°¨', 'ìµœëŒ€', 'ìµœì†Œ']:
        if col in matrix_df.columns:
            matrix_df[col] = matrix_df[col].round(2)
    
    print(matrix_df.to_string(index=False))
    
    # CSV ì €ì¥
    if save_csv:
        safe_name = strategy_name.replace('/', '_').replace('\\', '_')
        matrix_df.to_csv(f'nomad_v3_{safe_name}_holding.csv', index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ë³´ìœ ê¸°ê°„ ë§¤íŠ¸ë¦­ìŠ¤ ì €ì¥: nomad_v3_{safe_name}_holding.csv")
    
    return matrix_df


# =============================================================================
# 10. ë©”ì¸ ì‹¤í–‰
# =============================================================================

def main():
    parser = argparse.ArgumentParser(description='ìœ ëª©ë¯¼ ë°±í…ŒìŠ¤íŠ¸ v3.0')
    
    # ê¸°ë³¸ ì˜µì…˜
    parser.add_argument('--start', type=str, default=CONFIG.start_date, 
                       help=f'ì‹œì‘ì¼ (ê¸°ë³¸: {CONFIG.start_date})')
    parser.add_argument('--end', type=str, default=CONFIG.end_date,
                       help=f'ì¢…ë£Œì¼ (ê¸°ë³¸: {CONFIG.end_date})')
    parser.add_argument('--split', type=str, default=CONFIG.split_date,
                       help=f'In/Out Sample ë¶„í• ì¼ (ê¸°ë³¸: {CONFIG.split_date})')
    
    # ì‹¤í–‰ ëª¨ë“œ
    parser.add_argument('--quick', action='store_true',
                       help='ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì£¼ìš” ì „ëµë§Œ)')
    parser.add_argument('--full', action='store_true',
                       help='ì „ì²´ í…ŒìŠ¤íŠ¸ (ëª¨ë“  ì „ëµ)')
    parser.add_argument('--strategy', type=str, default=None,
                       help='íŠ¹ì • ì „ëµë§Œ í…ŒìŠ¤íŠ¸')
    
    # ë¶„ì„ ì˜µì…˜
    parser.add_argument('--time-analysis', action='store_true',
                       help='ì‹œê°„ëŒ€ë³„ ë¶„ì„ (ì›”ë³„/ë¶„ê¸°ë³„/ìš”ì¼ë³„)')
    parser.add_argument('--split-analysis', action='store_true',
                       help='ê¸°ê°„ ë¶„í•  ê²€ì¦')
    parser.add_argument('--holding-matrix', action='store_true',
                       help='ë³´ìœ ê¸°ê°„ë³„ ë§¤íŠ¸ë¦­ìŠ¤')
    parser.add_argument('--all-analysis', action='store_true',
                       help='ëª¨ë“  ë¶„ì„ ì‹¤í–‰')
    
    # ë©€í‹°ì½”ì–´
    parser.add_argument('--single', action='store_true',
                       help='ì‹±ê¸€ì½”ì–´ ëª¨ë“œ')
    parser.add_argument('--workers', type=int, default=CONFIG.num_workers,
                       help=f'ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: {CONFIG.num_workers})')
    
    # ì¶œë ¥
    parser.add_argument('--output', type=str, default='nomad_v3_result.csv',
                       help='ê²°ê³¼ CSV íŒŒì¼ëª…')
    
    args = parser.parse_args()
    
    # ì„¤ì • ì—…ë°ì´íŠ¸
    CONFIG.start_date = args.start
    CONFIG.end_date = args.end
    CONFIG.split_date = args.split
    CONFIG.use_multicore = not args.single
    CONFIG.num_workers = args.workers
    
    print(f"\n{'='*70}")
    print(f"ğŸ“š ìœ ëª©ë¯¼ ë°±í…ŒìŠ¤íŠ¸ v3.0 - Professional Grade")
    print(f"{'='*70}")
    print(f"   ê¸°ê°„: {CONFIG.start_date} ~ {CONFIG.end_date}")
    print(f"   ë¶„í• ì¼: {CONFIG.split_date}")
    print(f"   ë©€í‹°ì½”ì–´: {CONFIG.use_multicore} ({CONFIG.num_workers} workers)")
    print(f"   ìˆ˜ìˆ˜ë£Œ: {CONFIG.commission*100:.3f}%")
    print(f"   ì„¸ê¸ˆ: {CONFIG.tax*100:.2f}%")
    print(f"   ì†ì ˆ: {CONFIG.stop_loss*100:.0f}%")
    print(f"   ìµì ˆ: {CONFIG.take_profit*100:.0f}%")
    
    # ë°ì´í„° ë¡œë“œ
    ohlcv_data = load_all_ohlcv(
        CONFIG.ohlcv_dir,
        CONFIG.start_date,
        CONFIG.end_date,
        use_multicore=CONFIG.use_multicore,
        num_workers=CONFIG.num_workers,
    )
    
    if not ohlcv_data:
        print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    all_signals = run_backtest(ohlcv_data, use_multicore=CONFIG.use_multicore)
    
    # ì„±ê³¼ ë¦¬í¬íŠ¸
    output_path = Path(args.output)
    report_df = generate_performance_report(all_signals, output_path)
    
    # ==========================================================================
    # ì‹œê·¸ë„ ë°ì´í„° ì €ì¥ (ì „ëµë³„)
    # ==========================================================================
    print(f"\n{'='*70}")
    print(f"ğŸ’¾ ì‹œê·¸ë„ ë°ì´í„° ì €ì¥ ì¤‘...")
    print(f"{'='*70}")
    
    for strategy, signals_df in all_signals.items():
        if len(signals_df) > 0:
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            save_cols = ['date', 'code', 'open', 'high', 'low', 'close', 'volume',
                        'ret_D1', 'ret_D3', 'ret_D5', 'ret_D7', 'ret_D10', 'ret_D15', 'ret_D20']
            save_cols = [c for c in save_cols if c in signals_df.columns]
            
            signals_df[save_cols].to_csv(f'signals_{strategy}.csv', index=False, encoding='utf-8-sig')
    
    print(f"   âœ… {len([s for s in all_signals.values() if len(s) > 0])}ê°œ ì „ëµ ì‹œê·¸ë„ ì €ì¥ ì™„ë£Œ")
    print(f"   ğŸ“ íŒŒì¼ëª…: signals_[ì „ëµëª…].csv")
    
    # ì¶”ê°€ ë¶„ì„
    if args.all_analysis or args.time_analysis:
        # ì‹œê°„ëŒ€ë³„ ë¶„ì„ (ì£¼ìš” ì „ëµ)
        main_strategies = ['S2_vol_spike_drop', 'S4_ma78_pullback', 'S5_ma45_first']
        for strategy in main_strategies:
            if strategy in all_signals and len(all_signals[strategy]) > 0:
                analyze_by_time(all_signals[strategy], strategy, save_csv=True)
    
    if args.all_analysis or args.split_analysis:
        # ê¸°ê°„ ë¶„í•  ê²€ì¦
        for strategy in ['S2_vol_spike_drop', 'S4_ma78_pullback', 'S5_ma45_first']:
            if strategy in all_signals and len(all_signals[strategy]) > 0:
                split_sample_analysis(all_signals[strategy], CONFIG.split_date, strategy, save_csv=True)
    
    if args.all_analysis or args.holding_matrix:
        # ë³´ìœ ê¸°ê°„ë³„ ë§¤íŠ¸ë¦­ìŠ¤
        for strategy in ['S2_vol_spike_drop', 'S4_ma78_pullback', 'S5_ma45_first']:
            if strategy in all_signals and len(all_signals[strategy]) > 0:
                holding_period_matrix(all_signals[strategy], strategy, save_csv=True)
    
    # ==========================================================================
    # ì €ì¥ëœ íŒŒì¼ ëª©ë¡ ì¶œë ¥
    # ==========================================================================
    print(f"\n{'='*70}")
    print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼ ëª©ë¡")
    print(f"{'='*70}")
    
    saved_files = list(Path(".").glob("nomad_v3_*.csv")) + \
                  list(Path(".").glob("signals_*.csv")) + \
                  list(Path(".").glob("nomad_v3_*.xlsx")) + \
                  [output_path]
    
    for f in sorted(set(saved_files)):
        if f.exists():
            size_kb = f.stat().st_size / 1024
            print(f"   ğŸ“„ {f.name} ({size_kb:.1f} KB)")
    
    print(f"\n{'='*70}")
    print(f"âœ… ì™„ë£Œ!")
    print(f"{'='*70}")


if __name__ == '__main__':
    main()