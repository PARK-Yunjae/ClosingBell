"""
ClosingBell - ì¢…ëª© ê²€ìƒ‰ í˜ì´ì§€

ì¢…ëª©ì½”ë“œ/ì¢…ëª©ëª…ìœ¼ë¡œ TOP5/ìœ ëª©ë¯¼ ì¶œí˜„ ì´ë ¥ ê²€ìƒ‰
- ìš”ì•½ ì¹´ë“œ (ë“±ì¥ íšŸìˆ˜, í‰ê·  ë­í¬, ìµœê·¼ ë“±ì¥ì¼)
- í•„í„° (ê¸°ê°„, ì†ŒìŠ¤, TOP5/ìœ ëª©ë¯¼)
- íˆìŠ¤í† ë¦¬ í…Œì´ë¸” (ì •ë ¬ ê°€ëŠ¥)
- ì°¨íŠ¸ (OHLCV ê¸°ë°˜)
"""

import streamlit as st
import pandas as pd
import sys
import os
from datetime import datetime, timedelta
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# ì „ì—­ìƒìˆ˜ import
try:
    from src.config.app_config import (
        APP_VERSION, APP_FULL_VERSION, SIDEBAR_TITLE, FOOTER_SEARCH,
    )
except ImportError:
    APP_VERSION = "v9.0"
    APP_FULL_VERSION = f"ClosingBell {APP_VERSION}"
    SIDEBAR_TITLE = "ğŸ”” ClosingBell"
    FOOTER_SEARCH = f"{APP_FULL_VERSION} | ì¢…ëª© ìƒì„¸ ë¶„ì„"

st.set_page_config(
    page_title=f"ì¢…ëª© ê²€ìƒ‰ | {APP_FULL_VERSION}",
    page_icon="ğŸ”",
    layout="wide",
)

# ==================== ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜ ====================
with st.sidebar:
    st.markdown(f"## {SIDEBAR_TITLE}")
st.page_link("app.py", label="í™ˆ")
st.page_link("pages/1_top5_tracker.py", label="ì¢…ê°€ë§¤ë§¤ TOP5")
st.page_link("pages/2_nomad_study.py", label="ìœ ëª©ë¯¼ ê³µë¶€ë²•")
st.page_link("pages/3_stock_search.py", label="ì¢…ëª© ê²€ìƒ‰")
st.page_link("pages/4_broker_flow.py", label="ê±°ë˜ì› ìˆ˜ê¸‰")
st.page_link("pages/5_stock_analysis.py", label="ì¢…ëª© ì‹¬ì¸µ ë¶„ì„")
    st.markdown("---")

st.title("ğŸ” ì¢…ëª© ê²€ìƒ‰")
st.markdown("ì¢…ëª©ì½”ë“œ ë˜ëŠ” ì¢…ëª©ëª…ìœ¼ë¡œ **TOP5/ìœ ëª©ë¯¼** ì¶œí˜„ ì´ë ¥ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.")


# Repository ë¡œë“œ
@st.cache_resource
def get_repositories():
    from src.infrastructure.database import init_database
    from src.infrastructure.repository import (
        get_top5_history_repository,
        get_nomad_candidates_repository,
    )
    
    init_database()
    
    return {
        'top5': get_top5_history_repository(),
        'nomad': get_nomad_candidates_repository(),
    }


repos = get_repositories()


# OHLCV ì°¨íŠ¸ ë¡œë“œ (í‚¤ì›€ ê¸°ë°˜, ë¡œì»¬ íŒŒì¼ í´ë°±)
OHLCV_PATH = Path(os.getenv("DATA_DIR", "C:/Coding/data")) / "ohlcv_kiwoom"

@st.cache_data(ttl=3600)
def load_ohlcv(stock_code: str, days: int = 60):
    """OHLCV ë°ì´í„° ë¡œë“œ (FinanceDataReader ìš°ì„ , ë¡œì»¬ íŒŒì¼ í´ë°±)"""
    
    # 1. FinanceDataReaderë¡œ ì‹œë„ (Streamlit Cloud í˜¸í™˜)
    try:
        import FinanceDataReader as fdr
        from datetime import timedelta
        
        end = datetime.now()
        start = end - timedelta(days=days + 30)  # ì˜ì—…ì¼ ê³ ë ¤
        
        df = fdr.DataReader(stock_code, start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))
        
        if df is not None and not df.empty:
            df = df.reset_index()
            df.columns = df.columns.str.lower()
            
            # ì»¬ëŸ¼ëª… í‘œì¤€í™”
            if 'index' in df.columns:
                df = df.rename(columns={'index': 'date'})
            
            df = df.tail(days)  # ìµœê·¼ Nì¼
            
            if not df.empty:
                return df
    except Exception:
        pass  # FDR ì‹¤íŒ¨ì‹œ ë¡œì»¬ íŒŒì¼ ì‹œë„
    
    # 2. ë¡œì»¬ íŒŒì¼ í´ë°± (ë¡œì»¬ ê°œë°œìš©)
    try:
        file_path = OHLCV_PATH / f"{stock_code}.csv"
        if not file_path.exists():
            return None
        
        df = pd.read_csv(file_path)
        df.columns = df.columns.str.lower()
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date', ascending=False).head(days)
        df = df.sort_values('date')
        return df
    except Exception:
        return None


def create_candlestick_chart(df: pd.DataFrame, stock_name: str, highlight_dates: list = None):
    """ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ìƒì„± (í•œêµ­ì‹: ìƒìŠ¹=ë¹¨ê°•, í•˜ë½=íŒŒë‘)"""
    try:
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
        
        fig = make_subplots(
            rows=2, cols=1,
            row_heights=[0.7, 0.3],
            shared_xaxes=True,
            vertical_spacing=0.05,
        )
        
        # ìº”ë“¤ìŠ¤í‹± (í•œêµ­ì‹: ìƒìŠ¹=ë¹¨ê°•, í•˜ë½=íŒŒë‘)
        fig.add_trace(
            go.Candlestick(
                x=df['date'],
                open=df['open'],
                high=df['high'],
                low=df['low'],
                close=df['close'],
                name='ê°€ê²©',
                increasing_line_color='#F44336',  # ìƒìŠ¹=ë¹¨ê°•
                increasing_fillcolor='#F44336',
                decreasing_line_color='#2196F3',  # í•˜ë½=íŒŒë‘
                decreasing_fillcolor='#2196F3',
            ),
            row=1, col=1
        )
        
        # TOP5/ìœ ëª©ë¯¼ ì¶œí˜„ì¼ í‘œì‹œ
        if highlight_dates:
            for d in highlight_dates:
                fig.add_vline(
                    x=d,
                    line_dash="dash",
                    line_color="orange",
                    opacity=0.7,
                    row=1, col=1
                )
        
        # ê±°ë˜ëŸ‰ (í•œêµ­ì‹: ì–‘ë´‰=ë¹¨ê°•, ìŒë´‰=íŒŒë‘)
        colors = ['#F44336' if c >= o else '#2196F3' 
                  for c, o in zip(df['close'], df['open'])]
        fig.add_trace(
            go.Bar(x=df['date'], y=df['volume'], name='ê±°ë˜ëŸ‰', marker_color=colors),
            row=2, col=1
        )
        
        fig.update_layout(
            title=f"ğŸ“ˆ {stock_name} ì°¨íŠ¸ (ìµœê·¼ 60ì¼)",
            height=500,
            xaxis_rangeslider_visible=False,
            showlegend=False,
        )
        
        return fig
    except ImportError:
        return None


# ============================================================
# ì‚¬ì´ë“œë°”: ê²€ìƒ‰ ì¡°ê±´
# ============================================================
st.sidebar.header("ğŸ” ê²€ìƒ‰ ì¡°ê±´")

# ê²€ìƒ‰ì–´ ì…ë ¥
search_query = st.sidebar.text_input(
    "ì¢…ëª©ì½”ë“œ ë˜ëŠ” ì¢…ëª©ëª…",
    placeholder="ì˜ˆ: 005930 ë˜ëŠ” ì‚¼ì„±",
    help="2ê¸€ì ì´ìƒ ì…ë ¥í•˜ì„¸ìš”"
)

# ê¸°ê°„ í•„í„°
period_options = {
    "ìµœê·¼ 7ì¼": 7,
    "ìµœê·¼ 30ì¼": 30,
    "ìµœê·¼ 90ì¼": 90,
    "ìµœê·¼ 1ë…„": 365,
    "ì „ì²´": 9999,
}
selected_period = st.sidebar.selectbox("ê¸°ê°„", list(period_options.keys()), index=1)
days_back = period_options[selected_period]

# ë°ì´í„° ì†ŒìŠ¤ í•„í„°
source_options = ["ì „ì²´", "realtime", "backfill"]
selected_source = st.sidebar.selectbox("ë°ì´í„° ì†ŒìŠ¤", source_options)

# êµ¬ë¶„ í•„í„°
show_top5 = st.sidebar.checkbox("TOP5", value=True)
show_nomad = st.sidebar.checkbox("ìœ ëª©ë¯¼", value=True)


# ============================================================
# ê²€ìƒ‰ í•¨ìˆ˜ (ìºì‹œ)
# ============================================================
@st.cache_data(ttl=60)
def search_top5(query: str, limit: int = 200):
    """TOP5 íˆìŠ¤í† ë¦¬ ê²€ìƒ‰"""
    return repos['top5'].search_occurrences(query, limit=limit)


@st.cache_data(ttl=60)
def search_nomad(query: str, limit: int = 200):
    """ìœ ëª©ë¯¼ íˆìŠ¤í† ë¦¬ ê²€ìƒ‰"""
    return repos['nomad'].search_occurrences(query, limit=limit)


def filter_by_period(df: pd.DataFrame, days: int, date_col: str = 'screen_date') -> pd.DataFrame:
    """ê¸°ê°„ í•„í„°"""
    if days >= 9999 or df.empty:
        return df
    
    cutoff = (datetime.now() - timedelta(days=days)).date()
    
    # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
    df_copy = df.copy()
    if date_col in df_copy.columns:
        df_copy[date_col] = pd.to_datetime(df_copy[date_col]).dt.date
        return df_copy[df_copy[date_col] >= cutoff]
    
    return df_copy


def filter_by_source(df: pd.DataFrame, source: str) -> pd.DataFrame:
    """ì†ŒìŠ¤ í•„í„°"""
    if source == "ì „ì²´" or 'data_source' not in df.columns:
        return df
    return df[df['data_source'] == source]


# ============================================================
# ë©”ì¸ ê²€ìƒ‰ ë¡œì§
# ============================================================
if search_query and len(search_query) >= 2:
    
    # ê²€ìƒ‰ ì‹¤í–‰
    top5_results = []
    nomad_results = []
    
    if show_top5:
        top5_results = search_top5(search_query)
    
    if show_nomad:
        nomad_results = search_nomad(search_query)
    
    # DataFrame ë³€í™˜
    df_top5 = pd.DataFrame(top5_results) if top5_results else pd.DataFrame()
    df_nomad = pd.DataFrame(nomad_results) if nomad_results else pd.DataFrame()
    
    # í•„í„° ì ìš©
    if not df_top5.empty:
        df_top5 = filter_by_period(df_top5, days_back, 'screen_date')
        df_top5 = filter_by_source(df_top5, selected_source)
    
    if not df_nomad.empty:
        df_nomad = filter_by_period(df_nomad, days_back, 'study_date')
        # nomadëŠ” data_source ì»¬ëŸ¼ì´ ì—†ì„ ìˆ˜ ìˆìŒ
    
    # ============================================================
    # ìš”ì•½ ì¹´ë“œ
    # ============================================================
    st.markdown("---")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        top5_count = len(df_top5)
        st.metric("ğŸ† TOP5 ë“±ì¥", f"{top5_count}íšŒ")
    
    with col2:
        nomad_count = len(df_nomad)
        st.metric("ğŸ“š ìœ ëª©ë¯¼ ë“±ì¥", f"{nomad_count}íšŒ")
    
    with col3:
        # ìµœê·¼ ë“±ì¥ì¼
        latest_date = None
        if not df_top5.empty:
            latest_top5 = pd.to_datetime(df_top5['screen_date']).max()
            latest_date = latest_top5
        if not df_nomad.empty:
            latest_nomad = pd.to_datetime(df_nomad['study_date']).max()
            if latest_date is None or latest_nomad > latest_date:
                latest_date = latest_nomad
        
        if latest_date:
            st.metric("ğŸ“… ìµœê·¼ ë“±ì¥", latest_date.strftime("%Y-%m-%d"))
        else:
            st.metric("ğŸ“… ìµœê·¼ ë“±ì¥", "-")
    
    with col4:
        # í‰ê·  ë­í¬ (TOP5ë§Œ)
        if not df_top5.empty and 'rank' in df_top5.columns:
            avg_rank = df_top5['rank'].mean()
            st.metric("ğŸ“Š í‰ê·  ë­í¬", f"{avg_rank:.1f}")
        else:
            st.metric("ğŸ“Š í‰ê·  ë­í¬", "-")
    
    # ============================================================
    # TOP5 íˆìŠ¤í† ë¦¬ í…Œì´ë¸”
    # ============================================================
    if show_top5 and not df_top5.empty:
        st.markdown("---")
        st.subheader("ğŸ† TOP5 ì¶œí˜„ ì´ë ¥")
        
        # ì»¬ëŸ¼ ì„ íƒ ë° í¬ë§·
        display_cols = ['screen_date', 'stock_code', 'stock_name', 'rank', 
                       'screen_score', 'grade', 'change_rate', 'cci', 
                       'trading_value', 'data_source']
        
        available_cols = [c for c in display_cols if c in df_top5.columns]
        df_display = df_top5[available_cols].copy()
        
        # ì»¬ëŸ¼ëª… í•œê¸€í™”
        col_names = {
            'screen_date': 'ë‚ ì§œ',
            'stock_code': 'ì¢…ëª©ì½”ë“œ',
            'stock_name': 'ì¢…ëª©ëª…',
            'rank': 'ìˆœìœ„',
            'screen_score': 'ì ìˆ˜',
            'grade': 'ë“±ê¸‰',
            'change_rate': 'ë“±ë½ë¥ (%)',
            'cci': 'CCI',
            'trading_value': 'ê±°ë˜ëŒ€ê¸ˆ(ì–µ)',
            'data_source': 'ì†ŒìŠ¤',
        }
        df_display = df_display.rename(columns=col_names)
        
        # ë‚ ì§œ ì •ë ¬ (ìµœì‹ ìˆœ)
        if 'ë‚ ì§œ' in df_display.columns:
            df_display = df_display.sort_values('ë‚ ì§œ', ascending=False)
        
        # ìˆ«ì í¬ë§·
        if 'ì ìˆ˜' in df_display.columns:
            df_display['ì ìˆ˜'] = df_display['ì ìˆ˜'].round(1)
        if 'ë“±ë½ë¥ (%)' in df_display.columns:
            df_display['ë“±ë½ë¥ (%)'] = df_display['ë“±ë½ë¥ (%)'].round(2)
        if 'CCI' in df_display.columns:
            df_display['CCI'] = df_display['CCI'].round(0)
        if 'ê±°ë˜ëŒ€ê¸ˆ(ì–µ)' in df_display.columns:
            df_display['ê±°ë˜ëŒ€ê¸ˆ(ì–µ)'] = df_display['ê±°ë˜ëŒ€ê¸ˆ(ì–µ)'].round(0)
        
        st.dataframe(
            df_display,
            width='stretch',
            hide_index=True,
            height=min(400, 40 + len(df_display) * 35),
        )
        
        # ë“±ê¸‰ë³„ í†µê³„
        if 'grade' in df_top5.columns:
            st.markdown("**ë“±ê¸‰ ë¶„í¬:**")
            grade_counts = df_top5['grade'].value_counts().sort_index()
            cols = st.columns(len(grade_counts))
            for i, (grade, count) in enumerate(grade_counts.items()):
                with cols[i]:
                    emoji = {"S": "ğŸ†", "A": "ğŸ¥‡", "B": "ğŸ¥ˆ", "C": "ğŸ¥‰", "D": "âš ï¸"}.get(grade, "")
                    st.write(f"{emoji} {grade}ë“±ê¸‰: **{count}íšŒ**")
    
    elif show_top5:
        st.info("ğŸ† TOP5 ì¶œí˜„ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ============================================================
    # ìœ ëª©ë¯¼ íˆìŠ¤í† ë¦¬ í…Œì´ë¸”
    # ============================================================
    if show_nomad and not df_nomad.empty:
        st.markdown("---")
        st.subheader("ğŸ“š ìœ ëª©ë¯¼ ì¶œí˜„ ì´ë ¥")
        
        # ì»¬ëŸ¼ ì„ íƒ ë° í¬ë§·
        display_cols = ['study_date', 'stock_code', 'stock_name', 
                       'candidate_type', 'change_rate', 'score']
        
        available_cols = [c for c in display_cols if c in df_nomad.columns]
        df_display = df_nomad[available_cols].copy()
        
        # ì»¬ëŸ¼ëª… í•œê¸€í™”
        col_names = {
            'study_date': 'ë‚ ì§œ',
            'stock_code': 'ì¢…ëª©ì½”ë“œ',
            'stock_name': 'ì¢…ëª©ëª…',
            'candidate_type': 'ìœ í˜•',
            'change_rate': 'ë“±ë½ë¥ (%)',
            'score': 'ì ìˆ˜',
        }
        df_display = df_display.rename(columns=col_names)
        
        # ë‚ ì§œ ì •ë ¬ (ìµœì‹ ìˆœ)
        if 'ë‚ ì§œ' in df_display.columns:
            df_display = df_display.sort_values('ë‚ ì§œ', ascending=False)
        
        # ìœ í˜• í•œê¸€í™”
        if 'ìœ í˜•' in df_display.columns:
            type_map = {
                'limit_up': 'ğŸ”´ ìƒí•œê°€',
                'volume_explosion': 'ğŸŸ¡ ê±°ë˜ëŸ‰ì²œë§Œ',
            }
            df_display['ìœ í˜•'] = df_display['ìœ í˜•'].map(type_map).fillna(df_display['ìœ í˜•'])
        
        st.dataframe(
            df_display,
            width='stretch',
            hide_index=True,
            height=min(400, 40 + len(df_display) * 35),
        )
        
        # ìœ í˜•ë³„ í†µê³„
        if 'candidate_type' in df_nomad.columns:
            st.markdown("**ìœ í˜• ë¶„í¬:**")
            type_counts = df_nomad['candidate_type'].value_counts()
            cols = st.columns(len(type_counts))
            for i, (ctype, count) in enumerate(type_counts.items()):
                with cols[i]:
                    emoji = "ğŸ”´" if ctype == "limit_up" else "ğŸŸ¡"
                    label = "ìƒí•œê°€" if ctype == "limit_up" else "ê±°ë˜ëŸ‰ì²œë§Œ"
                    st.write(f"{emoji} {label}: **{count}íšŒ**")
    
    elif show_nomad:
        st.info("ğŸ“š ìœ ëª©ë¯¼ ì¶œí˜„ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ============================================================
    # ìˆ˜ìµë¥  ìš”ì•½ (TOP5ë§Œ, D+1~D+20 ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
    # ============================================================
    if show_top5 and not df_top5.empty:
        st.markdown("---")
        st.subheader("ğŸ“ˆ ìˆ˜ìµë¥  ìš”ì•½ (D+1 ~ D+20)")
        
        # D+1 ìˆ˜ìµë¥  ì¡°íšŒ ì‹œë„
        try:
            from src.infrastructure.repository import get_top5_prices_repository
            prices_repo = get_top5_prices_repository()
            
            # ê° TOP5 ê¸°ë¡ì˜ ìˆ˜ìµë¥  ì¡°íšŒ
            returns_data = []
            for _, row in df_top5.iterrows():
                if 'id' not in row:
                    continue
                    
                history_id = row['id']
                prices = prices_repo.get_by_history_id(history_id)
                
                if prices:
                    d1 = next((p for p in prices if p.get('day_number') == 1), None)
                    d5 = next((p for p in prices if p.get('day_number') == 5), None)
                    d20 = next((p for p in prices if p.get('day_number') == 20), None)
                    
                    returns_data.append({
                        'date': row.get('screen_date'),
                        'name': row.get('stock_name'),
                        'd1': d1.get('return_rate') if d1 else None,
                        'd5': d5.get('return_rate') if d5 else None,
                        'd20': d20.get('return_rate') if d20 else None,
                    })
            
            if returns_data:
                df_returns = pd.DataFrame(returns_data)
                
                # í‰ê·  ìˆ˜ìµë¥  ê³„ì‚°
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    d1_avg = df_returns['d1'].dropna().mean()
                    d1_win = (df_returns['d1'].dropna() > 0).mean() * 100
                    st.metric(
                        "D+1 í‰ê· ", 
                        f"{d1_avg:.2f}%" if pd.notna(d1_avg) else "-",
                        f"ìŠ¹ë¥  {d1_win:.0f}%" if pd.notna(d1_win) else None
                    )
                
                with col2:
                    d5_avg = df_returns['d5'].dropna().mean()
                    d5_win = (df_returns['d5'].dropna() > 0).mean() * 100
                    st.metric(
                        "D+5 í‰ê· ", 
                        f"{d5_avg:.2f}%" if pd.notna(d5_avg) else "-",
                        f"ìŠ¹ë¥  {d5_win:.0f}%" if pd.notna(d5_win) else None
                    )
                
                with col3:
                    d20_avg = df_returns['d20'].dropna().mean()
                    d20_win = (df_returns['d20'].dropna() > 0).mean() * 100
                    st.metric(
                        "D+20 í‰ê· ", 
                        f"{d20_avg:.2f}%" if pd.notna(d20_avg) else "-",
                        f"ìŠ¹ë¥  {d20_win:.0f}%" if pd.notna(d20_win) else None
                    )
                
                with col4:
                    total_samples = len(df_returns['d1'].dropna())
                    st.metric("ìƒ˜í”Œ ìˆ˜", f"{total_samples}ê±´")
            else:
                st.info("ìˆ˜ìµë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (D+1~D+20 ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ í•„ìš”)")
                
        except Exception as e:
            st.info(f"ìˆ˜ìµë¥  ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    # ============================================================
    # ì°¨íŠ¸ (OHLCV ê¸°ë°˜)
    # ============================================================
    st.markdown("---")
    st.subheader("ğŸ“Š ì°¨íŠ¸")
    
    # ê²€ìƒ‰ëœ ì¢…ëª© ì¤‘ ì²« ë²ˆì§¸ ì¢…ëª© ì½”ë“œë¡œ ì°¨íŠ¸ í‘œì‹œ
    chart_code = None
    chart_name = None
    highlight_dates = []
    
    if not df_top5.empty:
        chart_code = df_top5.iloc[0].get('stock_code')
        chart_name = df_top5.iloc[0].get('stock_name', chart_code)
        highlight_dates = pd.to_datetime(df_top5['screen_date']).tolist()
    elif not df_nomad.empty:
        chart_code = df_nomad.iloc[0].get('stock_code')
        chart_name = df_nomad.iloc[0].get('stock_name', chart_code)
        highlight_dates = pd.to_datetime(df_nomad['study_date']).tolist()
    
    if chart_code:
        ohlcv_df = load_ohlcv(chart_code, days=60)
        
        if ohlcv_df is not None and not ohlcv_df.empty:
            fig = create_candlestick_chart(ohlcv_df, chart_name, highlight_dates)
            if fig:
                st.plotly_chart(fig, width='stretch')
                st.caption("ğŸŸ  ì ì„ : TOP5/ìœ ëª©ë¯¼ ì¶œí˜„ì¼")
            else:
                st.warning("ì°¨íŠ¸ í‘œì‹œì— plotlyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            st.info(f"ğŸ“ OHLCV ë°ì´í„° ì—†ìŒ: {chart_code}")
            st.caption(f"ê²½ë¡œ: {OHLCV_PATH / f'{chart_code}.csv'}")

else:
    # ê²€ìƒ‰ì–´ ë¯¸ì…ë ¥ ì‹œ ì•ˆë‚´
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ **ì¢…ëª©ì½”ë“œ ë˜ëŠ” ì¢…ëª©ëª…**ì„ ì…ë ¥í•˜ì„¸ìš” (2ê¸€ì ì´ìƒ)")
    
    # ìµœê·¼ TOP5 ìš”ì•½
    st.markdown("---")
    st.subheader("ğŸ“Š ìµœê·¼ TOP5 ìš”ì•½")
    
    try:
        recent_dates = repos['top5'].get_dates_with_data(days=5)
        
        if recent_dates:
            for d in recent_dates[:3]:
                top5 = repos['top5'].get_by_date(d)
                if top5:
                    names = [f"{t.get('stock_name', '?')} ({t.get('grade', '?')})" for t in top5[:5]]
                    st.write(f"**{d}**: {', '.join(names)}")
        else:
            st.info("TOP5 ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.error(f"ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")


# í‘¸í„°
st.markdown("---")
st.caption(FOOTER_SEARCH)
