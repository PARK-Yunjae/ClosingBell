"""ëˆŒë¦¼ëª©(ê±°ê°ìŒë´‰) ìŠ¤ìºë„ˆ ëŒ€ì‹œë³´ë“œ - ClosingBell v9.1

ê±°ë˜ëŸ‰ í­ë°œ ê°ì‹œ â†’ ëˆŒë¦¼ëª© ì‹œê·¸ë„ ëª¨ë‹ˆí„°ë§ + ìº”ë“¤ì°¨íŠ¸
"""

import os
import sys
import streamlit as st
from datetime import date, datetime, timedelta

# â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€
_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if _root not in sys.path:
    sys.path.insert(0, _root)

from dashboard.components.sidebar import render_sidebar_nav

try:
    import pandas as pd
except ImportError:
    pd = None

try:
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False

# â”€â”€ í˜ì´ì§€ ì„¤ì • â”€â”€
st.set_page_config(page_title="ëˆŒë¦¼ëª© ìŠ¤ìºë„ˆ", page_icon="ğŸ“‰", layout="wide")

with st.sidebar:
    render_sidebar_nav()

st.title("ğŸ“‰ ëˆŒë¦¼ëª© ìŠ¤ìºë„ˆ")
st.caption("ClosingBell v10.1 | ê±°ë˜ëŸ‰ í­ë°œ í›„ ê±°ê°ìŒë´‰ + MA ì§€ì§€ ì¢…ëª© ê°ì‹œ")


# ============================================================
# ì¢…ëª©ëª… ë§¤í•‘ (stock_mapping.csv â†’ FDR í´ë°±)
# ============================================================

@st.cache_data(ttl=86400)
def _load_names() -> dict:
    """ì¢…ëª©ì½”ë“œ â†’ ì¢…ëª©ëª… ë§¤í•‘"""
    names = {}

    # 1) stock_mapping.csv
    try:
        from src.config.app_config import MAPPING_FILE
        if MAPPING_FILE and MAPPING_FILE.exists():
            import csv
            with open(MAPPING_FILE, "r", encoding="utf-8-sig") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    code = str(row.get("code", "")).strip().zfill(6)
                    name = row.get("name", "").strip()
                    if code and name:
                        names[code] = name
    except Exception:
        pass

    # 2) FDR ë¦¬ìŠ¤íŒ… (Streamlit Cloud í´ë°±)
    if len(names) < 100:
        try:
            import FinanceDataReader as fdr
            for market in ["KOSPI", "KOSDAQ"]:
                listing = fdr.StockListing(market)
                if listing is not None and not listing.empty:
                    for _, row in listing.iterrows():
                        code = str(row.get("Code", "")).strip().zfill(6)
                        name = str(row.get("Name", "")).strip()
                        if code and name and code not in names:
                            names[code] = name
        except Exception:
            pass

    return names


def _name(code: str, db_name: str, names: dict) -> str:
    """ì¢…ëª©ëª… í•´ê²°: DBê°’ â†’ ë§¤í•‘ â†’ ì½”ë“œ ê·¸ëŒ€ë¡œ"""
    if db_name and db_name != code and not db_name.isdigit():
        return db_name
    return names.get(code, code)


# ============================================================
# FDR OHLCV + ë¯¸ë‹ˆ ìº”ë“¤ì°¨íŠ¸
# ============================================================

@st.cache_data(ttl=3600, show_spinner=False)
def _fetch_ohlcv(code: str, days: int = 60):
    """OHLCV ì¡°íšŒ: ë¡œì»¬ CSV â†’ FDR í´ë°±"""
    if pd is None:
        return None

    # 1) ë¡œì»¬ CSV
    try:
        from src.config.app_config import OHLCV_DIR, OHLCV_FULL_DIR
        from pathlib import Path
        for d in [OHLCV_DIR, OHLCV_FULL_DIR]:
            if d:
                for fname in [f"{code}.csv", f"A{code}.csv"]:
                    p = Path(d) / fname
                    if p.exists():
                        from src.services.backfill.data_loader import load_single_ohlcv
                        df = load_single_ohlcv(p)
                        if df is not None and not df.empty:
                            return df.tail(days)
    except Exception:
        pass

    # 2) FDR (Cloud)
    try:
        import FinanceDataReader as fdr
        end = datetime.now().date()
        start = end - timedelta(days=days * 2)
        df = fdr.DataReader(code, start.strftime("%Y-%m-%d"), end.strftime("%Y-%m-%d"))
        if df is not None and not df.empty:
            df = df.reset_index()
            df.columns = [c.lower() for c in df.columns]
            if "date" not in df.columns:
                df = df.rename(columns={"index": "date"})
            return df.tail(days)
    except Exception:
        pass

    return None


def _draw_mini_chart(code: str, spike_date: str = "", signal_date: str = ""):
    """ì¢…ëª©ë³„ ë¯¸ë‹ˆ ìº”ë“¤ì°¨íŠ¸ (60ì¼) + í­ë°œì¼/ì‹œê·¸ë„ì¼ ë§ˆì»¤"""
    if not HAS_PLOTLY or pd is None:
        return

    df = _fetch_ohlcv(code, 60)
    if df is None or len(df) < 5:
        st.caption("ğŸ“Š ì°¨íŠ¸ ë°ì´í„° ì—†ìŒ")
        return

    df["date"] = pd.to_datetime(df["date"])
    view = df.copy()

    # ë¹„ì •ìƒ ë´‰ ì²˜ë¦¬
    if len(view) > 1:
        prev_close = view["close"].shift(1)
        spread = (view["high"] - view["low"]).abs()
        abnormal = (spread / prev_close.clip(lower=1)) > 0.30
        view.loc[abnormal, "open"] = view.loc[abnormal, "close"]
        view.loc[abnormal, "high"] = view.loc[abnormal, "close"]
        view.loc[abnormal, "low"] = view.loc[abnormal, "close"]

    fig = make_subplots(
        rows=2, cols=1, shared_xaxes=True,
        row_heights=[0.7, 0.3], vertical_spacing=0.06,
    )

    # ìº”ë“¤ìŠ¤í‹±
    fig.add_trace(go.Candlestick(
        x=view["date"], open=view["open"],
        high=view["high"], low=view["low"], close=view["close"],
        name="ì£¼ê°€",
        increasing_line_color="#e74c3c",
        decreasing_line_color="#3498db",
    ), row=1, col=1)

    # 5ì¼ì„ , 20ì¼ì„ 
    for ma_days, color, label in [(5, "#ff9800", "5ì¼ì„ "), (20, "#2196f3", "20ì¼ì„ ")]:
        if len(view) >= ma_days:
            ma = view["close"].rolling(ma_days).mean()
            fig.add_trace(go.Scatter(
                x=view["date"], y=ma,
                mode="lines", name=label,
                line=dict(color=color, width=1),
            ), row=1, col=1)

    # ê±°ë˜ëŸ‰
    colors = ["#e74c3c" if c >= o else "#3498db"
              for c, o in zip(view["close"], view["open"])]
    fig.add_trace(go.Bar(
        x=view["date"], y=view["volume"],
        name="ê±°ë˜ëŸ‰", marker_color=colors,
    ), row=2, col=1)

    # í­ë°œì¼ / ì‹œê·¸ë„ì¼ ì„¸ë¡œì„ 
    for d_str, label, clr in [
        (spike_date, "ğŸ”¥í­ë°œ", "red"),
        (signal_date, "ğŸ“‰ì‹œê·¸ë„", "orange"),
    ]:
        if d_str:
            try:
                dt = pd.to_datetime(d_str)
                if dt >= view["date"].min() and dt <= view["date"].max():
                    fig.add_vline(
                        x=dt, line_dash="dot", line_color=clr,
                        annotation_text=label,
                        annotation_position="top left",
                    )
            except Exception:
                pass

    fig.update_layout(
        height=320,
        showlegend=False,
        xaxis_rangeslider_visible=False,
        margin=dict(l=10, r=10, t=10, b=10),
    )
    fig.update_xaxes(dtick="M1", tickformat="%m/%d", row=2, col=1)
    fig.update_xaxes(rangebreaks=[dict(bounds=["sat", "mon"])])

    st.plotly_chart(fig, width="stretch")


# ============================================================
# Repository
# ============================================================

@st.cache_resource
def _get_repo():
    try:
        from src.infrastructure.database import get_database
        db = get_database()
        # í…Œì´ë¸” ì—†ìœ¼ë©´ ìë™ ìƒì„±
        try:
            db.run_migration_v91_pullback()
        except AttributeError:
            # database.pyì— ë©”ì„œë“œ ì—†ìœ¼ë©´ ì§ì ‘ ìƒì„±
            db.execute("""CREATE TABLE IF NOT EXISTS volume_spikes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                stock_code TEXT NOT NULL, stock_name TEXT NOT NULL,
                spike_date DATE NOT NULL, spike_volume INTEGER NOT NULL,
                volume_ma20 INTEGER DEFAULT 0, spike_ratio REAL DEFAULT 0,
                open_price REAL DEFAULT 0, high_price REAL DEFAULT 0,
                low_price REAL DEFAULT 0, close_price REAL DEFAULT 0,
                change_pct REAL DEFAULT 0, sector TEXT DEFAULT '',
                theme TEXT DEFAULT '', is_leading_sector INTEGER DEFAULT 0,
                status TEXT DEFAULT 'watching',
                created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(spike_date, stock_code))""")
            db.execute("""CREATE TABLE IF NOT EXISTS pullback_signals (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                stock_code TEXT NOT NULL, stock_name TEXT NOT NULL,
                spike_date DATE NOT NULL, signal_date DATE NOT NULL,
                days_after INTEGER DEFAULT 0, close_price REAL DEFAULT 0,
                open_price REAL DEFAULT 0, spike_high REAL DEFAULT 0,
                drop_from_high_pct REAL DEFAULT 0, today_volume INTEGER DEFAULT 0,
                spike_volume INTEGER DEFAULT 0, vol_decrease_pct REAL DEFAULT 0,
                ma5 REAL DEFAULT 0, ma20 REAL DEFAULT 0,
                ma_support TEXT DEFAULT '', ma_distance_pct REAL DEFAULT 0,
                is_negative_candle INTEGER DEFAULT 0, sector TEXT DEFAULT '',
                is_leading_sector INTEGER DEFAULT 0, has_recent_news INTEGER DEFAULT 0,
                signal_strength TEXT DEFAULT '', reason TEXT DEFAULT '',
                created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(signal_date, stock_code))""")
        except Exception:
            pass
        from src.infrastructure.repository import get_pullback_repository
        return get_pullback_repository()
    except Exception as e:
        st.error(f"Repository ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


repo = _get_repo()
names = _load_names()

if repo is None:
    st.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
    st.stop()

# â”€â”€ ë‚ ì§œ ì„ íƒ â”€â”€
col_date, col_range = st.columns([1, 1])
with col_date:
    sel_date = st.date_input("ê¸°ì¤€ì¼", value=date.today())
with col_range:
    history_days = st.selectbox("ì¡°íšŒ ê¸°ê°„", [3, 7, 14, 30], index=1, format_func=lambda x: f"ìµœê·¼ {x}ì¼")

# íœ´ì¥ì¼ ë³´ì •
try:
    from src.utils.market_calendar import is_market_open
    if not is_market_open(sel_date):
        corrected = sel_date
        for _ in range(10):
            corrected -= timedelta(days=1)
            if is_market_open(corrected):
                break
        weekday_kr = ['ì›”','í™”','ìˆ˜','ëª©','ê¸ˆ','í† ','ì¼'][sel_date.weekday()]
        st.caption(f"âš ï¸ {sel_date.strftime('%m/%d')}({weekday_kr}) íœ´ì¥ì¼ â†’ {corrected.strftime('%m/%d')} í‘œì‹œ")
        sel_date = corrected
except ImportError:
    pass

date_str = sel_date.strftime("%Y-%m-%d")


# ============================================================
# ì„¹ì…˜ 1: ëˆŒë¦¼ëª© ì‹œê·¸ë„ + ì°¨íŠ¸
# ============================================================

st.markdown("---")
st.subheader("ğŸ¯ ëˆŒë¦¼ëª© ì‹œê·¸ë„")

try:
    today_signals = repo.get_signals_by_date(date_str)
except Exception:
    today_signals = []

# v10.1: S/R + ê³µë§¤ë„ ì¡°íšŒìš© DB
try:
    from src.infrastructure.database import get_database
    _pb_db = get_database()
except Exception:
    _pb_db = None

if not today_signals:
    st.info(f"{date_str}ì˜ ëˆŒë¦¼ëª© ì‹œê·¸ë„ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    for sig in today_signals:
        row = dict(sig) if not isinstance(sig, dict) else sig
        strength = row.get("signal_strength", "")
        emoji = {"ê°•": "ğŸ”´", "ì¤‘": "ğŸŸ ", "ì•½": "ğŸŸ¡"}.get(strength, "âšª")
        code = row.get("stock_code", "")
        stock_name = _name(code, row.get("stock_name", ""), names)
        close = float(row.get("close_price", 0))
        drop_pct = float(row.get("drop_from_high_pct", 0))
        vol_pct = float(row.get("vol_decrease_pct", 0))
        ma_sup = row.get("ma_support", "")
        ma_dist = float(row.get("ma_distance_pct", 0))
        days_after = row.get("days_after", 0)
        spike_date = row.get("spike_date", "")
        reason = row.get("reason", "")
        sector = row.get("sector", "")
        is_leading = bool(row.get("is_leading_sector", 0))
        has_news = bool(row.get("has_recent_news", 0))

        with st.expander(
            f"{emoji} **{stock_name}** ({code}) | D+{days_after} | ì¢…ê°€ {close:,.0f}ì› | ì‹œê·¸ë„: {strength}",
            expanded=True,
        ):
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("ì¢…ê°€", f"{close:,.0f}ì›")
            c2.metric("ê³ ì  ëŒ€ë¹„", f"-{drop_pct:.1f}%")
            c3.metric("ê±°ë˜ëŸ‰ ë¹„ìœ¨", f"{vol_pct * 100:.0f}%", help="í­ë°œì¼ ëŒ€ë¹„")
            c4.metric("MA ì§€ì§€", f"{ma_sup} ({ma_dist:.1f}%)")

            # ì„¹í„°/ì¬ë£Œ
            info_cols = st.columns(3)
            sector_icon = "ğŸ”¥ ì£¼ë„ì„¹í„°" if is_leading else "ğŸ“‚ ì„¹í„°"
            info_cols[0].caption(f"{sector_icon}: {sector or '-'}")

            # ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ì¶”ì¶œ
            news_label = "âŒ ì—†ìŒ"
            if has_news and reason and "ğŸ“°" in reason:
                headline = reason.split("ğŸ“°")[-1].strip().split(" | ")[0].strip()
                if headline and headline != "ì¬ë£Œì—†ìŒ":
                    if len(headline) > 30:
                        headline = headline[:27] + "..."
                    news_label = f"âœ… {headline}"
                else:
                    news_label = "âœ… ì‚´ì•„ìˆìŒ"
            elif has_news:
                news_label = "âœ… ì‚´ì•„ìˆìŒ"
            info_cols[1].caption(f"ğŸ“° ì¬ë£Œ: {news_label}")
            info_cols[2].caption(f"ğŸ“… í­ë°œì¼: {spike_date}")

            if reason:
                st.caption(f"ğŸ’¡ {reason}")

            # v10.1: ì§€ì§€/ì €í•­ + ê³µë§¤ë„ í‘œì‹œ
            try:
                if not _pb_db:
                    raise Exception("no db")
                sr_row = _pb_db.fetch_one(
                    "SELECT nearest_support, nearest_resistance, support_distance_pct, "
                    "resistance_distance_pct, score, summary "
                    "FROM support_resistance_cache WHERE stock_code = ? "
                    "ORDER BY date DESC LIMIT 1", (code,)
                )
                ss_row = _pb_db.fetch_one(
                    "SELECT short_ratio, short_volume, trade_volume "
                    "FROM short_selling_daily WHERE stock_code = ? "
                    "ORDER BY date DESC LIMIT 1", (code,)
                )
                if sr_row or ss_row:
                    sr_cols = st.columns(3)
                    if sr_row:
                        sr = dict(sr_row)
                        sup = sr.get("nearest_support", 0)
                        res = sr.get("nearest_resistance", 0)
                        if sup:
                            sr_cols[0].caption(f"ğŸŸ¢ ì§€ì§€: {sup:,.0f}ì› ({sr.get('support_distance_pct', 0):.1f}%â†“)")
                        if res:
                            sr_cols[1].caption(f"ğŸ”´ ì €í•­: {res:,.0f}ì› ({sr.get('resistance_distance_pct', 0):.1f}%â†‘)")
                    if ss_row:
                        ss = dict(ss_row)
                        short_r = ss.get("short_ratio", 0) or 0
                        short_emoji = "ğŸ”´" if short_r >= 5 else ("ğŸŸ¡" if short_r >= 2 else "ğŸŸ¢")
                        sr_cols[2].caption(f"ğŸ“‰ ê³µë§¤ë„: {short_r:.1f}% {short_emoji}")
            except Exception:
                pass  # í…Œì´ë¸” ë¯¸ì¡´ì¬ì‹œ ë¬´ì‹œ

            # AI ë¶„ì„
            ai_comment = row.get("ai_comment", "")
            if ai_comment:
                with st.container():
                    st.markdown(f"ğŸ¤– **AI ë¶„ì„**")
                    for line in ai_comment.split('\n'):
                        line = line.strip()
                        if line:
                            st.caption(line)

            # ë¯¸ë‹ˆ ì°¨íŠ¸
            _draw_mini_chart(code, spike_date=spike_date, signal_date=date_str)


# ============================================================
# ì„¹ì…˜ 2: ê±°ë˜ëŸ‰ í­ë°œ ê°ì‹œí’€
# ============================================================

st.markdown("---")
st.subheader("ğŸ”¥ ê±°ë˜ëŸ‰ í­ë°œ ê°ì‹œí’€")

try:
    spikes = repo.get_recent_spikes(days=history_days)
except Exception:
    spikes = []

if not spikes:
    st.info(f"ìµœê·¼ {history_days}ì¼ê°„ ê±°ë˜ëŸ‰ í­ë°œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    if pd is not None:
        spike_data = []
        for s in spikes:
            r = dict(s) if not isinstance(s, dict) else s
            code = r.get("stock_code", "")
            spike_data.append({
                "í­ë°œì¼": r.get("spike_date", ""),
                "ì¢…ëª©ëª…": _name(code, r.get("stock_name", ""), names),
                "ì¢…ëª©ì½”ë“œ": code,
                "ì„¹í„°": r.get("sector", "") or "-",
                "ê±°ë˜ëŸ‰": f"{int(r.get('spike_volume', 0)):,}",
                "MA20 ëŒ€ë¹„": f"{float(r.get('spike_ratio', 0)):.1f}ë°°",
                "ë“±ë½ë¥ ": f"{float(r.get('change_pct', 0)):+.1f}%",
                "ì¢…ê°€": f"{float(r.get('close_price', 0)):,.0f}",
                "ì£¼ë„": "ğŸ”¥" if r.get("is_leading_sector") else "",
            })
        df_spikes = pd.DataFrame(spike_data)
        st.dataframe(df_spikes, width="stretch", hide_index=True)

    # ê°ì‹œí’€ ì°¨íŠ¸ (ì ‘ê¸°)
    if HAS_PLOTLY:
        with st.expander("ğŸ“Š ê°ì‹œí’€ ì¢…ëª© ì°¨íŠ¸ ë³´ê¸°", expanded=False):
            chart_cols = st.columns(2)
            for i, s in enumerate(spikes[:6]):
                r = dict(s) if not isinstance(s, dict) else s
                code = r.get("stock_code", "")
                stock_name = _name(code, r.get("stock_name", ""), names)
                with chart_cols[i % 2]:
                    st.caption(f"**{stock_name}** ({code})")
                    _draw_mini_chart(code, spike_date=r.get("spike_date", ""))


# ============================================================
# ì„¹ì…˜ 3: ì‹œê·¸ë„ íˆìŠ¤í† ë¦¬
# ============================================================

st.markdown("---")
st.subheader("ğŸ“‹ ì‹œê·¸ë„ íˆìŠ¤í† ë¦¬")

try:
    history = repo.get_signals_with_spikes(days=history_days)
except Exception:
    history = []

if not history:
    st.info(f"ìµœê·¼ {history_days}ì¼ê°„ ëˆŒë¦¼ëª© ì‹œê·¸ë„ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    if pd is not None:
        hist_data = []
        for h in history:
            r = dict(h) if not isinstance(h, dict) else h
            strength = r.get("signal_strength", "")
            emoji = {"ê°•": "ğŸ”´", "ì¤‘": "ğŸŸ ", "ì•½": "ğŸŸ¡"}.get(strength, "âšª")
            code = r.get("stock_code", "")
            hist_data.append({
                "ì‹œê·¸ë„ì¼": r.get("signal_date", ""),
                "ê°•ë„": f"{emoji} {strength}",
                "ì¢…ëª©ëª…": _name(code, r.get("stock_name", ""), names),
                "ì¢…ëª©ì½”ë“œ": code,
                "D+N": f"D+{r.get('days_after', 0)}",
                "ì¢…ê°€": f"{float(r.get('close_price', 0)):,.0f}",
                "ê³ ì ëŒ€ë¹„": f"-{float(r.get('drop_from_high_pct', 0)):.1f}%",
                "ê±°ê°ë¥ ": f"{float(r.get('vol_decrease_pct', 0)) * 100:.0f}%",
                "MAì§€ì§€": r.get("ma_support", ""),
                "ì„¹í„°": r.get("sector", "") or "-",
                "ì¬ë£Œ": "âœ…" if r.get("has_recent_news") else "âŒ",
                "í­ë°œì¼": r.get("spike_date", ""),
            })
        df_hist = pd.DataFrame(hist_data)
        st.dataframe(df_hist, width="stretch", hide_index=True)


# ============================================================
# ì„¹ì…˜ 4: í†µê³„ ì°¨íŠ¸
# ============================================================

if HAS_PLOTLY and spikes and pd is not None:
    st.markdown("---")
    st.subheader("ğŸ“Š ê±°ë˜ëŸ‰ í­ë°œ ì¼ë³„ ë¶„í¬")

    spike_dates = {}
    for s in spikes:
        r = dict(s) if not isinstance(s, dict) else s
        d = r.get("spike_date", "")
        spike_dates[d] = spike_dates.get(d, 0) + 1

    if spike_dates:
        fig = go.Figure(data=[go.Bar(
            x=list(spike_dates.keys()),
            y=list(spike_dates.values()),
            marker_color="#ff6b35",
            text=list(spike_dates.values()),
            textposition="outside",
        )])
        fig.update_layout(
            height=250,
            xaxis_title="ë‚ ì§œ", yaxis_title="ì¢…ëª© ìˆ˜",
            margin=dict(l=10, r=10, t=10, b=10),
        )
        st.plotly_chart(fig, width="stretch")


# â”€â”€ D+1~D+5 ì„±ê³¼ ì¶”ì  â”€â”€
st.markdown("---")
st.subheader("ğŸ“Š ëˆŒë¦¼ëª© D+1~D+5 ì„±ê³¼")
st.caption("ì‹œê·¸ë„ ë°œìƒ í›„ ì‹¤ì œ ìˆ˜ìµë¥  ì¶”ì  (OHLCV ê¸°ë°˜, ë§¤ì¼ 16:07 ìë™ ê°±ì‹ )")

try:
    from src.services.pullback_tracker import get_pullback_performance

    perf_days = st.selectbox("ë¶„ì„ ê¸°ê°„", [7, 14, 30, 90], index=2,
                             format_func=lambda x: f"ìµœê·¼ {x}ì¼", key="pb_perf")
    perf = get_pullback_performance(days=perf_days)

    if perf.get("tracked_signals", 0) > 0:
        st.markdown(f"**ì¶”ì  ì‹œê·¸ë„: {perf['tracked_signals']}ê°œ** / ì „ì²´ {perf['total_signals']}ê°œ")

        # D+1 ~ D+5 ì „ì²´ í†µê³„
        d_cols = st.columns(5)
        for i in range(1, 6):
            d_stat = perf.get(f"d{i}", {})
            with d_cols[i - 1]:
                avg = d_stat.get("avg", 0)
                wr = d_stat.get("win_rate", 0)
                n = d_stat.get("n", 0)
                color = "normal" if avg > 0 else "inverse"
                st.metric(
                    f"D+{i}",
                    f"{avg:+.2f}%",
                    delta=f"ìŠ¹ë¥  {wr:.0f}% ({n}ê±´)",
                    delta_color=color,
                )

        # ì‹œê·¸ë„ ê°•ë„ë³„ ë¹„êµ
        by_str = perf.get("by_strength", {})
        if by_str:
            st.markdown("**ì‹œê·¸ë„ ê°•ë„ë³„ D+1 ì„±ê³¼:**")
            str_cols = st.columns(len(by_str))
            for i, (strength, data) in enumerate(sorted(by_str.items())):
                with str_cols[i]:
                    emoji = {"ê°•": "ğŸ”´", "ì¤‘": "ğŸŸ ", "ì•½": "ğŸŸ¡"}.get(strength, "âšª")
                    d1 = data.get("d1", {})
                    d5 = data.get("d5", {})
                    st.markdown(f"**{emoji} {strength}**")
                    st.write(f"D+1: {d1.get('avg', 0):+.2f}% (ìŠ¹ë¥  {d1.get('win_rate', 0):.0f}%)")
                    st.write(f"D+5: {d5.get('avg', 0):+.2f}% (ìŠ¹ë¥  {d5.get('win_rate', 0):.0f}%)")
    else:
        st.info("ğŸ“Š ì•„ì§ ì¶”ì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œê·¸ë„ ë°œìƒ ë‹¤ìŒ ê±°ë˜ì¼ë¶€í„° ìë™ ìˆ˜ì§‘ë©ë‹ˆë‹¤.")

except ImportError:
    st.info("pullback_tracker ëª¨ë“ˆ ë¯¸ì„¤ì¹˜ - D+1~D+5 ì¶”ì  ë¹„í™œì„±")
except Exception as e:
    st.warning(f"ì„±ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")


# â”€â”€ ì¡°ê±´ ì•ˆë‚´ â”€â”€
st.markdown("---")
with st.expander("ğŸ“– ìŠ¤ìºë‹ ì¡°ê±´ ìƒì„¸"):
    st.markdown("""
**1ë‹¨ê³„: ê±°ë˜ëŸ‰ í­ë°œ ê°ì§€** (ë§¤ì¼ 16:05)
- ë‹¹ì¼ ê±°ë˜ëŸ‰ â‰¥ **1,000ë§Œì£¼**
- 20ì¼ ì´ë™í‰ê·  ëŒ€ë¹„ **3ë°° ì´ìƒ**
- ê°ì‹œí’€ì— ë“±ë¡, D+1 ~ D+3ê¹Œì§€ ëª¨ë‹ˆí„°ë§

**2ë‹¨ê³„: ëˆŒë¦¼ëª© ì‹œê·¸ë„** (ë§¤ì¼ 14:55)
- ê±°ë˜ëŸ‰ ê¸‰ê°: í­ë°œì¼ ëŒ€ë¹„ **20% ì´í•˜** (80%+ ê°ì†Œ)
- **ìŒë´‰** (ì¢…ê°€ < ì‹œê°€)
- **5ì¼ì„  or 20ì¼ì„ ** Â±2% ì´ë‚´
- ê³ ì  ëŒ€ë¹„ ë‚™í­ **15% ì´ë‚´**

**ì‹œê·¸ë„ ê°•ë„**
- ğŸ”´ **ê°•**: ê±°ë˜ëŸ‰ 85%â†‘ ê¸‰ê° + ê³ ì  ê·¼ì ‘ (5% ì´ë‚´)
- ğŸŸ  **ì¤‘**: ê¸°ë³¸ ì¡°ê±´ ì¶©ì¡±
- ğŸŸ¡ **ì•½**: ê²½ê³„ì„  ì¡°ê±´

**Enrichment**
- ğŸ“‚ ì„¹í„°: stock_mapping.csv â†’ FDR ë¦¬ìŠ¤íŒ…
- ğŸ”¥ ì£¼ë„ì„¹í„°: sector_service íŒë³„
- ğŸ“° ì¬ë£Œ: ë„¤ì´ë²„ ë‰´ìŠ¤ ìµœê·¼ 3ì¼
- ğŸ¢ ê¸°ì—…: DART í”„ë¡œí•„ (ë§¤ì¶œ/ìœ„í—˜ë„)

**ë””ìŠ¤ì½”ë“œ ì•Œë¦¼**: ì‹œê·¸ë„ ë°œìƒ ì‹œ ìë™ ì›¹í›… ë°œì†¡
""")

st.caption("ClosingBell v10.1")