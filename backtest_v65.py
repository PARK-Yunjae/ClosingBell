"""
ClosingBell v6.5 ë°±í…ŒìŠ¤íŒ… ì‹œë®¬ë ˆì´ì…˜ (ê³ ì„±ëŠ¥ ë²„ì „)

ì „ëµ:
- í•„í„°: ê±°ë˜ëŒ€ê¸ˆ 150ì–µ+, ê±°ë˜ëŸ‰ TOP 150, ë“±ë½ë¥  1~29%
- ì ìˆ˜: v6.5 êµ¬ê°„ ìµœì í™” (100ì  ë§Œì )

v6.5 ì ìˆ˜ ì²´ê³„ (êµ¬ê°„ ìµœì í™”):
- CCI: 160~180 ë§Œì , 180+ ê°ì 
- ë“±ë½ë¥ : 4~6% ë§Œì , 8%+ ê°ì   
- ì´ê²©ë„: 2~8% ë§Œì , 15%+ ê°ì 
- ì—°ì†ì–‘ë´‰: 1~3ì¼ ë§Œì , 5ì¼+ ê¸‰ê°ì 

ì„±ëŠ¥ ìµœì í™”:
- CPU 90% í™œìš© (ìë™ ê°ì§€)
- ë©€í‹°ìŠ¤ë ˆë”© ë°ì´í„° ë¡œë“œ
- ë³‘ë ¬ ë‚ ì§œë³„ ì²˜ë¦¬

Usage:
    python backtest_v64.py --start 2020-01-01 --end 2025-12-31 --top 5
    python backtest_v64.py --start 2016-01-01 --end 2025-12-31 --top 10 --cpu 90
"""

import argparse
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import date, datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed
from multiprocessing import cpu_count
import warnings
import logging
import os
import time

warnings.filterwarnings('ignore')

# ============================================================
# ì„¤ì •
# ============================================================

def get_optimal_workers(cpu_percent: int = 90) -> int:
    """CPU ì‚¬ìš©ë¥ ì— ë”°ë¥¸ ìµœì  ì›Œì»¤ ìˆ˜ ê³„ì‚°
    
    Args:
        cpu_percent: CPU ì‚¬ìš©ë¥  (0-100)
    
    Returns:
        ì›Œì»¤ ìˆ˜
    """
    total_cores = cpu_count()
    workers = max(1, int(total_cores * cpu_percent / 100))
    return workers


@dataclass
class BacktestConfig:
    """ë°±í…ŒìŠ¤íŠ¸ ì„¤ì •"""
    # ë°ì´í„° ê²½ë¡œ
    ohlcv_dir: Path = Path(r"C:\Coding\data\ohlcv")          # FDR (ë°±í…ŒìŠ¤íŒ…ìš©)
    ohlcv_kis_dir: Path = Path(r"C:\Coding\data\ohlcv_kis")  # KIS (ìš´ì˜ìš©)
    stock_mapping_path: Path = Path(r"C:\Coding\data\stock_mapping.csv")
    global_data_dir: Path = Path(r"C:\Coding\data\global")
    output_dir: Path = Path(r"C:\Coding\ClosingBell\backtest_results")
    
    # ë°ì´í„° ì†ŒìŠ¤
    data_source: str = 'fdr'  # ë°±í…ŒìŠ¤íŒ…ì€ FDR ê¶Œì¥ (ì¥ê¸° ë°ì´í„°)
    
    # í•„í„° ì¡°ê±´ (v6.4)
    min_trading_value: float = 150  # ìµœì†Œ ê±°ë˜ëŒ€ê¸ˆ (ì–µì›)
    volume_top_n: int = 150         # ê±°ë˜ëŸ‰ ìƒìœ„ Nìœ„
    min_change_rate: float = 1.0    # ìµœì†Œ ë“±ë½ë¥  (%)
    max_change_rate: float = 29.0   # ìµœëŒ€ ë“±ë½ë¥  (%)
    
    # TOP N
    top_n: int = 5                  # ì„ ì • ì¢…ëª© ìˆ˜
    
    # ì¶”ì  ì¼ìˆ˜
    tracking_days: int = 20         # ë³´ìœ  ê¸°ê°„ ë¶„ì„
    
    # ì„±ëŠ¥ ì„¤ì • (CPU 90% ê¸°ë³¸)
    cpu_percent: int = 90           # CPU ì‚¬ìš©ë¥  (%)
    num_workers: int = None         # Noneì´ë©´ ìë™ ê³„ì‚°
    chunk_size: int = 50            # ë‚ ì§œ ì²­í¬ í¬ê¸° (ë³‘ë ¬ ì²˜ë¦¬ìš©)
    
    def __post_init__(self):
        if self.num_workers is None:
            self.num_workers = get_optimal_workers(self.cpu_percent)
    
    def get_active_ohlcv_dir(self) -> Path:
        if self.data_source == 'kis':
            return self.ohlcv_kis_dir
        return self.ohlcv_dir


# ============================================================
# ë°ì´í„° ë¡œë”
# ============================================================

def load_single_ohlcv(file_path: Path) -> Optional[pd.DataFrame]:
    """ë‹¨ì¼ OHLCV íŒŒì¼ ë¡œë“œ"""
    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        df.columns = df.columns.str.lower()
        
        column_map = {
            'ë‚ ì§œ': 'date', 'ì¼ì': 'date',
            'ì‹œê°€': 'open', 'ê³ ê°€': 'high', 'ì €ê°€': 'low',
            'ì¢…ê°€': 'close', 'ê±°ë˜ëŸ‰': 'volume', 'ê±°ë˜ëŒ€ê¸ˆ': 'trading_value',
        }
        df = df.rename(columns=column_map)
        
        required = ['date', 'open', 'high', 'low', 'close', 'volume']
        if not all(col in df.columns for col in required):
            return None
        
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')
        
        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # ê±°ë˜ëŒ€ê¸ˆ (ì–µì›)
        if 'trading_value' in df.columns:
            df['trading_value'] = pd.to_numeric(df['trading_value'], errors='coerce')
            median_val = df['trading_value'].median()
            if median_val > 1_000_000:
                df['trading_value'] = df['trading_value'] / 100_000_000
        else:
            df['trading_value'] = df['close'] * df['volume'] / 100_000_000
        
        # ì¢…ëª©ì½”ë“œ
        code = file_path.stem.lstrip('A')
        if len(code) == 6 and code.isdigit():
            df['code'] = code
        else:
            df['code'] = file_path.stem
        
        return df[['date', 'code', 'open', 'high', 'low', 'close', 'volume', 'trading_value']]
        
    except Exception as e:
        return None


def load_all_ohlcv(config: BacktestConfig, start_date: date, end_date: date) -> Dict[str, pd.DataFrame]:
    """ì „ì²´ OHLCV ë°ì´í„° ë¡œë“œ (ë©€í‹°ìŠ¤ë ˆë”©)"""
    ohlcv_dir = config.get_active_ohlcv_dir()
    if not ohlcv_dir.exists():
        print(f"OHLCV ë””ë ‰í† ë¦¬ ì—†ìŒ: {ohlcv_dir}")
        return {}
    
    files = list(ohlcv_dir.glob("*.csv"))
    print(f"OHLCV íŒŒì¼: {len(files)}ê°œ")
    print(f"ë©€í‹°ìŠ¤ë ˆë”© ì›Œì»¤: {config.num_workers}ê°œ (CPU {config.cpu_percent}%)")
    
    result = {}
    loaded = 0
    start_time = time.time()
    
    def load_worker(file_path: Path) -> Tuple[str, Optional[pd.DataFrame]]:
        """ì›Œì»¤ í•¨ìˆ˜"""
        df = load_single_ohlcv(file_path)
        if df is not None and len(df) > 0:
            mask = (df['date'].dt.date >= start_date) & (df['date'].dt.date <= end_date)
            df_filtered = df[mask]
            if len(df_filtered) > 0:
                code = df_filtered['code'].iloc[0]
                return (code, df_filtered)
        return (None, None)
    
    # ThreadPoolExecutor ì‚¬ìš© (Windows í˜¸í™˜ + I/O ì‘ì—…ì— ì í•©)
    with ThreadPoolExecutor(max_workers=config.num_workers) as executor:
        futures = {executor.submit(load_worker, f): f for f in files}
        
        for future in as_completed(futures):
            try:
                code, df = future.result()
                if code is not None:
                    result[code] = df
                loaded += 1
                
                if loaded % 500 == 0:
                    elapsed = time.time() - start_time
                    rate = loaded / elapsed if elapsed > 0 else 0
                    remaining = (len(files) - loaded) / rate if rate > 0 else 0
                    print(f"  ë¡œë“œ ì¤‘... {loaded}/{len(files)} ({rate:.0f}ê°œ/ì´ˆ, ë‚¨ì€ì‹œê°„: {remaining:.0f}ì´ˆ)")
            except Exception as e:
                pass
    
    elapsed = time.time() - start_time
    print(f"ë¡œë“œ ì™„ë£Œ: {len(result)}ê°œ ì¢…ëª© ({elapsed:.1f}ì´ˆ, {len(result)/elapsed:.0f}ê°œ/ì´ˆ)")
    return result


def load_stock_mapping(config: BacktestConfig) -> pd.DataFrame:
    """ì¢…ëª© ë§¤í•‘ ë¡œë“œ"""
    if not config.stock_mapping_path.exists():
        return pd.DataFrame()
    
    df = pd.read_csv(config.stock_mapping_path, encoding='utf-8-sig')
    if 'stock_code' in df.columns:
        df = df.rename(columns={'stock_code': 'code', 'stock_name': 'name'})
    df['code'] = df['code'].astype(str).str.zfill(6)
    return df


def load_global_index(config: BacktestConfig, index_name: str) -> Optional[pd.DataFrame]:
    """ê¸€ë¡œë²Œ ì§€ìˆ˜ ë¡œë“œ"""
    index_files = {
        'NASDAQ': ['nasdaq.csv', 'NASDAQ.csv'],
        'USDKRW': ['usdkrw.csv', 'USDKRW.csv', 'USD_KRW.csv'],
    }
    
    for filename in index_files.get(index_name, []):
        file_path = config.global_data_dir / filename
        if file_path.exists():
            try:
                df = pd.read_csv(file_path, encoding='utf-8-sig')
                first_col = df.columns[0]
                if first_col == '' or first_col == 'Unnamed: 0':
                    df = df.rename(columns={first_col: 'date'})
                
                column_map = {'ë‚ ì§œ': 'date', 'Date': 'date', 'ì¢…ê°€': 'close', 'Close': 'close'}
                df = df.rename(columns=column_map)
                
                if 'date' not in df.columns:
                    df = df.reset_index().rename(columns={'index': 'date'})
                
                df['date'] = pd.to_datetime(df['date'])
                df = df.sort_values('date')
                
                if 'close' in df.columns:
                    df['change_rate'] = df['close'].pct_change() * 100
                    return df[['date', 'close', 'change_rate']]
            except:
                pass
    return None


# ============================================================
# ì§€í‘œ ê³„ì‚°
# ============================================================

def calculate_cci(df: pd.DataFrame, period: int = 14) -> pd.Series:
    """CCI ê³„ì‚°"""
    tp = (df['high'] + df['low'] + df['close']) / 3
    sma = tp.rolling(window=period).mean()
    mad = tp.rolling(window=period).apply(lambda x: np.mean(np.abs(x - x.mean())), raw=True)
    cci = (tp - sma) / (0.015 * mad)
    return cci


def calculate_all_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """ëª¨ë“  ì§€í‘œ ê³„ì‚°"""
    result = df.copy()
    
    # ë“±ë½ë¥ 
    result['change_rate'] = result['close'].pct_change() * 100
    
    # CCI
    result['cci'] = calculate_cci(result)
    result['prev_cci'] = result['cci'].shift(1)
    
    # ì´ë™í‰ê· 
    result['ma5'] = result['close'].rolling(5).mean()
    result['ma20'] = result['close'].rolling(20).mean()
    
    # MA20 ìƒìŠ¹ ì—¬ë¶€
    ma20_diff = result['ma20'].diff()
    result['ma20_3day_up'] = ((ma20_diff > 0) & (ma20_diff.shift(1) > 0) & (ma20_diff.shift(2) > 0)).astype(int)
    result['ma20_2day_up'] = ((ma20_diff > 0) & (ma20_diff.shift(1) > 0)).astype(int)
    
    # ì´ê²©ë„
    result['disparity_20'] = (result['close'] / result['ma20'] - 1) * 100
    
    # ê±°ë˜ëŸ‰ ë¹„ìœ¨ (ë‹¹ì¼ ì œì™¸ í‰ê· )
    result['volume_ratio_19'] = result['volume'] / result['volume'].shift(1).rolling(19).mean()
    
    # ì—°ì† ì–‘ë´‰
    is_up = result['close'] > result['open']
    groups = (~is_up).cumsum()
    result['consecutive_up'] = is_up.groupby(groups).cumsum()
    
    # ìº”ë“¤ ì§€í‘œ
    result['is_bullish'] = (result['close'] > result['open']).astype(int)
    lower_shadow = result['open'].where(result['close'] > result['open'], result['close']) - result['low']
    result['lower_shadow_pct'] = lower_shadow / result['close'] * 100
    
    # ê³ ê°€=ì¢…ê°€ ì—¬ë¶€
    result['high_eq_close'] = ((result['high'] == result['close']) & (result['is_bullish'] == 1)).astype(int)
    
    return result


# ============================================================
# ì ìˆ˜ ê³„ì‚° (v6.4)
# ============================================================

def calc_cci_score(cci: float) -> float:
    """CCI ì ìˆ˜ (15ì  ë§Œì ) - v6.5 ë‹¨ìˆœí™”
    
    ìµœì  êµ¬ê°„: 160~180 (ë§Œì )
    ë©€ì–´ì§ˆìˆ˜ë¡ ì ì§„ì  ê°ì 
    ìŒìˆ˜: ë§ì´ ê°ì 
    """
    if pd.isna(cci): return 7.5
    
    # ìŒìˆ˜: ë§ì´ ê°ì 
    if cci < 0:
        return max(0, 5 + cci * 0.05)  # 0 â†’ 5ì , -100 â†’ 0ì 
    
    # ìµœì  êµ¬ê°„: 160~180 (ë§Œì )
    if 160 <= cci <= 180:
        return 15.0
    
    # 160 ë¯¸ë§Œ: ì ì§„ì  ê°ì  (ê±°ë¦¬ì— ë¹„ë¡€)
    if cci < 160:
        distance = 160 - cci
        return max(5, 15 - distance * 0.0625)  # 160pt ë–¨ì–´ì§€ë©´ 10ì  ê°ì 
    
    # 180 ì´ˆê³¼: ì ì§„ì  ê°ì  (ê³¼ì—´)
    distance = cci - 180
    return max(3, 15 - distance * 0.1)  # 120pt ë–¨ì–´ì§€ë©´ 12ì  ê°ì 

def calc_change_score(change_rate: float) -> float:
    """ë“±ë½ë¥  ì ìˆ˜ (15ì  ë§Œì ) - v6.5 ë‹¨ìˆœí™”
    
    ìµœì  êµ¬ê°„: 4~6% (ë§Œì )
    ë©€ì–´ì§ˆìˆ˜ë¡ ì ì§„ì  ê°ì 
    ìŒìˆ˜: ë§ì´ ê°ì 
    25%+: ë§ì´ ê°ì  (ì¶”ê²©ë§¤ìˆ˜ ìœ„í—˜)
    """
    if pd.isna(change_rate): return 7.5
    
    # ìŒìˆ˜: ë§ì´ ê°ì 
    if change_rate < 0:
        return max(0, 5 + change_rate * 0.5)  # 0% â†’ 5ì , -10% â†’ 0ì 
    
    # 25%+: ë§ì´ ê°ì  (ê¸‰ë“± ì¶”ê²© ìœ„í—˜)
    if change_rate >= 25:
        return 2.0
    
    # ìµœì  êµ¬ê°„: 4~6% (ë§Œì )
    if 4 <= change_rate <= 6:
        return 15.0
    
    # 4% ë¯¸ë§Œ: ì ì§„ì  ê°ì 
    if change_rate < 4:
        distance = 4 - change_rate
        return max(7, 15 - distance * 2)  # 4pt ë–¨ì–´ì§€ë©´ 8ì  ê°ì 
    
    # 6% ì´ˆê³¼: ì ì§„ì  ê°ì  (ì¶”ê²©ë§¤ìˆ˜ ìœ„í—˜ ì¦ê°€)
    distance = change_rate - 6
    return max(3, 15 - distance * 0.63)  # 19pt ë–¨ì–´ì§€ë©´ 12ì  ê°ì 

def calc_distance_score(distance: float) -> float:
    """ì´ê²©ë„ ì ìˆ˜ (15ì  ë§Œì ) - v6.5 ë‹¨ìˆœí™”
    
    ìµœì  êµ¬ê°„: 2~8% (ë§Œì )
    ë©€ì–´ì§ˆìˆ˜ë¡ ì ì§„ì  ê°ì 
    ìŒìˆ˜: ë§ì´ ê°ì  (MA20 ì•„ë˜)
    """
    if pd.isna(distance): return 7.5
    
    # ìŒìˆ˜: ë§ì´ ê°ì  (MA20 ì•„ë˜ = ì•½ì„¸)
    if distance < 0:
        return max(0, 5 + distance * 0.5)  # 0% â†’ 5ì , -10% â†’ 0ì 
    
    # ìµœì  êµ¬ê°„: 2~8% (ë§Œì )
    if 2 <= distance <= 8:
        return 15.0
    
    # 2% ë¯¸ë§Œ: ì ì§„ì  ê°ì  (ì•„ì§ ëœ ì˜¬ëìŒ)
    if distance < 2:
        return max(10, 15 - (2 - distance) * 2.5)  # 2pt ë–¨ì–´ì§€ë©´ 5ì  ê°ì 
    
    # 8% ì´ˆê³¼: ì ì§„ì  ê°ì  (ê³¼ì—´)
    return max(3, 15 - (distance - 8) * 0.6)  # 20pt ë–¨ì–´ì§€ë©´ 12ì  ê°ì 

def calc_consec_score(consec_days: int) -> float:
    """ì—°ì†ì–‘ë´‰ ì ìˆ˜ (15ì  ë§Œì ) - v6.5 ë‹¨ìˆœí™”
    
    ìµœì  êµ¬ê°„: 2~3ì¼ (ë§Œì )
    ë©€ì–´ì§ˆìˆ˜ë¡ ì ì§„ì  ê°ì 
    """
    if pd.isna(consec_days): consec_days = 0
    consec_days = int(consec_days)
    
    # ìµœì  êµ¬ê°„: 2~3ì¼ (ë§Œì )
    if 2 <= consec_days <= 3:
        return 15.0
    
    # 0~1ì¼: ì ì§„ì  ê°ì  (ëª¨ë©˜í…€ ë¶€ì¡±)
    if consec_days < 2:
        return 7 + consec_days * 4  # 0ì¼ â†’ 7ì , 1ì¼ â†’ 11ì 
    
    # 4ì¼+: ì ì§„ì  ê°ì  (ê³¼ì—´/ê¸‰ë½ ìœ„í—˜)
    return max(2, 15 - (consec_days - 3) * 3)  # 4ì¼ â†’ 12ì , 5ì¼ â†’ 9ì , 6ì¼ â†’ 6ì 

def calc_volume_score(volume_ratio: float) -> float:
    if pd.isna(volume_ratio) or volume_ratio < 1: return 0.0
    return max(0, min(1, (volume_ratio - 1) / 4)) * 15

def calc_candle_score(is_bullish: int, lower_shadow_pct: float) -> float:
    if pd.isna(is_bullish): is_bullish = 0
    if pd.isna(lower_shadow_pct): lower_shadow_pct = 0.0
    bullish_score = 1.0 if is_bullish else 0.0
    lower_score = min(lower_shadow_pct / 3, 1.0)
    return (bullish_score * 0.5 + lower_score * 0.5) * 15


def calculate_score(row: pd.Series) -> float:
    """ì¢…ëª© ì ìˆ˜ ê³„ì‚° (100ì  ë§Œì )"""
    # ê¸°ë³¸ ì ìˆ˜ (90ì )
    cci_score = calc_cci_score(row.get('cci'))
    change_score = calc_change_score(row.get('change_rate'))
    distance_score = calc_distance_score(row.get('disparity_20'))
    consec_score = calc_consec_score(row.get('consecutive_up'))
    volume_score = calc_volume_score(row.get('volume_ratio_19'))
    candle_score = calc_candle_score(row.get('is_bullish', 0), row.get('lower_shadow_pct', 0))
    
    base_score = cci_score + change_score + distance_score + consec_score + volume_score + candle_score
    
    # ë³´ë„ˆìŠ¤ (10ì )
    bonus = 0.0
    
    # CCI ìƒìŠ¹ ë³´ë„ˆìŠ¤ (4ì )
    cci = row.get('cci')
    prev_cci = row.get('prev_cci')
    if not pd.isna(cci) and not pd.isna(prev_cci) and cci > prev_cci:
        rise = cci - prev_cci
        if rise > 20: bonus += 4.0
        elif rise > 10: bonus += 3.5
        elif rise > 5: bonus += 3.0
        else: bonus += 2.5
    
    # MA20 3ì¼ ìƒìŠ¹ ë³´ë„ˆìŠ¤ (3ì )
    if row.get('ma20_3day_up', 0) == 1:
        bonus += 3.0
    elif row.get('ma20_2day_up', 0) == 1:
        bonus += 1.5
    
    # ê³ ê°€â‰ ì¢…ê°€ ë³´ë„ˆìŠ¤ (3ì )
    if row.get('high_eq_close', 0) == 0:
        bonus += 3.0
    
    return min(100.0, base_score + bonus)


def score_to_grade(score: float) -> str:
    if score >= 85: return 'S'
    elif score >= 75: return 'A'
    elif score >= 65: return 'B'
    elif score >= 55: return 'C'
    else: return 'D'


# ============================================================
# ë°±í…ŒìŠ¤íŒ… ì—”ì§„ (ë³‘ë ¬ ì²˜ë¦¬)
# ============================================================

@dataclass
class TradeResult:
    """ê±°ë˜ ê²°ê³¼"""
    trade_date: date           # ë§¤ìˆ˜ì¼
    code: str                  # ì¢…ëª©ì½”ë“œ
    name: str                  # ì¢…ëª©ëª…
    rank: int                  # ìˆœìœ„ (1~5)
    score: float               # ì ìˆ˜
    grade: str                 # ë“±ê¸‰
    buy_price: float           # ë§¤ìˆ˜ê°€ (ë‹¹ì¼ ì¢…ê°€)
    
    # ìˆ˜ìµë¥ 
    next_open_return: float = 0.0    # ìµì¼ ì‹œê°€ ìˆ˜ìµë¥ 
    next_close_return: float = 0.0   # ìµì¼ ì¢…ê°€ ìˆ˜ìµë¥ 
    day3_return: float = 0.0         # 3ì¼ í›„ ì¢…ê°€ ìˆ˜ìµë¥ 
    day5_return: float = 0.0         # 5ì¼ í›„ ì¢…ê°€ ìˆ˜ìµë¥ 
    day10_return: float = 0.0        # 10ì¼ í›„ ì¢…ê°€ ìˆ˜ìµë¥ 
    day20_return: float = 0.0        # 20ì¼ í›„ ì¢…ê°€ ìˆ˜ìµë¥ 
    max_return: float = 0.0          # 20ì¼ ë‚´ ìµœëŒ€ ìˆ˜ìµë¥ 
    min_return: float = 0.0          # 20ì¼ ë‚´ ìµœì†Œ ìˆ˜ìµë¥  (MDD)


def process_single_date(args) -> List[dict]:
    """ë‹¨ì¼ ë‚ ì§œ ì²˜ë¦¬ (ì›Œì»¤ í•¨ìˆ˜)"""
    trade_date, day_data, all_data, name_map, config = args
    
    results = []
    
    if len(day_data) == 0:
        return results
    
    # 1. í•„í„°ë§: ê±°ë˜ëŒ€ê¸ˆ 150ì–µ+
    filtered = day_data[day_data['trading_value'] >= config['min_trading_value']]
    
    # 2. í•„í„°ë§: ë“±ë½ë¥  1~29%
    filtered = filtered[
        (filtered['change_rate'] >= config['min_change_rate']) &
        (filtered['change_rate'] < config['max_change_rate'])
    ]
    
    # 3. í•„í„°ë§: ê±°ë˜ëŸ‰ TOP 150
    if len(filtered) > config['volume_top_n']:
        filtered = filtered.nlargest(config['volume_top_n'], 'volume')
    
    if len(filtered) == 0:
        return results
    
    # 4. ì ìˆ˜ ê³„ì‚°
    filtered = filtered.copy()
    filtered['score'] = filtered.apply(calculate_score, axis=1)
    filtered['grade'] = filtered['score'].apply(score_to_grade)
    
    # 5. TOP N ì„ ì •
    top_stocks = filtered.nlargest(config['top_n'], 'score')
    
    # 6. ìˆ˜ìµë¥  ê³„ì‚°
    for rank, (idx, row) in enumerate(top_stocks.iterrows(), 1):
        code = row['code']
        buy_price = row['close']
        
        # í•´ë‹¹ ì¢…ëª©ì˜ ë¯¸ë˜ ë°ì´í„°
        stock_future = all_data.get(code)
        if stock_future is None:
            continue
        
        future_data = stock_future[stock_future['date'].dt.date > trade_date].sort_values('date')
        
        if len(future_data) == 0:
            continue
        
        # ìµì¼ ì‹œê°€/ì¢…ê°€
        next_day = future_data.iloc[0] if len(future_data) > 0 else None
        next_open_return = (next_day['open'] / buy_price - 1) * 100 if next_day is not None else 0
        next_close_return = (next_day['close'] / buy_price - 1) * 100 if next_day is not None else 0
        
        # Nì¼ í›„ ìˆ˜ìµë¥ 
        day3_return = (future_data.iloc[2]['close'] / buy_price - 1) * 100 if len(future_data) > 2 else 0
        day5_return = (future_data.iloc[4]['close'] / buy_price - 1) * 100 if len(future_data) > 4 else 0
        day10_return = (future_data.iloc[9]['close'] / buy_price - 1) * 100 if len(future_data) > 9 else 0
        day20_return = (future_data.iloc[19]['close'] / buy_price - 1) * 100 if len(future_data) > 19 else 0
        
        # 20ì¼ ë‚´ ìµœëŒ€/ìµœì†Œ ìˆ˜ìµë¥ 
        future_20 = future_data.head(20)
        if len(future_20) > 0:
            max_price = future_20['high'].max()
            min_price = future_20['low'].min()
            max_return = (max_price / buy_price - 1) * 100
            min_return = (min_price / buy_price - 1) * 100
        else:
            max_return = 0
            min_return = 0
        
        results.append({
            'trade_date': trade_date,
            'code': code,
            'name': name_map.get(code, code),
            'rank': rank,
            'score': row['score'],
            'grade': row['grade'],
            'buy_price': buy_price,
            'next_open_return': next_open_return,
            'next_close_return': next_close_return,
            'day3_return': day3_return,
            'day5_return': day5_return,
            'day10_return': day10_return,
            'day20_return': day20_return,
            'max_return': max_return,
            'min_return': min_return,
        })
    
    return results


def run_backtest(
    config: BacktestConfig,
    all_data: Dict[str, pd.DataFrame],
    stock_mapping: pd.DataFrame,
    start_date: date,
    end_date: date,
) -> List[TradeResult]:
    """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ (ë³‘ë ¬ ì²˜ë¦¬)"""
    
    start_time = time.time()
    
    # ì¢…ëª©ëª… ë”•ì…”ë„ˆë¦¬
    name_map = dict(zip(stock_mapping['code'], stock_mapping['name'])) if len(stock_mapping) > 0 else {}
    
    # ëª¨ë“  ë‚ ì§œì˜ ë°ì´í„°ë¥¼ í•©ì¹¨ + ì§€í‘œ ê³„ì‚°
    print("ë°ì´í„° ë³‘í•© ë° ì§€í‘œ ê³„ì‚° ì¤‘...")
    indicator_start = time.time()
    
    all_rows = []
    processed = 0
    
    # ì§€í‘œ ê³„ì‚°ë„ ë³‘ë ¬ë¡œ
    def calc_indicators(item):
        code, df = item
        df_ind = calculate_all_indicators(df)
        df_ind['code'] = code
        return df_ind
    
    with ThreadPoolExecutor(max_workers=config.num_workers) as executor:
        futures = [executor.submit(calc_indicators, item) for item in all_data.items()]
        
        for future in as_completed(futures):
            try:
                df_ind = future.result()
                all_rows.append(df_ind)
                processed += 1
                
                if processed % 500 == 0:
                    print(f"  ì§€í‘œ ê³„ì‚° ì¤‘... {processed}/{len(all_data)}")
            except:
                pass
    
    combined = pd.concat(all_rows, ignore_index=True)
    combined['trade_date'] = combined['date'].dt.date
    
    print(f"ì§€í‘œ ê³„ì‚° ì™„ë£Œ: {time.time() - indicator_start:.1f}ì´ˆ")
    
    # ê±°ë˜ì¼ ëª©ë¡
    trading_days = sorted(combined['trade_date'].unique())
    trading_days = [d for d in trading_days if start_date <= d <= end_date]
    
    print(f"ê±°ë˜ì¼: {len(trading_days)}ì¼ ({trading_days[0]} ~ {trading_days[-1]})")
    print(f"ë³‘ë ¬ ì²˜ë¦¬: {config.num_workers}ê°œ ì›Œì»¤ (CPU {config.cpu_percent}%)")
    
    # ë‚ ì§œë³„ ë°ì´í„° ë¯¸ë¦¬ ë¶„ë¦¬
    date_groups = {d: combined[combined['trade_date'] == d].copy() for d in trading_days}
    
    # configë¥¼ dictë¡œ ë³€í™˜ (pickle ê°€ëŠ¥í•˜ê²Œ)
    config_dict = {
        'min_trading_value': config.min_trading_value,
        'min_change_rate': config.min_change_rate,
        'max_change_rate': config.max_change_rate,
        'volume_top_n': config.volume_top_n,
        'top_n': config.top_n,
    }
    
    # ë³‘ë ¬ ì²˜ë¦¬
    all_results = []
    backtest_start = time.time()
    
    # ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
    chunk_size = config.chunk_size
    total_chunks = (len(trading_days) + chunk_size - 1) // chunk_size
    
    for chunk_idx in range(total_chunks):
        chunk_start = chunk_idx * chunk_size
        chunk_end = min(chunk_start + chunk_size, len(trading_days))
        chunk_dates = trading_days[chunk_start:chunk_end]
        
        # ì´ ì²­í¬ì˜ ë‚ ì§œë“¤ì— ëŒ€í•´ ë³‘ë ¬ ì²˜ë¦¬
        args_list = [
            (d, date_groups[d], all_data, name_map, config_dict)
            for d in chunk_dates
        ]
        
        with ThreadPoolExecutor(max_workers=config.num_workers) as executor:
            futures = [executor.submit(process_single_date, args) for args in args_list]
            
            for future in as_completed(futures):
                try:
                    results = future.result()
                    all_results.extend(results)
                except Exception as e:
                    pass
        
        # ì§„í–‰ë¥  í‘œì‹œ
        processed_days = chunk_end
        elapsed = time.time() - backtest_start
        rate = processed_days / elapsed if elapsed > 0 else 0
        remaining = (len(trading_days) - processed_days) / rate if rate > 0 else 0
        print(f"  ë°±í…ŒìŠ¤íŠ¸ ì§„í–‰: {processed_days}/{len(trading_days)}ì¼ "
              f"({rate:.1f}ì¼/ì´ˆ, ë‚¨ì€ì‹œê°„: {remaining:.0f}ì´ˆ)")
    
    # TradeResult ê°ì²´ë¡œ ë³€í™˜
    results = [TradeResult(**r) for r in all_results]
    
    total_time = time.time() - start_time
    print(f"\nì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ì´ˆ ({len(results)}ê±´ ì²˜ë¦¬)")
    
    return results


# ============================================================
# ë¶„ì„ ë° ë¦¬í¬íŠ¸
# ============================================================

def analyze_results(results: List[TradeResult], config: BacktestConfig) -> pd.DataFrame:
    """ê²°ê³¼ ë¶„ì„"""
    df = pd.DataFrame([vars(r) for r in results])
    
    if len(df) == 0:
        print("ê²°ê³¼ ì—†ìŒ")
        return df
    
    print("\n" + "=" * 70)
    print(f"ğŸ“Š ClosingBell v6.4 ë°±í…ŒìŠ¤íŒ… ê²°ê³¼")
    print("=" * 70)
    
    # ê¸°ë³¸ í†µê³„
    print(f"\nğŸ“ˆ ê¸°ë³¸ í†µê³„")
    print(f"  - ì´ ê±°ë˜ì¼: {df['trade_date'].nunique()}ì¼")
    print(f"  - ì´ ê±°ë˜: {len(df)}ê±´ (ì¼í‰ê·  {len(df) / df['trade_date'].nunique():.1f}ê±´)")
    print(f"  - ë¶„ì„ ê¸°ê°„: {df['trade_date'].min()} ~ {df['trade_date'].max()}")
    
    # ìˆ˜ìµë¥  ë¶„ì„
    print(f"\nğŸ’° ìˆ˜ìµë¥  ë¶„ì„ (ì¢…ê°€ ë§¤ìˆ˜ ê¸°ì¤€)")
    print(f"  {'êµ¬ë¶„':12} {'í‰ê· ':>8} {'ìŠ¹ë¥ ':>8} {'ìµœëŒ€':>8} {'ìµœì†Œ':>8}")
    print(f"  {'-'*48}")
    
    metrics = [
        ('ìµì¼ ì‹œê°€', 'next_open_return'),
        ('ìµì¼ ì¢…ê°€', 'next_close_return'),
        ('3ì¼ í›„', 'day3_return'),
        ('5ì¼ í›„', 'day5_return'),
        ('10ì¼ í›„', 'day10_return'),
        ('20ì¼ í›„', 'day20_return'),
        ('20ì¼ ìµœëŒ€', 'max_return'),
    ]
    
    for name, col in metrics:
        avg = df[col].mean()
        win_rate = (df[col] > 0).mean() * 100
        max_val = df[col].max()
        min_val = df[col].min()
        print(f"  {name:12} {avg:+7.2f}% {win_rate:6.1f}% {max_val:+7.1f}% {min_val:+7.1f}%")
    
    # ë“±ê¸‰ë³„ ë¶„ì„
    print(f"\nğŸ† ë“±ê¸‰ë³„ ë¶„ì„ (ìµì¼ ì‹œê°€ ê¸°ì¤€)")
    print(f"  {'ë“±ê¸‰':6} {'ê±´ìˆ˜':>8} {'í‰ê· ':>8} {'ìŠ¹ë¥ ':>8}")
    print(f"  {'-'*36}")
    
    for grade in ['S', 'A', 'B', 'C', 'D']:
        grade_df = df[df['grade'] == grade]
        if len(grade_df) > 0:
            count = len(grade_df)
            avg = grade_df['next_open_return'].mean()
            win_rate = (grade_df['next_open_return'] > 0).mean() * 100
            print(f"  {grade:6} {count:8} {avg:+7.2f}% {win_rate:6.1f}%")
    
    # ìˆœìœ„ë³„ ë¶„ì„
    print(f"\nğŸ“Š ìˆœìœ„ë³„ ë¶„ì„ (ìµì¼ ì‹œê°€ ê¸°ì¤€)")
    print(f"  {'ìˆœìœ„':6} {'ê±´ìˆ˜':>8} {'í‰ê· ':>8} {'ìŠ¹ë¥ ':>8}")
    print(f"  {'-'*36}")
    
    for rank in range(1, config.top_n + 1):
        rank_df = df[df['rank'] == rank]
        if len(rank_df) > 0:
            count = len(rank_df)
            avg = rank_df['next_open_return'].mean()
            win_rate = (rank_df['next_open_return'] > 0).mean() * 100
            print(f"  #{rank:5} {count:8} {avg:+7.2f}% {win_rate:6.1f}%")
    
    # ì—°ë„ë³„ ë¶„ì„
    df['year'] = pd.to_datetime(df['trade_date']).dt.year
    
    print(f"\nğŸ“… ì—°ë„ë³„ ë¶„ì„ (ìµì¼ ì‹œê°€ ê¸°ì¤€)")
    print(f"  {'ì—°ë„':6} {'ê±°ë˜':>8} {'í‰ê· ':>8} {'ìŠ¹ë¥ ':>8}")
    print(f"  {'-'*36}")
    
    for year in sorted(df['year'].unique()):
        year_df = df[df['year'] == year]
        count = len(year_df)
        avg = year_df['next_open_return'].mean()
        win_rate = (year_df['next_open_return'] > 0).mean() * 100
        print(f"  {year:6} {count:8} {avg:+7.2f}% {win_rate:6.1f}%")
    
    # ì›”ë³„ ë¶„ì„
    df['month'] = pd.to_datetime(df['trade_date']).dt.month
    
    print(f"\nğŸ“† ì›”ë³„ ë¶„ì„ (ìµì¼ ì‹œê°€ ê¸°ì¤€)")
    print(f"  {'ì›”':6} {'ê±°ë˜':>8} {'í‰ê· ':>8} {'ìŠ¹ë¥ ':>8}")
    print(f"  {'-'*36}")
    
    for month in range(1, 13):
        month_df = df[df['month'] == month]
        if len(month_df) > 0:
            count = len(month_df)
            avg = month_df['next_open_return'].mean()
            win_rate = (month_df['next_open_return'] > 0).mean() * 100
            print(f"  {month:2}ì›”    {count:8} {avg:+7.2f}% {win_rate:6.1f}%")
    
    print("\n" + "=" * 70)
    
    return df


def main():
    parser = argparse.ArgumentParser(description='ClosingBell v6.4 ë°±í…ŒìŠ¤íŒ… (ê³ ì„±ëŠ¥)')
    parser.add_argument('--start', type=str, default='2020-01-01', help='ì‹œì‘ì¼ (YYYY-MM-DD)')
    parser.add_argument('--end', type=str, default='2025-12-31', help='ì¢…ë£Œì¼ (YYYY-MM-DD)')
    parser.add_argument('--top', type=int, default=5, help='TOP N')
    parser.add_argument('--source', type=str, default='fdr', choices=['fdr', 'kis'], help='ë°ì´í„° ì†ŒìŠ¤')
    parser.add_argument('--cpu', type=int, default=90, help='CPU ì‚¬ìš©ë¥  (%%)')
    parser.add_argument('--chunk', type=int, default=50, help='ì²­í¬ í¬ê¸°')
    parser.add_argument('--output', type=str, default=None, help='ê²°ê³¼ CSV ê²½ë¡œ')
    
    args = parser.parse_args()
    
    # ì„¤ì •
    config = BacktestConfig()
    config.data_source = args.source
    config.top_n = args.top
    config.cpu_percent = args.cpu
    config.chunk_size = args.chunk
    config.num_workers = get_optimal_workers(config.cpu_percent)
    
    start_date = datetime.strptime(args.start, '%Y-%m-%d').date()
    end_date = datetime.strptime(args.end, '%Y-%m-%d').date()
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š ClosingBell v6.4 ë°±í…ŒìŠ¤íŒ… (ê³ ì„±ëŠ¥ ë²„ì „)")
    print(f"{'='*70}")
    print(f"  ê¸°ê°„: {start_date} ~ {end_date}")
    print(f"  TOP N: {config.top_n}")
    print(f"  ë°ì´í„°: {config.data_source} ({config.get_active_ohlcv_dir()})")
    print(f"  í•„í„°: ê±°ë˜ëŒ€ê¸ˆâ‰¥{config.min_trading_value}ì–µ, ê±°ë˜ëŸ‰TOP{config.volume_top_n}, ë“±ë½ë¥ {config.min_change_rate}~{config.max_change_rate}%")
    print(f"  ")
    print(f"  ğŸš€ ì„±ëŠ¥ ì„¤ì •:")
    print(f"     CPU ì‚¬ìš©ë¥ : {config.cpu_percent}%")
    print(f"     ì›Œì»¤ ìˆ˜: {config.num_workers}ê°œ (ì´ {cpu_count()}ì½”ì–´)")
    print(f"     ì²­í¬ í¬ê¸°: {config.chunk_size}ì¼")
    print(f"{'='*70}\n")
    
    # ë°ì´í„° ë¡œë“œ
    print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    all_data = load_all_ohlcv(config, start_date - timedelta(days=60), end_date + timedelta(days=30))
    
    if len(all_data) == 0:
        print("âŒ OHLCV ë°ì´í„° ì—†ìŒ")
        return
    
    stock_mapping = load_stock_mapping(config)
    print(f"ì¢…ëª© ë§¤í•‘: {len(stock_mapping)}ê°œ")
    
    # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
    print("\nğŸ”„ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ ì¤‘...")
    results = run_backtest(config, all_data, stock_mapping, start_date, end_date)
    
    # ë¶„ì„
    df = analyze_results(results, config)
    
    # ê²°ê³¼ ì €ì¥
    if args.output:
        output_path = Path(args.output)
    else:
        config.output_dir.mkdir(parents=True, exist_ok=True)
        output_path = config.output_dir / f"backtest_v64_{args.start}_{args.end}.csv"
    
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")


if __name__ == '__main__':
    main()