#!/usr/bin/env python3
"""
ClosingBell v10.1.1 íŒ¨ì¹˜ ì ìš© ìŠ¤í¬ë¦½íŠ¸
=====================================
5ê°œ íŒŒì¼, 6ê°œ ìˆ˜ì •ì‚¬í•­

ì‚¬ìš©ë²•:
    cd C:\\Coding\\ClosingBell
    python apply_patch_v10.1.1.py           # ì‹¤ì œ ì ìš©
    python apply_patch_v10.1.1.py --dry-run  # ë¯¸ë¦¬ë³´ê¸°ë§Œ
    python apply_patch_v10.1.1.py --revert   # ë°±ì—…ì—ì„œ ë³µì›

ìˆ˜ì • ëª©ë¡:
    1. enrichment_service.py   - ê³µë§¤ë„/SR ë¡œê¹… debugâ†’info, ì—ëŸ¬ íƒ€ì… ì¶”ê°€
    2. top5_pipeline.py        - ê³µë§¤ë„/SR DB ì €ì¥ ë¡œê¹… + sqlite3.Row .get() ìˆ˜ì • + AI ìºì‹œ ë¡œê·¸
    3. pullback_tracker.py     - OHLCV CSV ì—†ì„ ë•Œ í‚¤ì›€ API í´ë°± ì¶”ê°€
    4. screener_service.py     - VP ë§¤ë¬¼ëŒ€ None ë°©ì–´ + ë¡œê·¸ ìŠ¤íŒ¸ ì œê±° (76ê±´â†’1ì¤„ ìš”ì•½)
    5. 1_top5_tracker.py       - CSS hex color #888 â†’ #888888 (alpha í˜¸í™˜)
"""

import sys
import shutil
from pathlib import Path
from datetime import datetime

# ============================================================
# ì„¤ì •
# ============================================================
PROJECT_ROOT = Path(__file__).parent
BACKUP_DIR = PROJECT_ROOT / "_backup_v10.1.0"

PATCHES = []

# ============================================================
# Patch 1: enrichment_service.py - ê³µë§¤ë„/SR ë¡œê¹… ê°•í™”
# ============================================================
PATCHES.append({
    "file": "src/services/enrichment_service.py",
    "desc": "ê³µë§¤ë„/SR ë¡œê¹… debugâ†’info + ì—ëŸ¬ íƒ€ì… ì¶”ê°€",
    "old": '''        # 3. v10.0: ê³µë§¤ë„/ëŒ€ì°¨ê±°ë˜ ë¶„ì„
        try:
            from src.services.short_selling_service import fetch_and_analyze
            from src.adapters.kiwoom_rest_client import get_kiwoom_client
            broker = get_kiwoom_client()
            stock.short_selling_score = fetch_and_analyze(stock.stock_code, broker)
            logger.debug(f"ê³µë§¤ë„ ë¶„ì„: {stock.stock_code} â†’ {stock.short_selling_score.summary}")
        except Exception as e:
            logger.warning(f"ê³µë§¤ë„ ë¶„ì„ ì‹¤íŒ¨ ({stock.stock_code}): {e}")
            stock.enrich_errors.append(f"Short: {str(e)[:50]}")
        
        # 4. v10.0: ì§€ì§€/ì €í•­ì„  ë¶„ì„
        try:
            from src.services.sr_calculator import calculate_support_resistance
            from src.adapters.kiwoom_rest_client import get_kiwoom_client
            broker = get_kiwoom_client()
            prices = broker.get_daily_prices(stock.stock_code, count=120)
            if prices:
                current = stock.screen_price or (prices[-1].close if prices else 0)
                stock.sr_analysis = calculate_support_resistance(
                    stock.stock_code, prices, current_price=current
                )
                logger.debug(f"ì§€ì§€/ì €í•­: {stock.stock_code} â†’ {stock.sr_analysis.summary}")
        except Exception as e:
            logger.warning(f"ì§€ì§€/ì €í•­ ë¶„ì„ ì‹¤íŒ¨ ({stock.stock_code}): {e}")
            stock.enrich_errors.append(f"SR: {str(e)[:50]}")''',
    "new": '''        # 3. v10.0: ê³µë§¤ë„/ëŒ€ì°¨ê±°ë˜ ë¶„ì„
        try:
            from src.services.short_selling_service import fetch_and_analyze
            from src.adapters.kiwoom_rest_client import get_kiwoom_client
            broker = get_kiwoom_client()
            stock.short_selling_score = fetch_and_analyze(stock.stock_code, broker)
            logger.info(f"ğŸ“‰ ê³µë§¤ë„ ë¶„ì„: {stock.stock_code} â†’ score={stock.short_selling_score.score}, ratio={stock.short_selling_score.latest_short_ratio}%, {stock.short_selling_score.summary}")
        except Exception as e:
            logger.warning(f"âš ï¸ ê³µë§¤ë„ ë¶„ì„ ì‹¤íŒ¨ ({stock.stock_code}): {type(e).__name__}: {e}")
            stock.enrich_errors.append(f"Short: {str(e)[:50]}")
        
        # 4. v10.0: ì§€ì§€/ì €í•­ì„  ë¶„ì„
        try:
            from src.services.sr_calculator import calculate_support_resistance
            from src.adapters.kiwoom_rest_client import get_kiwoom_client
            broker = get_kiwoom_client()
            prices = broker.get_daily_prices(stock.stock_code, count=120)
            if prices:
                current = stock.screen_price or (prices[-1].close if prices else 0)
                stock.sr_analysis = calculate_support_resistance(
                    stock.stock_code, prices, current_price=current
                )
                logger.info(f"ğŸ“Š ì§€ì§€/ì €í•­: {stock.stock_code} â†’ score={stock.sr_analysis.score}, S={stock.sr_analysis.nearest_support}, R={stock.sr_analysis.nearest_resistance}")
            else:
                logger.warning(f"âš ï¸ ì§€ì§€/ì €í•­: {stock.stock_code} â†’ ê°€ê²© ë°ì´í„° ì—†ìŒ (prices=None)")
        except Exception as e:
            logger.warning(f"âš ï¸ ì§€ì§€/ì €í•­ ë¶„ì„ ì‹¤íŒ¨ ({stock.stock_code}): {type(e).__name__}: {e}")
            stock.enrich_errors.append(f"SR: {str(e)[:50]}")'''
})

# ============================================================
# Patch 2a: top5_pipeline.py - ê³µë§¤ë„/SR DB ì €ì¥ ë¡œê¹… ê°•í™”
# ============================================================
PATCHES.append({
    "file": "src/services/top5_pipeline.py",
    "desc": "ê³µë§¤ë„/SR DB ì €ì¥ ë¡œê¹… ê°•í™”",
    "old": '''            # v10.0: ê³µë§¤ë„/ì§€ì§€ì €í•­ í•„ë“œ ì €ì¥
            if enriched_stocks:
                ss_count = 0
                missing_data_count = 0
                for stock in enriched_stocks:
                    code = getattr(stock, 'stock_code', '')
                    ss = getattr(stock, 'short_selling_score', None)
                    sr = getattr(stock, 'sr_analysis', None)
                    
                    if ss or sr:
                        try:
                            repo.update_short_sr_fields(
                                screen_date=screen_date.isoformat(),
                                stock_code=code,
                                short_ratio=getattr(ss, 'latest_short_ratio', 0) if ss else 0,
                                short_score=getattr(ss, 'score', 0) if ss else 0,
                                short_tags=' '.join(getattr(ss, 'tags', [])) if ss else '',
                                sr_score=getattr(sr, 'score', 0) if sr else 0,
                                sr_nearest_support=getattr(sr, 'nearest_support', 0) if sr else 0,
                                sr_nearest_resistance=getattr(sr, 'nearest_resistance', 0) if sr else 0,
                                sr_tags=' '.join(getattr(sr, 'tags', [])) if sr else '',
                            )
                            ss_count += 1
                        except Exception as e:
                            logger.debug(f"ê³µë§¤ë„/SR ì €ì¥ ì‹¤íŒ¨ ({code}): {e}")
                    else:
                        missing_data_count += 1''',
    "new": '''            # v10.0: ê³µë§¤ë„/ì§€ì§€ì €í•­ í•„ë“œ ì €ì¥
            if enriched_stocks:
                ss_count = 0
                missing_data_count = 0
                for stock in enriched_stocks:
                    code = getattr(stock, 'stock_code', '')
                    ss = getattr(stock, 'short_selling_score', None)
                    sr = getattr(stock, 'sr_analysis', None)
                    
                    logger.info(f"  ê³µë§¤ë„/SR ì²´í¬: {code} â†’ ss={'ìˆìŒ' if ss else 'None'}, sr={'ìˆìŒ' if sr else 'None'}")
                    
                    if ss or sr:
                        try:
                            repo.update_short_sr_fields(
                                screen_date=screen_date.isoformat(),
                                stock_code=code,
                                short_ratio=getattr(ss, 'latest_short_ratio', 0) if ss else 0,
                                short_score=getattr(ss, 'score', 0) if ss else 0,
                                short_tags=' '.join(getattr(ss, 'tags', [])) if ss else '',
                                sr_score=getattr(sr, 'score', 0) if sr else 0,
                                sr_nearest_support=getattr(sr, 'nearest_support', 0) if sr else 0,
                                sr_nearest_resistance=getattr(sr, 'nearest_resistance', 0) if sr else 0,
                                sr_tags=' '.join(getattr(sr, 'tags', [])) if sr else '',
                            )
                            ss_count += 1
                            logger.debug(f"  âœ… ê³µë§¤ë„/SR ì €ì¥: {code}")
                        except Exception as e:
                            logger.warning(f"  âŒ ê³µë§¤ë„/SR ì €ì¥ ì‹¤íŒ¨ ({code}): {e}")
                    else:
                        missing_data_count += 1'''
})

# ============================================================
# Patch 2b: top5_pipeline.py - sqlite3.Row .get() ìˆ˜ì •
# ============================================================
PATCHES.append({
    "file": "src/services/top5_pipeline.py",
    "desc": "sqlite3.Row .get() â†’ dict() ë³€í™˜ ìˆ˜ì •",
    "old": '''                            if existing:
                                already_analyzed[stock_code] = {
                                    'recommendation': existing.get('ai_recommendation', 'ê´€ë§'),
                                    'risk_level': existing.get('ai_risk_level', 'ë³´í†µ'),
                                    'summary': existing.get('ai_summary', ''),
                                    'investment_point': '',
                                    'risk_factor': '',
                                }''',
    "new": '''                            if existing:
                                existing = dict(existing)
                                already_analyzed[stock_code] = {
                                    'recommendation': existing.get('ai_recommendation', 'ê´€ë§'),
                                    'risk_level': existing.get('ai_risk_level', 'ë³´í†µ'),
                                    'summary': existing.get('ai_summary', ''),
                                    'investment_point': '',
                                    'risk_factor': '',
                                }'''
})

# ============================================================
# Patch 2c: top5_pipeline.py - AI ìºì‹œ ë¡œê·¸ ë ˆë²¨ ìƒí–¥
# ============================================================
PATCHES.append({
    "file": "src/services/top5_pipeline.py",
    "desc": "AI ìºì‹œ ì²´í¬ ì‹¤íŒ¨ ë¡œê·¸ debugâ†’info",
    "old": '''                except Exception as e:
                    logger.debug(f"AI ìºì‹œ ì²´í¬ ì‹¤íŒ¨ (ì „ì²´ ë¶„ì„ ì§„í–‰): {e}")
                    stocks_to_analyze = enriched_stocks if enriched_stocks else scores[:self.top_n_count]''',
    "new": '''                except Exception as e:
                    logger.info(f"AI ìºì‹œ ì²´í¬ ì‹¤íŒ¨ (ì „ì²´ ë¶„ì„ ì§„í–‰): {type(e).__name__}: {e}")
                    stocks_to_analyze = enriched_stocks if enriched_stocks else scores[:self.top_n_count]'''
})

# ============================================================
# Patch 3: pullback_tracker.py - API í´ë°± ì¶”ê°€
# ============================================================
PATCHES.append({
    "file": "src/services/pullback_tracker.py",
    "desc": "ëˆŒë¦¼ëª© ì¶”ì : OHLCV CSV ì—†ì„ ë•Œ í‚¤ì›€ API í´ë°±",
    "old": '''    # OHLCV ë°ì´í„° ê²½ë¡œ
    ohlcv_dir = DATA_DIR / "ohlcv_kiwoom"
    
    for sig in signals:
        signal_id = sig["id"]
        stock_code = sig["stock_code"]
        signal_date = sig["signal_date"]
        signal_close = sig["close_price"]
        
        if not signal_close or signal_close <= 0:
            continue
        
        # ì´ë¯¸ ì¶”ì  ì™„ë£Œëœ ì¼ìˆ˜ í™•ì¸
        existing = db.fetch_all(
            "SELECT days_after FROM pullback_daily_prices "
            "WHERE pullback_signal_id = ? ORDER BY days_after",
            (signal_id,),
        )
        existing_days = {r["days_after"] for r in existing}
        
        # D+tracking_daysê¹Œì§€ ì™„ë£Œë˜ë©´ ìŠ¤í‚µ
        if len(existing_days) >= tracking_days:
            continue
        
        # OHLCV íŒŒì¼ì—ì„œ ê°€ê²© ë¡œë“œ
        csv_path = ohlcv_dir / f"{stock_code}.csv"
        if not csv_path.exists():
            continue
        
        try:
            df = pd.read_csv(csv_path)
            df.columns = df.columns.str.lower()
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date')
            
            # signal_date ì´í›„ì˜ ê±°ë˜ì¼ ë°ì´í„°
            signal_dt = pd.to_datetime(signal_date)
            future = df[df['date'] > signal_dt].head(tracking_days)
            
            if future.empty:
                continue
            
            signals_tracked += 1
            
            for day_n, (_, row) in enumerate(future.iterrows(), 1):
                if day_n in existing_days:
                    continue
                
                trade_date = row['date'].strftime('%Y-%m-%d')
                
                # ìˆ˜ìµë¥  ê³„ì‚°
                open_price = row.get('open', 0)
                close_price = row.get('close', 0)
                high_price = row.get('high', 0)
                low_price = row.get('low', 0)
                volume = int(row.get('volume', 0))
                
                gap_rate = (open_price / signal_close - 1) * 100 if day_n == 1 else 0
                return_from_signal = (close_price / signal_close - 1) * 100
                high_return = (high_price / signal_close - 1) * 100
                low_return = (low_price / signal_close - 1) * 100
                
                db.execute(
                    """INSERT OR IGNORE INTO pullback_daily_prices 
                    (pullback_signal_id, stock_code, trade_date, days_after,
                     open_price, high_price, low_price, close_price, volume,
                     gap_rate, return_from_signal, high_return, low_return)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (signal_id, stock_code, trade_date, day_n,
                     open_price, high_price, low_price, close_price, volume,
                     gap_rate, return_from_signal, high_return, low_return),
                )
                prices_updated += 1
                
        except Exception as e:
            logger.warning(f"[pullback_tracker] {stock_code} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue''',
    "new": '''    # OHLCV ë°ì´í„° ê²½ë¡œ
    ohlcv_dir = DATA_DIR / "ohlcv_kiwoom"
    
    # API í´ë°±ìš© í´ë¼ì´ì–¸íŠ¸ (lazy init)
    _api_client = None
    
    def _get_api_client():
        nonlocal _api_client
        if _api_client is None:
            try:
                from src.adapters.kiwoom_rest_client import get_kiwoom_client
                _api_client = get_kiwoom_client()
            except Exception as e:
                logger.warning(f"[pullback_tracker] API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return _api_client
    
    def _load_ohlcv_df(stock_code: str) -> Optional[pd.DataFrame]:
        """OHLCV CSV ë¡œë“œ, ì—†ìœ¼ë©´ API í´ë°±"""
        csv_path = ohlcv_dir / f"{stock_code}.csv"
        
        # 1ìˆœìœ„: CSV íŒŒì¼
        if csv_path.exists():
            try:
                df = pd.read_csv(csv_path)
                df.columns = df.columns.str.lower()
                df['date'] = pd.to_datetime(df['date'])
                return df.sort_values('date')
            except Exception as e:
                logger.debug(f"[pullback_tracker] CSV ë¡œë“œ ì‹¤íŒ¨ ({stock_code}): {e}")
        
        # 2ìˆœìœ„: í‚¤ì›€ API
        client = _get_api_client()
        if client:
            try:
                prices = client.get_daily_prices(stock_code, count=30)
                if prices:
                    rows = []
                    for p in prices:
                        rows.append({
                            'date': pd.to_datetime(getattr(p, 'date', None) or getattr(p, 'trade_date', None)),
                            'open': getattr(p, 'open', 0) or getattr(p, 'open_price', 0),
                            'high': getattr(p, 'high', 0) or getattr(p, 'high_price', 0),
                            'low': getattr(p, 'low', 0) or getattr(p, 'low_price', 0),
                            'close': getattr(p, 'close', 0) or getattr(p, 'close_price', 0),
                            'volume': getattr(p, 'volume', 0),
                        })
                    df = pd.DataFrame(rows)
                    df = df.dropna(subset=['date'])
                    if not df.empty:
                        logger.info(f"[pullback_tracker] API í´ë°±: {stock_code} â†’ {len(df)}ì¼")
                        return df.sort_values('date')
            except Exception as e:
                logger.debug(f"[pullback_tracker] API ì¡°íšŒ ì‹¤íŒ¨ ({stock_code}): {e}")
        
        logger.debug(f"[pullback_tracker] OHLCV ì—†ìŒ: {stock_code}")
        return None
    
    for sig in signals:
        signal_id = sig["id"]
        stock_code = sig["stock_code"]
        signal_date = sig["signal_date"]
        signal_close = sig["close_price"]
        
        if not signal_close or signal_close <= 0:
            continue
        
        # ì´ë¯¸ ì¶”ì  ì™„ë£Œëœ ì¼ìˆ˜ í™•ì¸
        existing = db.fetch_all(
            "SELECT days_after FROM pullback_daily_prices "
            "WHERE pullback_signal_id = ? ORDER BY days_after",
            (signal_id,),
        )
        existing_days = {r["days_after"] for r in existing}
        
        # D+tracking_daysê¹Œì§€ ì™„ë£Œë˜ë©´ ìŠ¤í‚µ
        if len(existing_days) >= tracking_days:
            continue
        
        # OHLCV ë°ì´í„° ë¡œë“œ (CSV â†’ API í´ë°±)
        df = _load_ohlcv_df(stock_code)
        if df is None:
            continue
        
        try:
            # signal_date ì´í›„ì˜ ê±°ë˜ì¼ ë°ì´í„°
            signal_dt = pd.to_datetime(signal_date)
            future = df[df['date'] > signal_dt].head(tracking_days)
            
            if future.empty:
                continue
            
            signals_tracked += 1
            
            for day_n, (_, row) in enumerate(future.iterrows(), 1):
                if day_n in existing_days:
                    continue
                
                trade_date = row['date'].strftime('%Y-%m-%d')
                
                # ìˆ˜ìµë¥  ê³„ì‚°
                open_price = row.get('open', 0)
                close_price = row.get('close', 0)
                high_price = row.get('high', 0)
                low_price = row.get('low', 0)
                volume = int(row.get('volume', 0))
                
                gap_rate = (open_price / signal_close - 1) * 100 if day_n == 1 else 0
                return_from_signal = (close_price / signal_close - 1) * 100
                high_return = (high_price / signal_close - 1) * 100
                low_return = (low_price / signal_close - 1) * 100
                
                db.execute(
                    """INSERT OR IGNORE INTO pullback_daily_prices 
                    (pullback_signal_id, stock_code, trade_date, days_after,
                     open_price, high_price, low_price, close_price, volume,
                     gap_rate, return_from_signal, high_return, low_return)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (signal_id, stock_code, trade_date, day_n,
                     open_price, high_price, low_price, close_price, volume,
                     gap_rate, return_from_signal, high_return, low_return),
                )
                prices_updated += 1
                
        except Exception as e:
            logger.warning(f"[pullback_tracker] {stock_code} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue'''
})

# ============================================================
# Patch 4: screener_service.py - VP ë§¤ë¬¼ëŒ€ ì˜¤ë¥˜ ë°©ì–´ + ë¡œê·¸ ì •ë¦¬
# ============================================================
PATCHES.append({
    "file": "src/services/screener_service.py",
    "desc": "VP ë§¤ë¬¼ëŒ€: None ë°©ì–´ + ë¡œê·¸ ìŠ¤íŒ¸ 76ê±´â†’1ì¤„ ìš”ì•½",
    "old": """            vp_data_cache = None
            for score in scores_filtered:
                code = score.stock_code
                price = score.current_price
                try:
                    vp_result = None
                    vp_meta = ""
                    
                    # í‚¤ì›€ API
                    if use_kiwoom and kiwoom_client and kiwoom_available:
                        try:
                            if vp_data_cache is None:
                                data = kiwoom_client.get_volume_profile(
                                    stock_code=code,
                                    cycle_tp=str(vp_cfg.cycle),
                                    prpscnt=str(vp_cfg.bands),
                                    cur_prc_entry=str(vp_cfg.cur_entry),
                                    trde_qty_tp=str(vp_cfg.trde_qty_tp),
                                    tr_id=str(vp_cfg.api_id),
                                )
                                if isinstance(data, dict) and not any(
                                    isinstance(v, list) and v for v in data.values()
                                ):
                                    kiwoom_available = False
                                    data = {}
                                vp_data_cache = data
                            else:
                                data = vp_data_cache
                            
                            vp_result = calc_volume_profile_from_kiwoom(
                                data=data, current_price=price,
                                n_days=vp_cfg.cycle, cur_entry=vp_cfg.cur_entry,
                                stock_code=code,
                            )
                            vp_meta = f"kiwoom/{vp_cfg.cycle}d/{vp_cfg.bands}b/cur{vp_cfg.cur_entry}"
                        except Exception as e:
                            logger.debug(f"VP(kiwoom) {code} ì˜¤ë¥˜: {e}")
                    
                    if vp_result is not None and vp_result.tag == "ë°ì´í„°ë¶€ì¡±":
                        vp_result = None
                    
                    # ë¡œì»¬ CSV í´ë°±
                    if vp_result is None and use_local:
                        vp_result = calc_volume_profile_from_csv(
                            stock_code=code, current_price=price,
                            ohlcv_dir=OHLCV_FULL_DIR,
                            n_days=vp_cfg.cycle, n_bands=vp_cfg.bands,
                        )
                        vp_meta = f"local/{vp_cfg.cycle}d/{vp_cfg.bands}b/cur{vp_cfg.cur_entry}"
                    
                    if vp_result is None:
                        vp_result = VolumeProfileResult()
                        vp_meta = ""
                    
                    score.score_detail.raw_vp_score = vp_result.score
                    score.score_detail.raw_vp_above_pct = vp_result.above_pct
                    score.score_detail.raw_vp_below_pct = vp_result.below_pct
                    score.score_detail.raw_vp_tag = vp_result.tag
                    score.score_detail.raw_vp_meta = vp_meta
                    if vp_result.tag != "ë°ì´í„°ë¶€ì¡±":
                        vp_count += 1
                except Exception as e:
                    logger.debug(f"VP {code} ì˜¤ë¥˜: {e}")
                    score.score_detail.raw_vp_score = VP_SCORE_NEUTRAL
                    score.score_detail.raw_vp_above_pct = 0.0
                    score.score_detail.raw_vp_below_pct = 0.0
                    score.score_detail.raw_vp_tag = "ì˜¤ë¥˜"
                    score.score_detail.raw_vp_meta = ""
            
            logger.info(f"[ë§¤ë¬¼ëŒ€] {vp_count}/{len(scores_filtered)}ê°œ ê³„ì‚° ì™„ë£Œ")""",
    "new": """            vp_data_cache = None
            vp_error_count = 0
            for score in scores_filtered:
                code = score.stock_code
                price = score.current_price
                try:
                    vp_result = None
                    vp_meta = ""
                    
                    # í‚¤ì›€ API
                    if use_kiwoom and kiwoom_client and kiwoom_available:
                        try:
                            if vp_data_cache is None:
                                data = kiwoom_client.get_volume_profile(
                                    stock_code=code,
                                    cycle_tp=str(vp_cfg.cycle),
                                    prpscnt=str(vp_cfg.bands),
                                    cur_prc_entry=str(vp_cfg.cur_entry),
                                    trde_qty_tp=str(vp_cfg.trde_qty_tp),
                                    tr_id=str(vp_cfg.api_id),
                                )
                                if isinstance(data, dict) and not any(
                                    isinstance(v, list) and v for v in data.values()
                                ):
                                    kiwoom_available = False
                                    data = {}
                                vp_data_cache = data
                            else:
                                data = vp_data_cache
                            
                            vp_result = calc_volume_profile_from_kiwoom(
                                data=data, current_price=price,
                                n_days=vp_cfg.cycle, cur_entry=vp_cfg.cur_entry,
                                stock_code=code,
                            )
                            vp_meta = f"kiwoom/{vp_cfg.cycle}d/{vp_cfg.bands}b/cur{vp_cfg.cur_entry}"
                        except Exception as e:
                            logger.debug(f"VP(kiwoom) {code} ì˜¤ë¥˜: {e}")
                    
                    if vp_result is not None and vp_result.tag == "ë°ì´í„°ë¶€ì¡±":
                        vp_result = None
                    
                    # ë¡œì»¬ CSV í´ë°±
                    if vp_result is None and use_local:
                        vp_result = calc_volume_profile_from_csv(
                            stock_code=code, current_price=price,
                            ohlcv_dir=OHLCV_FULL_DIR,
                            n_days=vp_cfg.cycle, n_bands=vp_cfg.bands,
                        )
                        vp_meta = f"local/{vp_cfg.cycle}d/{vp_cfg.bands}b/cur{vp_cfg.cur_entry}"
                    
                    if vp_result is None:
                        vp_result = VolumeProfileResult()
                        vp_meta = ""
                    
                    # ì•ˆì „í•œ ì†ì„± ì ‘ê·¼ (score_detail ë˜ëŠ” vp_resultê°€ Noneì¸ ì¼€ì´ìŠ¤ ë°©ì–´)
                    if score.score_detail is not None and vp_result is not None:
                        score.score_detail.raw_vp_score = vp_result.score
                        score.score_detail.raw_vp_above_pct = vp_result.above_pct
                        score.score_detail.raw_vp_below_pct = vp_result.below_pct
                        score.score_detail.raw_vp_tag = vp_result.tag
                        score.score_detail.raw_vp_meta = vp_meta
                        if vp_result.tag != "ë°ì´í„°ë¶€ì¡±":
                            vp_count += 1
                    else:
                        vp_error_count += 1
                except Exception as e:
                    vp_error_count += 1
                    if score.score_detail is not None:
                        score.score_detail.raw_vp_score = VP_SCORE_NEUTRAL
                        score.score_detail.raw_vp_above_pct = 0.0
                        score.score_detail.raw_vp_below_pct = 0.0
                        score.score_detail.raw_vp_tag = "ì˜¤ë¥˜"
                        score.score_detail.raw_vp_meta = ""
            
            # ìš”ì•½ ë¡œê·¸ (ê°œë³„ ì˜¤ë¥˜ ìŠ¤íŒ¸ ì œê±°)
            if vp_error_count > 0:
                logger.info(f"[ë§¤ë¬¼ëŒ€] {vp_count}/{len(scores_filtered)}ê°œ ê³„ì‚° ì™„ë£Œ (ì˜¤ë¥˜: {vp_error_count}ê°œ)")
            else:
                logger.info(f"[ë§¤ë¬¼ëŒ€] {vp_count}/{len(scores_filtered)}ê°œ ê³„ì‚° ì™„ë£Œ")"""
})

# ============================================================
# Patch 5a: 1_top5_tracker.py - CSS #888 â†’ #888888 (ìš”ì•½ì¹´ë“œ)
# ============================================================
PATCHES.append({
    "file": "dashboard/pages/1_top5_tracker.py",
    "desc": "CSS hex 3ìë¦¬â†’6ìë¦¬ ìˆ˜ì • (ìš”ì•½ì¹´ë“œ rec_color)",
    "old": "rec_color = {'ë§¤ìˆ˜': '#4CAF50', 'ê´€ë§': '#FF9800', 'ë§¤ë„': '#F44336'}.get(ai_rec, '#888')",
    "new": "rec_color = {'ë§¤ìˆ˜': '#4CAF50', 'ê´€ë§': '#FF9800', 'ë§¤ë„': '#F44336'}.get(ai_rec, '#888888')",
})

# ============================================================
# Patch 5b: 1_top5_tracker.py - CSS #888 â†’ #888888 (ìƒì„¸ë¶„ì„)
# ============================================================
PATCHES.append({
    "file": "dashboard/pages/1_top5_tracker.py",
    "desc": "CSS hex 3ìë¦¬â†’6ìë¦¬ ìˆ˜ì • (ìƒì„¸ë¶„ì„ risk_color)",
    "old": "risk_color = {'ë†’ìŒ': '#4CAF50', 'ë³´í†µ': '#FF9800', 'ë‚®ìŒ': '#F44336'}.get(ai_risk, '#888')",
    "new": "risk_color = {'ë†’ìŒ': '#4CAF50', 'ë³´í†µ': '#FF9800', 'ë‚®ìŒ': '#F44336'}.get(ai_risk, '#888888')",
})


# ============================================================
# íŒ¨ì¹˜ ì ìš© ì—”ì§„
# ============================================================

def apply_patches(dry_run=False, revert=False):
    """íŒ¨ì¹˜ ì ìš©/ë³µì›"""
    
    if revert:
        return revert_from_backup()
    
    print(f"{'ğŸ” DRY RUN' if dry_run else 'ğŸ”§ APPLYING'} - ClosingBell v10.1.1 íŒ¨ì¹˜")
    print(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}")
    print(f"íŒ¨ì¹˜ ìˆ˜: {len(PATCHES)}ê°œ")
    print("=" * 60)
    
    # ë°±ì—…
    if not dry_run:
        BACKUP_DIR.mkdir(exist_ok=True)
        backed_up = set()
        for p in PATCHES:
            fpath = PROJECT_ROOT / p["file"]
            if fpath.exists() and p["file"] not in backed_up:
                backup_path = BACKUP_DIR / p["file"].replace("/", "_").replace("\\", "_")
                shutil.copy2(fpath, backup_path)
                backed_up.add(p["file"])
        print(f"ğŸ“¦ ë°±ì—… ì™„ë£Œ: {len(backed_up)}ê°œ íŒŒì¼ â†’ {BACKUP_DIR}")
        print()
    
    success = 0
    failed = 0
    skipped = 0
    
    for i, p in enumerate(PATCHES, 1):
        fpath = PROJECT_ROOT / p["file"]
        print(f"[{i}/{len(PATCHES)}] {p['file']}")
        print(f"  ğŸ“ {p['desc']}")
        
        if not fpath.exists():
            print(f"  âŒ íŒŒì¼ ì—†ìŒ!")
            failed += 1
            continue
        
        content = fpath.read_text(encoding='utf-8')
        
        if p["old"] not in content:
            if p["new"] in content:
                print(f"  â­ï¸ ì´ë¯¸ ì ìš©ë¨ (ìŠ¤í‚µ)")
                skipped += 1
            else:
                print(f"  âŒ ë§¤ì¹­ ì‹¤íŒ¨! (ì½”ë“œê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŒ)")
                failed += 1
            continue
        
        # ìœ ì¼ì„± ê²€ì¦
        count = content.count(p["old"])
        if count > 1:
            print(f"  âš ï¸ ì¤‘ë³µ ë§¤ì¹­ {count}íšŒ (ì²« ë²ˆì§¸ë§Œ êµì²´)")
        
        new_content = content.replace(p["old"], p["new"], 1)
        
        if dry_run:
            print(f"  âœ… ë§¤ì¹­ ì„±ê³µ (ì ìš© ê°€ëŠ¥)")
        else:
            fpath.write_text(new_content, encoding='utf-8')
            print(f"  âœ… ì ìš© ì™„ë£Œ")
        
        success += 1
    
    print()
    print("=" * 60)
    print(f"ê²°ê³¼: âœ… {success}ê°œ ì„±ê³µ | â­ï¸ {skipped}ê°œ ìŠ¤í‚µ | âŒ {failed}ê°œ ì‹¤íŒ¨")
    
    if not dry_run and failed == 0:
        print()
        print("ğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
        print("  1. python test_patch_v10.1.1.py   â† ë¡œì»¬ ê²€ì¦ ì‹¤í–‰")
        print("  2. ê±°ë˜ì¼ì— python main.py ì‹¤í–‰ í›„ ë¡œê·¸ í™•ì¸")
    
    return failed == 0


def revert_from_backup():
    """ë°±ì—…ì—ì„œ ë³µì›"""
    if not BACKUP_DIR.exists():
        print(f"âŒ ë°±ì—… ë””ë ‰í† ë¦¬ ì—†ìŒ: {BACKUP_DIR}")
        return False
    
    restored = 0
    for backup_file in BACKUP_DIR.iterdir():
        # ì—­ë³€í™˜: src_services_xxx.py â†’ src/services/xxx.py
        # ì›ë³¸ ì´ë¦„ ì¶”ì • (ë‹¨ìˆœ ë§¤í•‘)
        original_name = None
        for p in PATCHES:
            expected_backup = p["file"].replace("/", "_").replace("\\", "_")
            if backup_file.name == expected_backup:
                original_name = p["file"]
                break
        
        if original_name:
            target = PROJECT_ROOT / original_name
            shutil.copy2(backup_file, target)
            print(f"  â™»ï¸ ë³µì›: {original_name}")
            restored += 1
    
    print(f"\nâœ… {restored}ê°œ íŒŒì¼ ë³µì› ì™„ë£Œ")
    return True


if __name__ == "__main__":
    dry_run = "--dry-run" in sys.argv
    revert = "--revert" in sys.argv
    
    if not apply_patches(dry_run=dry_run, revert=revert):
        sys.exit(1)
