"""ëˆŒë¦¼ëª©(ê±°ê°ìŒë´‰) ìŠ¤ìºë„ˆ v9.1

ìœ ëª©ë¯¼ ê±°ë˜ëŸ‰ ë‹¨íƒ€ë²• ê¸°ë°˜:
1) ê±°ë˜ëŸ‰ 1000ë§Œì£¼+ í­ë°œ ê°ì§€ â†’ ê°ì‹œí’€ ë“±ë¡
2) D+1~D+3 ëª¨ë‹ˆí„°ë§: ê±°ê° 80%â†‘ + ìŒë´‰ + MA ì§€ì§€ â†’ ì‹œê·¸ë„
3) ì¬ë£Œ/ì„¹í„° í•„í„°: ì£¼ë„ì„¹í„° ìœ ì§€, ë‰´ìŠ¤ ì¡´ì¬

ìŠ¤ì¼€ì¤„:
  15:10 â†’ run_pullback_scan()        ëˆŒë¦¼ëª© ì‹œê·¸ë„ (ì‹¤ì‹œê°„ API) + ë””ìŠ¤ì½”ë“œ
  16:05 â†’ run_volume_spike_scan()    ê±°ë˜ëŸ‰ í­ë°œ ê°ì§€ (OHLCV CSV)
"""

import logging
import os
import csv
import json
import time
from pathlib import Path
from datetime import date, datetime, timedelta
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional, Tuple

import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)


# ============================================================
# ì„¤ì •
# ============================================================

VOLUME_SPIKE_MIN = 10_000_000       # ìµœì†Œ ê±°ë˜ëŸ‰ (1000ë§Œì£¼)
VOLUME_SPIKE_MA_RATIO = 3.0         # 20ì¼ í‰ê·  ëŒ€ë¹„ ë°°ìˆ˜
PULLBACK_WATCH_DAYS = 3             # ê°ì‹œ ê¸°ê°„ (D+1 ~ D+3)
PULLBACK_VOL_RATIO = 0.20           # ê±°ë˜ëŸ‰ ê¸‰ê° ê¸°ì¤€ (í­ë°œì¼ ëŒ€ë¹„ 20% ì´í•˜)
PULLBACK_MA_TOLERANCE = 0.02        # MA ì§€ì§€ í—ˆìš© ì˜¤ì°¨ (Â±2%)
PULLBACK_MAX_DROP = 0.15            # ê³ ì  ëŒ€ë¹„ ìµœëŒ€ ë‚™í­ 15%


# ============================================================
# ëª¨ë¸
# ============================================================

@dataclass
class VolumeSpike:
    """ê±°ë˜ëŸ‰ í­ë°œ ê°ì§€ ê²°ê³¼"""
    stock_code: str
    stock_name: str
    spike_date: str           # YYYY-MM-DD
    spike_volume: int
    volume_ma20: int
    spike_ratio: float        # volume / ma20
    open_price: float
    high_price: float
    low_price: float
    close_price: float
    change_pct: float         # ë“±ë½ë¥ 
    sector: str = ""
    theme: str = ""
    is_leading_sector: bool = False


@dataclass
class PullbackSignal:
    """ëˆŒë¦¼ëª© ì‹œê·¸ë„"""
    stock_code: str
    stock_name: str
    spike_date: str           # í­ë°œì¼
    signal_date: str          # ì‹œê·¸ë„ ë°œìƒì¼
    days_after: int           # D+N
    # ê°€ê²©
    close_price: float
    open_price: float
    spike_high: float
    drop_from_high_pct: float  # ê³ ì  ëŒ€ë¹„ ë‚™í­ %
    # ê±°ë˜ëŸ‰
    today_volume: int
    spike_volume: int
    vol_decrease_pct: float    # ê±°ë˜ëŸ‰ ê°ì†Œìœ¨ (0.15 = í­ë°œì¼ì˜ 15%)
    # MA ì§€ì§€
    ma5: float
    ma20: float
    ma_support: str            # "5ì¼ì„ " / "20ì¼ì„ " / "ì—†ìŒ"
    ma_distance_pct: float     # MAì™€ì˜ ê±°ë¦¬ %
    # í•„í„°
    is_negative_candle: bool
    sector: str = ""
    is_leading_sector: bool = False
    has_recent_news: bool = False
    # ì¢…í•©
    signal_strength: str = ""  # "ê°•", "ì¤‘", "ì•½"
    reason: str = ""


# ============================================================
# OHLCV ë¡œë”© (CSV ê¸°ë°˜ - 16:05 í­ë°œê°ì§€ìš©)
# ============================================================

def _load_ohlcv(code: str) -> Optional[pd.DataFrame]:
    """ì¢…ëª© OHLCV ë¡œë“œ (ë¡œì»¬ CSV)"""
    try:
        from src.config.app_config import OHLCV_DIR, OHLCV_FULL_DIR
    except ImportError:
        return None

    bases = []
    for d in [OHLCV_DIR, OHLCV_FULL_DIR]:
        if d and d not in bases:
            bases.append(d)
    try:
        from src.config.backfill_config import get_backfill_config
        cfg = get_backfill_config()
        bd = cfg.get_active_ohlcv_dir()
        if bd and bd not in bases:
            bases.append(bd)
    except Exception:
        pass

    for base in bases:
        for name in [f"{code}.csv", f"A{code}.csv"]:
            p = Path(base) / name
            if p.exists():
                try:
                    from src.services.backfill.data_loader import load_single_ohlcv
                    return load_single_ohlcv(p)
                except Exception:
                    pass
    return None


# ============================================================
# ì‹¤ì‹œê°„ OHLCV ë¡œë”© (í‚¤ì›€ API - 15:10 ëˆŒë¦¼ëª©ìš©)
# ============================================================

def _load_ohlcv_live(code: str, days: int = 30) -> Optional[pd.DataFrame]:
    """ì‹¤ì‹œê°„ OHLCV ë¡œë“œ (í‚¤ì›€ API â†’ FDR â†’ CSV ìˆœ í´ë°±)

    15:10 ì‹œì ì—ëŠ” OHLCV CSVê°€ ì•„ì§ ê°±ì‹  ì•ˆ ëìœ¼ë¯€ë¡œ
    í‚¤ì›€ APIë¡œ ë‹¹ì¼ í¬í•¨ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´.
    """
    # 1) í‚¤ì›€ API (ì‹¤ì‹œê°„, ë‹¹ì¼ í¬í•¨)
    try:
        from src.adapters.kiwoom_rest_client import KiwoomRestClient
        client = KiwoomRestClient()
        prices = client.get_daily_prices(code, count=days)
        if prices and len(prices) >= 5:
            rows = []
            for p in prices:
                rows.append({
                    "date": pd.Timestamp(p.date),
                    "open": float(p.open),
                    "high": float(p.high),
                    "low": float(p.low),
                    "close": float(p.close),
                    "volume": int(p.volume),
                })
            df = pd.DataFrame(rows).sort_values("date").reset_index(drop=True)
            logger.debug(f"[pullback] {code} í‚¤ì›€ API ë¡œë“œ: {len(df)}ì¼")
            return df
    except Exception as e:
        logger.debug(f"[pullback] {code} í‚¤ì›€ API ì‹¤íŒ¨: {e}")

    # 2) FDR (ì¥ ë§ˆê° í›„ì—ë§Œ ë‹¹ì¼ ë°˜ì˜)
    try:
        import FinanceDataReader as fdr
        end = datetime.now().date()
        start = end - timedelta(days=days * 2)
        df = fdr.DataReader(code, start.strftime("%Y-%m-%d"), end.strftime("%Y-%m-%d"))
        if df is not None and not df.empty:
            df = df.reset_index()
            df.columns = [c.lower() for c in df.columns]
            if "date" not in df.columns and "index" in df.columns:
                df = df.rename(columns={"index": "date"})
            df["date"] = pd.to_datetime(df["date"])
            logger.debug(f"[pullback] {code} FDR ë¡œë“œ: {len(df)}ì¼")
            return df
    except Exception as e:
        logger.debug(f"[pullback] {code} FDR ì‹¤íŒ¨: {e}")

    # 3) CSV í´ë°±
    return _load_ohlcv(code)


def _load_stock_names() -> Dict[str, str]:
    """ì¢…ëª© ë§¤í•‘ ë¡œë“œ (stock_mapping.csv â†’ FDR í´ë°±)"""
    names = {}
    try:
        from src.config.app_config import MAPPING_FILE
        if MAPPING_FILE and MAPPING_FILE.exists():
            with open(MAPPING_FILE, "r", encoding="utf-8-sig") as f:
                for row in csv.DictReader(f):
                    names[str(row.get("code", "")).zfill(6)] = row.get("name", "")
    except Exception:
        pass

    # FDR í´ë°± (ë¡œì»¬ ë§¤í•‘ì´ ë¶€ì¡±í•  ë•Œ)
    if len(names) < 100:
        try:
            import FinanceDataReader as fdr
            for market in ["KOSPI", "KOSDAQ"]:
                listing = fdr.StockListing(market)
                if listing is not None and not listing.empty:
                    for _, row in listing.iterrows():
                        code = str(row.get("Code", "")).strip().zfill(6)
                        name = str(row.get("Name", "")).strip()
                        if code and name and code not in names:
                            names[code] = name
        except Exception:
            pass

    return names


def _get_all_codes() -> List[str]:
    """ì „ì²´ ì¢…ëª©ì½”ë“œ ë¦¬ìŠ¤íŠ¸ (OHLCV íŒŒì¼ ê¸°ë°˜)"""
    codes = []
    try:
        from src.config.app_config import OHLCV_DIR, OHLCV_FULL_DIR
        dirs = []
        for d in [OHLCV_DIR, OHLCV_FULL_DIR]:
            if d and d.exists():
                dirs.append(d)
        try:
            from src.config.backfill_config import get_backfill_config
            cfg = get_backfill_config()
            bd = cfg.get_active_ohlcv_dir()
            if bd and bd.exists():
                dirs.append(bd)
        except Exception:
            pass

        seen = set()
        for d in dirs:
            for f in d.glob("*.csv"):
                code = f.stem.replace("A", "")
                if code.isdigit() and len(code) == 6 and code not in seen:
                    seen.add(code)
                    codes.append(code)
    except Exception as e:
        logger.error(f"[pullback] ì¢…ëª©ì½”ë“œ ë¡œë”© ì‹¤íŒ¨: {e}")
    return codes


# ============================================================
# ì¬ë£Œ/ì„¹í„°/ë‰´ìŠ¤ Enrichment (3ë‹¨ê³„ í•„í„°)
# ============================================================

def _enrich_sector(code: str) -> Tuple[str, bool]:
    """ì¢…ëª©ì˜ ì„¹í„° + ì£¼ë„ì„¹í„° ì—¬ë¶€ ì¡°íšŒ

    Returns:
        (ì„¹í„°ëª…, ì£¼ë„ì„¹í„°ì—¬ë¶€)
    """
    sector = ""
    is_leading = False

    # 1) stock_mapping.csvì—ì„œ ì—…ì¢… ì¡°íšŒ
    try:
        from src.services.company_service import get_sector_from_mapping
        sector = get_sector_from_mapping(code) or ""
    except Exception as e:
        logger.debug(f"[pullback] ì„¹í„° ì¡°íšŒ ì‹¤íŒ¨ ({code}): {e}")

    # 2) ì£¼ë„ì„¹í„° íŒë³„ (ìºì‹œëœ ê²°ê³¼ ì‚¬ìš©)
    if sector:
        try:
            from src.services.sector_service import SectorService
            svc = SectorService()
            leading = svc.get_leading_sectors()
            is_leading = sector in leading
        except Exception:
            pass

    return sector, is_leading


def _check_recent_news(stock_name: str, days: int = 3) -> Tuple[bool, str]:
    """ìµœê·¼ Nì¼ ë‰´ìŠ¤ ì¡´ì¬ ì—¬ë¶€ + ì²«ë²ˆì§¸ í—¤ë“œë¼ì¸

    Returns:
        (ë‰´ìŠ¤ì¡´ì¬ì—¬ë¶€, ëŒ€í‘œí—¤ë“œë¼ì¸)
    """
    try:
        from src.services.news_service import search_naver_news
        query = f"{stock_name} ì£¼ì‹"
        news_list = search_naver_news(query, display=5, sort='date')

        if not news_list:
            return False, ""

        # ìµœê·¼ Nì¼ ì´ë‚´ ë‰´ìŠ¤ í•„í„°
        from datetime import timedelta
        cutoff = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
        recent = []
        for n in news_list:
            pub = n.get("pub_date", "")
            # pub_dateê°€ RFC 822 í˜•ì‹ì¼ ìˆ˜ ìˆìŒ
            news_date = n.get("news_date", "")
            if not news_date and pub:
                try:
                    from src.services.news_service import parse_pub_date
                    news_date = parse_pub_date(pub) or ""
                except Exception:
                    pass
            if news_date and news_date >= cutoff:
                recent.append(n)

        if recent:
            headline = recent[0].get("title", "")[:60]
            return True, headline
        # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë‰´ìŠ¤ ì¡´ì¬ ìì²´ë¡œ íŒë‹¨
        if news_list:
            return True, news_list[0].get("title", "")[:60]
        return False, ""
    except Exception as e:
        logger.debug(f"[pullback] ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨ ({stock_name}): {e}")
        return False, ""


def _get_company_summary(code: str) -> str:
    """ê¸°ì—… í”„ë¡œí•„ í•œì¤„ ìš”ì•½ (DART ìºì‹œ)

    Returns:
        "ë°˜ë„ì²´ì¥ë¹„ | ë§¤ì¶œ 1,234ì–µ | ìœ„í—˜: ë‚®ìŒ" í˜•íƒœ
    """
    try:
        from src.infrastructure.repository import get_company_profile_repository
        repo = get_company_profile_repository()
        profile = repo.get_by_code(code)
        if not profile:
            return ""

        parts = []
        # ì—…ì¢…
        induty = profile.get("induty_code", "")
        if induty:
            parts.append(induty)
        # ë§¤ì¶œ
        revenue = profile.get("revenue")
        if revenue and revenue > 0:
            if revenue >= 10000:
                parts.append(f"ë§¤ì¶œ {revenue/10000:.1f}ì¡°")
            elif revenue >= 1:
                parts.append(f"ë§¤ì¶œ {revenue:.0f}ì–µ")
        # ìœ„í—˜ë„
        risk = profile.get("risk_level", "")
        if risk and risk != "ë‚®ìŒ":
            parts.append(f"âš ï¸ìœ„í—˜:{risk}")
        # ë¦¬ìŠ¤í¬ ìš”ì•½
        risk_summary = profile.get("risk_summary", "")
        if risk_summary:
            parts.append(risk_summary[:30])

        return " | ".join(parts)
    except Exception:
        return ""


def _enrich_spike(spike: VolumeSpike) -> VolumeSpike:
    """ê±°ë˜ëŸ‰ í­ë°œ ì¢…ëª©ì— ì„¹í„° ì •ë³´ ë³´ê°•"""
    sector, is_leading = _enrich_sector(spike.stock_code)
    spike.sector = sector
    spike.is_leading_sector = is_leading
    return spike


def _enrich_signal(signal: PullbackSignal) -> PullbackSignal:
    """ëˆŒë¦¼ëª© ì‹œê·¸ë„ì— ì„¹í„°/ë‰´ìŠ¤/ê¸°ì—… ì •ë³´ ë³´ê°•"""
    # ì„¹í„°
    sector, is_leading = _enrich_sector(signal.stock_code)
    signal.sector = sector
    signal.is_leading_sector = is_leading

    # ë‰´ìŠ¤ (ìµœê·¼ 3ì¼)
    has_news, headline = _check_recent_news(signal.stock_name, days=3)
    signal.has_recent_news = has_news

    # reasonì— ì„¹í„°/ë‰´ìŠ¤ ì •ë³´ ì¶”ê°€
    extras = []
    if sector:
        label = f"{'ğŸ”¥' if is_leading else 'ğŸ“‚'}{sector}"
        extras.append(label)
    if has_news and headline:
        extras.append(f"ğŸ“°{headline}")
    elif not has_news:
        extras.append("ğŸ“°ì¬ë£Œì—†ìŒ")

    if extras:
        signal.reason = signal.reason + " | " + " | ".join(extras)

    return signal


# ============================================================
# 1ë‹¨ê³„: ê±°ë˜ëŸ‰ í­ë°œ ê°ì§€
# ============================================================

def scan_volume_spikes(target_date: Optional[date] = None) -> List[VolumeSpike]:
    """ì „ì²´ ì¢…ëª©ì—ì„œ ê±°ë˜ëŸ‰ í­ë°œ ê°ì§€

    Args:
        target_date: ê²€ì‚¬ ë‚ ì§œ (ê¸°ë³¸: ì˜¤ëŠ˜)

    Returns:
        ê±°ë˜ëŸ‰ í­ë°œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
    """
    if target_date is None:
        target_date = date.today()

    date_str = target_date.strftime("%Y-%m-%d")
    logger.info(f"[pullback] ê±°ë˜ëŸ‰ í­ë°œ ìŠ¤ìº” ì‹œì‘: {date_str}")

    codes = _get_all_codes()
    if not codes:
        logger.warning("[pullback] OHLCV íŒŒì¼ ì—†ìŒ")
        return []

    names = _load_stock_names()
    spikes = []

    for code in codes:
        df = _load_ohlcv(code)
        if df is None or len(df) < 25:
            continue

        # ë‚ ì§œ í•„í„°
        df["date_str"] = df["date"].dt.strftime("%Y-%m-%d")
        today_row = df[df["date_str"] == date_str]
        if today_row.empty:
            continue

        row = today_row.iloc[-1]
        vol = int(row["volume"])

        # ê±°ë˜ëŸ‰ ìµœì†Œ ê¸°ì¤€
        if vol < VOLUME_SPIKE_MIN:
            continue

        # 20ì¼ ì´ë™í‰ê·  ê³„ì‚°
        idx = today_row.index[0]
        pos = df.index.get_loc(idx)
        if pos < 20:
            continue

        vol_ma20 = int(df.iloc[pos - 20:pos]["volume"].mean())
        if vol_ma20 <= 0:
            continue

        ratio = vol / vol_ma20
        if ratio < VOLUME_SPIKE_MA_RATIO:
            continue

        # ë“±ë½ë¥ 
        prev_close = float(df.iloc[pos - 1]["close"]) if pos > 0 else float(row["open"])
        change_pct = ((float(row["close"]) - prev_close) / prev_close * 100) if prev_close > 0 else 0

        spike = VolumeSpike(
            stock_code=code,
            stock_name=names.get(code, code),
            spike_date=date_str,
            spike_volume=vol,
            volume_ma20=vol_ma20,
            spike_ratio=round(ratio, 1),
            open_price=float(row["open"]),
            high_price=float(row["high"]),
            low_price=float(row["low"]),
            close_price=float(row["close"]),
            change_pct=round(change_pct, 2),
        )
        spike = _enrich_spike(spike)
        spikes.append(spike)

    # ê±°ë˜ëŸ‰ ë°°ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
    spikes.sort(key=lambda s: s.spike_ratio, reverse=True)
    logger.info(f"[pullback] ê±°ë˜ëŸ‰ í­ë°œ ê°ì§€: {len(spikes)}ê°œ ì¢…ëª©")

    # DB ì €ì¥
    _save_spikes(spikes)

    return spikes


def _save_spikes(spikes: List[VolumeSpike]):
    """ê±°ë˜ëŸ‰ í­ë°œ DB ì €ì¥"""
    if not spikes:
        return
    try:
        from src.infrastructure.repository import get_pullback_repository
        repo = get_pullback_repository()
        for s in spikes:
            repo.save_spike(s)
        logger.info(f"[pullback] {len(spikes)}ê°œ í­ë°œ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"[pullback] í­ë°œ ì €ì¥ ì‹¤íŒ¨: {e}")


# ============================================================
# 2ë‹¨ê³„: ëˆŒë¦¼ëª© ì‹œê·¸ë„ ê°ì§€
# ============================================================

def scan_pullback_signals(target_date: Optional[date] = None) -> List[PullbackSignal]:
    """ê°ì‹œí’€ ì¢…ëª©ì—ì„œ ëˆŒë¦¼ëª© ì‹œê·¸ë„ ê°ì§€

    Args:
        target_date: ê²€ì‚¬ ë‚ ì§œ (ê¸°ë³¸: ì˜¤ëŠ˜)

    Returns:
        ëˆŒë¦¼ëª© ì‹œê·¸ë„ ë¦¬ìŠ¤íŠ¸
    """
    if target_date is None:
        target_date = date.today()

    date_str = target_date.strftime("%Y-%m-%d")
    logger.info(f"[pullback] ëˆŒë¦¼ëª© ì‹œê·¸ë„ ìŠ¤ìº”: {date_str}")

    # ê°ì‹œí’€ ì¡°íšŒ (ìµœê·¼ PULLBACK_WATCH_DAYSì¼ ì´ë‚´ í­ë°œ ì¢…ëª©)
    try:
        from src.infrastructure.repository import get_pullback_repository
        repo = get_pullback_repository()
        watch_list = repo.get_active_spikes(target_date, PULLBACK_WATCH_DAYS)
    except Exception as e:
        logger.error(f"[pullback] ê°ì‹œí’€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

    if not watch_list:
        logger.info("[pullback] ê°ì‹œí’€ ë¹„ì–´ìˆìŒ")
        return []

    logger.info(f"[pullback] ê°ì‹œí’€: {len(watch_list)}ê°œ ì¢…ëª©")

    signals = []
    names = _load_stock_names()

    for spike_row in watch_list:
        spike = dict(spike_row) if not isinstance(spike_row, dict) else spike_row
        code = spike["stock_code"]
        spike_date_str = spike["spike_date"]
        spike_vol = int(spike["spike_volume"])
        spike_high = float(spike["high_price"])

        df = _load_ohlcv_live(code, days=30)  # ì‹¤ì‹œê°„ API (15:10)
        if df is None or len(df) < 20:
            continue

        # ì˜¤ëŠ˜ ë°ì´í„°
        df["date_str"] = df["date"].dt.strftime("%Y-%m-%d")
        today_data = df[df["date_str"] == date_str]
        if today_data.empty:
            continue

        row = today_data.iloc[-1]
        idx = today_data.index[0]
        pos = df.index.get_loc(idx)

        close = float(row["close"])
        open_p = float(row["open"])
        vol = int(row["volume"])

        # D+N ê³„ì‚°
        spike_dt = datetime.strptime(spike_date_str, "%Y-%m-%d").date()
        days_after = (target_date - spike_dt).days
        if days_after < 1 or days_after > PULLBACK_WATCH_DAYS:
            continue

        # â”€â”€ ì¡°ê±´ ì²´í¬ â”€â”€

        # 1. ê±°ë˜ëŸ‰ ê¸‰ê° (í­ë°œì¼ ëŒ€ë¹„ 20% ì´í•˜)
        vol_ratio = vol / spike_vol if spike_vol > 0 else 1.0
        if vol_ratio > PULLBACK_VOL_RATIO:
            continue

        # 2. ìŒë´‰
        is_negative = close < open_p
        if not is_negative:
            continue

        # 3. MA ì§€ì§€ (5ì¼ì„  or 20ì¼ì„  Â±2%)
        ma5 = float(df.iloc[max(0, pos - 4):pos + 1]["close"].mean()) if pos >= 4 else 0
        ma20 = float(df.iloc[max(0, pos - 19):pos + 1]["close"].mean()) if pos >= 19 else 0

        ma_support = "ì—†ìŒ"
        ma_dist = 999.0

        if ma5 > 0:
            dist5 = abs(close - ma5) / ma5
            if dist5 <= PULLBACK_MA_TOLERANCE:
                ma_support = "5ì¼ì„ "
                ma_dist = dist5
        if ma20 > 0:
            dist20 = abs(close - ma20) / ma20
            if dist20 <= PULLBACK_MA_TOLERANCE:
                if ma_support == "ì—†ìŒ" or dist20 < ma_dist:
                    ma_support = "20ì¼ì„ "
                    ma_dist = dist20

        if ma_support == "ì—†ìŒ":
            continue

        # 4. ê³ ì  ëŒ€ë¹„ ë‚™í­ ì œí•œ
        drop_pct = (spike_high - close) / spike_high if spike_high > 0 else 0
        if drop_pct > PULLBACK_MAX_DROP:
            continue

        # â”€â”€ ì‹œê·¸ë„ ê°•ë„ íŒì • â”€â”€
        strength = "ì¤‘"
        reasons = []
        if vol_ratio <= 0.10:
            reasons.append("ê±°ë˜ëŸ‰ 90%â†‘ ê¸‰ê°")
            strength = "ê°•"
        elif vol_ratio <= 0.15:
            reasons.append(f"ê±°ë˜ëŸ‰ {(1 - vol_ratio) * 100:.0f}% ê¸‰ê°")
            strength = "ê°•"
        else:
            reasons.append(f"ê±°ë˜ëŸ‰ {(1 - vol_ratio) * 100:.0f}% ê°ì†Œ")

        reasons.append(f"{ma_support} ì§€ì§€ ({ma_dist * 100:.1f}%)")
        if drop_pct <= 0.05:
            reasons.append("ê³ ì  ê·¼ì ‘")
            if strength != "ê°•":
                strength = "ê°•"

        signal = PullbackSignal(
            stock_code=code,
            stock_name=names.get(code, spike.get("stock_name", code)),
            spike_date=spike_date_str,
            signal_date=date_str,
            days_after=days_after,
            close_price=close,
            open_price=open_p,
            spike_high=spike_high,
            drop_from_high_pct=round(drop_pct * 100, 1),
            today_volume=vol,
            spike_volume=spike_vol,
            vol_decrease_pct=round(vol_ratio, 3),
            ma5=round(ma5, 0),
            ma20=round(ma20, 0),
            ma_support=ma_support,
            ma_distance_pct=round(ma_dist * 100, 2),
            is_negative_candle=True,
            signal_strength=strength,
            reason=" | ".join(reasons),
        )
        signal = _enrich_signal(signal)
        signals.append(signal)

    # ê°•ë„ìˆœ ì •ë ¬
    order = {"ê°•": 0, "ì¤‘": 1, "ì•½": 2}
    signals.sort(key=lambda s: (order.get(s.signal_strength, 9), s.vol_decrease_pct))

    logger.info(f"[pullback] ëˆŒë¦¼ëª© ì‹œê·¸ë„: {len(signals)}ê°œ")

    # DB ì €ì¥
    _save_signals(signals)

    # ë””ìŠ¤ì½”ë“œ ì•Œë¦¼
    if signals:
        _notify_discord(signals)

    return signals


def _save_signals(signals: List[PullbackSignal]):
    """ëˆŒë¦¼ëª© ì‹œê·¸ë„ DB ì €ì¥"""
    if not signals:
        return
    try:
        from src.infrastructure.repository import get_pullback_repository
        repo = get_pullback_repository()
        for s in signals:
            repo.save_signal(s)
        logger.info(f"[pullback] {len(signals)}ê°œ ì‹œê·¸ë„ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"[pullback] ì‹œê·¸ë„ ì €ì¥ ì‹¤íŒ¨: {e}")


# ============================================================
# ë””ìŠ¤ì½”ë“œ ì•Œë¦¼
# ============================================================

def _notify_discord(signals: List[PullbackSignal]):
    """ëˆŒë¦¼ëª© ì‹œê·¸ë„ ë””ìŠ¤ì½”ë“œ ì•Œë¦¼ (ì„¹í„°/ë‰´ìŠ¤ í¬í•¨)"""
    try:
        from src.adapters.discord_notifier import DiscordNotifier
        notifier = DiscordNotifier()

        # ì‹œê·¸ë„ ê°•ë„ë³„ ì¹´ìš´íŠ¸
        strong = sum(1 for s in signals if s.signal_strength == "ê°•")
        medium = sum(1 for s in signals if s.signal_strength == "ì¤‘")
        desc_parts = ["ê±°ë˜ëŸ‰ í­ë°œ í›„ ê±°ê°ìŒë´‰ + MA ì§€ì§€ ì¢…ëª©"]
        if strong:
            desc_parts.append(f"ğŸ”´ê°• {strong}ê°œ")
        if medium:
            desc_parts.append(f"ğŸŸ ì¤‘ {medium}ê°œ")

        embed = {
            "title": f"ğŸ“‰ ëˆŒë¦¼ëª© ì‹œê·¸ë„ {len(signals)}ê°œ ê°ì§€",
            "color": 0xFF6B35,
            "description": " | ".join(desc_parts),
            "fields": [],
            "footer": {"text": f"ClosingBell ëˆŒë¦¼ëª© ìŠ¤ìºë„ˆ | {date.today().strftime('%Y-%m-%d')}"},
        }

        for sig in signals[:10]:
            strength_emoji = {"ê°•": "ğŸ”´", "ì¤‘": "ğŸŸ ", "ì•½": "ğŸŸ¡"}.get(sig.signal_strength, "âšª")
            vol_pct = f"{sig.vol_decrease_pct * 100:.0f}%"

            value_lines = [
                f"ì¢…ê°€ {sig.close_price:,.0f}ì› | ê³ ì ëŒ€ë¹„ -{sig.drop_from_high_pct:.1f}%",
                f"ê±°ë˜ëŸ‰ í­ë°œì¼ì˜ {vol_pct} | {sig.ma_support} ì§€ì§€",
                f"D+{sig.days_after} | í­ë°œì¼: {sig.spike_date}",
            ]

            # ì„¹í„°/ì¬ë£Œ ì •ë³´
            info_parts = []
            if sig.sector:
                sector_icon = "ğŸ”¥" if sig.is_leading_sector else "ğŸ“‚"
                info_parts.append(f"{sector_icon}{sig.sector}")
            if sig.has_recent_news:
                info_parts.append("ğŸ“°ì¬ë£Œì‚´ì•„ìˆìŒ")
            else:
                info_parts.append("ğŸ“°ì¬ë£Œì—†ìŒ")

            # ê¸°ì—… í”„ë¡œí•„
            company_info = _get_company_summary(sig.stock_code)
            if company_info:
                info_parts.append(company_info)

            if info_parts:
                value_lines.append(" | ".join(info_parts))

            embed["fields"].append({
                "name": f"{strength_emoji} {sig.stock_name} ({sig.stock_code})",
                "value": "\n".join(value_lines),
                "inline": False,
            })

        notifier.send_embed(embed)
        logger.info(f"[pullback] ë””ìŠ¤ì½”ë“œ ì•Œë¦¼ ë°œì†¡: {len(signals)}ê°œ")
    except Exception as e:
        logger.warning(f"[pullback] ë””ìŠ¤ì½”ë“œ ì•Œë¦¼ ì‹¤íŒ¨: {e}")


# ============================================================
# ìŠ¤ì¼€ì¤„ëŸ¬ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
# ============================================================

def run_volume_spike_scan():
    """ìŠ¤ì¼€ì¤„ëŸ¬ìš©: ê±°ë˜ëŸ‰ í­ë°œ ìŠ¤ìº”"""
    return scan_volume_spikes()


def run_pullback_scan():
    """ìŠ¤ì¼€ì¤„ëŸ¬ìš©: ëˆŒë¦¼ëª© ì‹œê·¸ë„ ìŠ¤ìº”"""
    return scan_pullback_signals()