"""
AI ë¶„ì„ ì„œë¹„ìŠ¤ v6.2
====================

ìœ ëª©ë¯¼ ê³µë¶€ë²• ì¢…ëª©ì— ëŒ€í•´ Gemini 2.0 Flashë¡œ AI ë¶„ì„ ìƒì„±

ìŠ¤ì¼€ì¤„:
- 17:50 ê¸°ì—…ì •ë³´ ìˆ˜ì§‘ í›„ ìë™ ì‹¤í–‰

ì‚¬ìš©:
    python main.py --run-ai-analysis
    
    ë˜ëŠ” ì½”ë“œì—ì„œ:
    from src.services.ai_service import run_ai_analysis
    run_ai_analysis()
"""

import os
import json
import logging
import time
from datetime import date
from typing import Dict, Optional, List

from src.infrastructure.repository import (
    get_nomad_candidates_repository,
    get_nomad_news_repository,
)

logger = logging.getLogger(__name__)

# API í˜¸ì¶œ ê°„ê²© (ì´ˆ)
API_DELAY = 1.0


def format_market_cap(cap) -> str:
    """ì‹œê°€ì´ì•¡ í¬ë§·"""
    if cap is None or cap <= 0:
        return "-"
    if cap >= 10000:
        return f"{cap/10000:.1f}ì¡°"
    return f"{cap:,.0f}ì–µ"


def generate_ai_analysis(candidate: dict, news_list: list) -> tuple:
    """
    Gemini 2.0 Flashë¡œ AI ë¶„ì„ ìƒì„±
    
    Returns:
        (result_dict, error_message)
    """
    try:
        from google import genai
        from dotenv import load_dotenv
        
        # .env ë¡œë“œ
        load_dotenv()
        api_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
        
        if not api_key:
            return None, "Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        # ìƒˆ API í´ë¼ì´ì–¸íŠ¸
        client = genai.Client(api_key=api_key)
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        company_info = f"""
ì¢…ëª©: {candidate['stock_name']} ({candidate['stock_code']})
ë“±ë½ë¥ : {candidate['change_rate']:+.1f}%
ì‚¬ìœ : {candidate['reason_flag']}
ì‹œì¥: {candidate.get('market', '-')}
ì—…ì¢…: {candidate.get('sector', '-')}
ì‹œê°€ì´ì•¡: {format_market_cap(candidate.get('market_cap'))}
PER: {candidate.get('per', '-')}
PBR: {candidate.get('pbr', '-')}
ROE: {candidate.get('roe', '-')}%
ì™¸êµ­ì¸ë³´ìœ ìœ¨: {candidate.get('foreign_rate', '-')}%
ì‚¬ì—…ë‚´ìš©: {str(candidate.get('business_summary', '-'))[:300]}
"""
        
        news_text = ""
        if news_list:
            news_text = "\nê´€ë ¨ ë‰´ìŠ¤:\n"
            for news in news_list[:5]:
                sentiment = news.get('sentiment', 'ì¤‘ë¦½')
                title = news.get('news_title', '')
                news_text += f"- [{sentiment}] {title}\n"
        
        prompt = f"""
ë‹¤ìŒ ì¢…ëª©ì— ëŒ€í•´ ê°„ê²°í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”. ê° í•­ëª©ì€ 1-2ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

{company_info}
{news_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "summary": "í•µì‹¬ ìš”ì•½ (1ë¬¸ì¥)",
    "price_reason": "ì˜¤ëŠ˜ ì£¼ê°€ ì›€ì§ì„ ì›ì¸ ì¶”ì •",
    "investment_points": ["íˆ¬ì í¬ì¸íŠ¸ 1", "íˆ¬ì í¬ì¸íŠ¸ 2"],
    "risk_factors": ["ë¦¬ìŠ¤í¬ 1", "ë¦¬ìŠ¤í¬ 2"],
    "valuation_comment": "ë°¸ë¥˜ì—ì´ì…˜ ì˜ê²¬",
    "short_term_outlook": "ë‹¨ê¸° ì „ë§ (1-2ì£¼)",
    "recommendation": "ë§¤ìˆ˜/ê´€ë§/ë§¤ë„ ì¤‘ í•˜ë‚˜"
}}
"""
        
        # ìƒˆ API í˜¸ì¶œ
        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        result_text = response.text
        
        # JSON íŒŒì‹±
        if '```json' in result_text:
            result_text = result_text.split('```json')[1].split('```')[0]
        elif '```' in result_text:
            result_text = result_text.split('```')[1].split('```')[0]
        
        result = json.loads(result_text.strip())
        return result, None
        
    except ImportError:
        return None, "google-genai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install google-genai"
    except json.JSONDecodeError as e:
        return None, f"AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}"
    except Exception as e:
        return None, f"AI ë¶„ì„ ì‹¤íŒ¨: {e}"


def analyze_candidates_with_ai(study_date: str = None, limit: int = 50) -> Dict:
    """
    ìœ ëª©ë¯¼ ì¢…ëª©ì— ëŒ€í•´ AI ë¶„ì„ ì‹¤í–‰
    
    Args:
        study_date: ë¶„ì„í•  ë‚ ì§œ (ê¸°ë³¸: ì˜¤ëŠ˜)
        limit: ìµœëŒ€ ë¶„ì„ ê°œìˆ˜
    
    Returns:
        ë¶„ì„ ê²°ê³¼ í†µê³„
    """
    if study_date is None:
        study_date = date.today().isoformat()
    
    logger.info("=" * 60)
    logger.info(f"ğŸ¤– AI ë¶„ì„ ì‹œì‘: {study_date}")
    logger.info("=" * 60)
    
    stats = {
        'date': study_date,
        'total': 0,
        'analyzed': 0,
        'skipped': 0,
        'failed': 0,
        'errors': [],
    }
    
    try:
        candidate_repo = get_nomad_candidates_repository()
        news_repo = get_nomad_news_repository()
        
        # ì˜¤ëŠ˜ ì¢…ëª© ì¤‘ AI ë¶„ì„ ì—†ëŠ” ê²ƒ
        candidates = candidate_repo.get_by_date(study_date)
        candidates_to_analyze = [
            c for c in candidates 
            if not c.get('ai_summary')
        ]
        
        stats['total'] = len(candidates_to_analyze)
        logger.info(f"ë¶„ì„ ëŒ€ìƒ: {stats['total']}ê°œ (ì „ì²´ {len(candidates)}ê°œ ì¤‘ AI ë¶„ì„ ì—†ëŠ” ê²ƒ)")
        
        if stats['total'] == 0:
            logger.info("âœ… ëª¨ë“  ì¢…ëª©ì´ ì´ë¯¸ AI ë¶„ì„ ì™„ë£Œë¨")
            return stats
        
        # API í‚¤ í™•ì¸
        api_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
        if not api_key:
            logger.error("âŒ Gemini API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .envì— GEMINI_API_KEY ì¶”ê°€í•˜ì„¸ìš”.")
            stats['errors'].append("API í‚¤ ì—†ìŒ")
            return stats
        
        # ë¶„ì„ ì‹¤í–‰
        for i, candidate in enumerate(candidates_to_analyze[:limit]):
            stock_name = candidate['stock_name']
            stock_code = candidate['stock_code']
            
            logger.info(f"  [{i+1}/{min(stats['total'], limit)}] {stock_name} ({stock_code})")
            
            try:
                # ë‰´ìŠ¤ ì¡°íšŒ
                news_list = news_repo.get_by_candidate(study_date, stock_code)
                
                # AI ë¶„ì„
                result, error = generate_ai_analysis(candidate, news_list)
                
                if result:
                    # DB ì €ì¥
                    candidate_repo.update_ai_summary(
                        candidate['id'], 
                        json.dumps(result, ensure_ascii=False)
                    )
                    stats['analyzed'] += 1
                    
                    rec = result.get('recommendation', '-')
                    logger.info(f"    âœ… ì™„ë£Œ â†’ {rec}")
                else:
                    stats['failed'] += 1
                    stats['errors'].append(f"{stock_name}: {error}")
                    logger.warning(f"    âŒ ì‹¤íŒ¨: {error}")
                
                # API í˜¸ì¶œ ê°„ê²©
                time.sleep(API_DELAY)
                
            except Exception as e:
                stats['failed'] += 1
                stats['errors'].append(f"{stock_name}: {str(e)}")
                logger.error(f"    âŒ ì—ëŸ¬: {e}")
        
    except Exception as e:
        logger.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        stats['errors'].append(str(e))
    
    logger.info("=" * 60)
    logger.info(f"ğŸ¤– AI ë¶„ì„ ì™„ë£Œ: {stats['analyzed']}/{stats['total']} ì„±ê³µ")
    if stats['failed'] > 0:
        logger.warning(f"   ì‹¤íŒ¨: {stats['failed']}ê°œ")
    logger.info("=" * 60)
    
    return stats


def run_ai_analysis() -> Dict:
    """
    AI ë¶„ì„ ì‹¤í–‰ (ìŠ¤ì¼€ì¤„ëŸ¬ìš© - ì˜¤ëŠ˜ ë‚ ì§œë§Œ)
    """
    return analyze_candidates_with_ai(limit=50)


def analyze_all_pending(limit: int = 500) -> Dict:
    """
    AI ë¶„ì„ ì—†ëŠ” ëª¨ë“  ì¢…ëª© ë¶„ì„ (ë°±í•„ ë°ì´í„° í¬í•¨)
    
    Args:
        limit: ìµœëŒ€ ë¶„ì„ ê°œìˆ˜
    
    Returns:
        ë¶„ì„ ê²°ê³¼ í†µê³„
    """
    logger.info("=" * 60)
    logger.info("ğŸ¤– ì „ì²´ AI ë¶„ì„ ì‹œì‘ (ë°±í•„ ë°ì´í„° í¬í•¨)")
    logger.info("=" * 60)
    
    stats = {
        'total': 0,
        'analyzed': 0,
        'skipped': 0,
        'failed': 0,
        'errors': [],
    }
    
    try:
        candidate_repo = get_nomad_candidates_repository()
        news_repo = get_nomad_news_repository()
        
        # AI ë¶„ì„ ì—†ëŠ” ëª¨ë“  ì¢…ëª© ì¡°íšŒ
        with candidate_repo.db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT * FROM nomad_candidates 
                WHERE ai_summary IS NULL OR ai_summary = ''
                ORDER BY study_date DESC
                LIMIT ?
            """, (limit,))
            columns = [desc[0] for desc in cursor.description]
            candidates = [dict(zip(columns, row)) for row in cursor.fetchall()]
        
        stats['total'] = len(candidates)
        logger.info(f"ë¶„ì„ ëŒ€ìƒ: {stats['total']}ê°œ (AI ë¶„ì„ ì—†ëŠ” ì „ì²´ ì¢…ëª©)")
        
        if stats['total'] == 0:
            logger.info("âœ… ëª¨ë“  ì¢…ëª©ì´ ì´ë¯¸ AI ë¶„ì„ ì™„ë£Œë¨")
            return stats
        
        # API í‚¤ í™•ì¸
        api_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
        if not api_key:
            logger.error("âŒ Gemini API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .envì— GEMINI_API_KEY ì¶”ê°€í•˜ì„¸ìš”.")
            stats['errors'].append("API í‚¤ ì—†ìŒ")
            return stats
        
        # ë¶„ì„ ì‹¤í–‰
        for i, candidate in enumerate(candidates):
            stock_name = candidate['stock_name']
            stock_code = candidate['stock_code']
            study_date = candidate['study_date']
            
            logger.info(f"  [{i+1}/{stats['total']}] {study_date} {stock_name} ({stock_code})")
            
            try:
                # ë‰´ìŠ¤ ì¡°íšŒ
                news_list = news_repo.get_by_candidate(study_date, stock_code)
                
                # AI ë¶„ì„
                result, error = generate_ai_analysis(candidate, news_list)
                
                if result:
                    candidate_repo.update_ai_summary(
                        candidate['id'], 
                        json.dumps(result, ensure_ascii=False)
                    )
                    stats['analyzed'] += 1
                    time.sleep(0.5)  # API ì†ë„ ì œí•œ
                else:
                    stats['failed'] += 1
                    if error:
                        stats['errors'].append(f"{stock_name}: {error}")
                        
            except Exception as e:
                logger.error(f"    âŒ ì—ëŸ¬: {e}")
                stats['failed'] += 1
                stats['errors'].append(f"{stock_name}: {str(e)}")
    
    except Exception as e:
        logger.error(f"AI ë¶„ì„ ì‹¤íŒ¨: {e}")
        stats['errors'].append(str(e))
    
    logger.info("=" * 60)
    logger.info(f"ğŸ¤– ì „ì²´ AI ë¶„ì„ ì™„ë£Œ: {stats['analyzed']}/{stats['total']} ì„±ê³µ")
    if stats['failed'] > 0:
        logger.warning(f"   ì‹¤íŒ¨: {stats['failed']}ê°œ")
    logger.info("=" * 60)
    
    return stats


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    )
    
    from dotenv import load_dotenv
    load_dotenv()
    
    print("=" * 60)
    print("ğŸ¤– AI ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    result = run_ai_analysis()
    print(f"\nê²°ê³¼: {result}")
