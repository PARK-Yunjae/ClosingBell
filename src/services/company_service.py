"""
ê¸°ì—… ì •ë³´ ìˆ˜ì§‘ ì„œë¹„ìŠ¤ v6.5
===========================

v6.5: DART API ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½ (ë„¤ì´ë²„ í¬ë¡¤ë§ì€ fallback)

## ìˆ˜ì§‘ í•­ëª© (DART)
- ê¸°ì—…ê°œí™©: íšŒì‚¬ëª…, ëŒ€í‘œì, ì—…ì¢…ì½”ë“œ, ì„¤ë¦½ì¼
- ì¬ë¬´ìš”ì•½: ë§¤ì¶œì•¡, ì˜ì—…ì´ìµ, ìˆœì´ìµ, ìë³¸ì´ê³„
- ìœ„í—˜ê³µì‹œ: ì •ë¦¬ë§¤ë§¤, ìœ ìƒì¦ì ë“± ìë™ íƒì§€

## ê¸°ì¡´ ë„¤ì´ë²„ ìˆ˜ì§‘ í•­ëª© (fallbackìš©)

| í•­ëª© | ì†ŒìŠ¤ | íŒ¨í„´ |
|------|------|------|
| ì‹œê°€ì´ì•¡ | coinfo | id="_market_sum" |
| ì‹œê°€ì´ì•¡ìˆœìœ„ | coinfo | ì½”ìŠ¤í”¼ <em>13</em>ìœ„ |
| PER | coinfo | id="_per" |
| EPS | coinfo | id="_eps" |
| PBR | coinfo | id="_pbr" |
| BPS | coinfo | PBR ë‹¤ìŒ <em> |
| ì™¸êµ­ì¸ë³´ìœ ìœ¨ | coinfo | ì™¸êµ­ì¸ì†Œì§„ìœ¨ |
| íˆ¬ìì˜ê²¬ | coinfo | <em>4.00</em>ë§¤ìˆ˜ |
| ëª©í‘œì£¼ê°€ | coinfo | ëª©í‘œì£¼ê°€</th>...<em> |
| 52ì£¼ìµœê³ /ìµœì € | coinfo | 52ì£¼ìµœê³ ...<em> |
| ê¸°ì—…ê°œìš” | coinfo | <p>ë™ì‚¬ëŠ”... |
| ì—…ì¢… | main | ì—…ì¢…...<a> |
| ì‹œì¥ | main | kospi_link |

ì‚¬ìš©:
    python main.py --run-company-info
    
    ë˜ëŠ” ì½”ë“œì—ì„œ:
    from src.services.company_service import run_company_info_collection
    run_company_info_collection()
"""

import re
import time
import logging
import urllib.request
from pathlib import Path
from typing import Dict, Optional, Any
from html import unescape
from dataclasses import dataclass, field, asdict
from datetime import datetime
import pandas as pd

from src.infrastructure.repository import get_nomad_candidates_repository

logger = logging.getLogger(__name__)

# ìƒìˆ˜
API_DELAY = 0.3  # í¬ë¡¤ë§ ê°„ê²© (ì´ˆ)
BASE_URL = "https://finance.naver.com"
STOCK_MAPPING_PATH = Path(r"C:\Coding\data\stock_mapping.csv")

# ì¢…ëª© ë§¤í•‘ ìºì‹œ
_stock_mapping_cache: Optional[Dict[str, str]] = None

def get_sector_from_mapping(stock_code: str) -> Optional[str]:
    """stock_mapping.csvì—ì„œ ì—…ì¢… ì¡°íšŒ"""
    global _stock_mapping_cache
    
    if _stock_mapping_cache is None:
        try:
            if STOCK_MAPPING_PATH.exists():
                df = pd.read_csv(STOCK_MAPPING_PATH, encoding='utf-8-sig')
                df['code'] = df['code'].astype(str).str.zfill(6)
                _stock_mapping_cache = dict(zip(df['code'], df['sector']))
                logger.info(f"stock_mapping.csv ë¡œë“œ: {len(_stock_mapping_cache)}ê°œ ì¢…ëª©")
            else:
                _stock_mapping_cache = {}
                logger.warning(f"stock_mapping.csv ì—†ìŒ: {STOCK_MAPPING_PATH}")
        except Exception as e:
            logger.error(f"stock_mapping.csv ë¡œë“œ ì‹¤íŒ¨: {e}")
            _stock_mapping_cache = {}
    
    return _stock_mapping_cache.get(stock_code.zfill(6))

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
}


@dataclass
class CompanyInfo:
    """ê¸°ì—… ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    # ê¸°ë³¸
    market: Optional[str] = None  # KOSPI/KOSDAQ
    sector: Optional[str] = None  # ì—…ì¢…
    
    # ì‹œê°€ì´ì•¡
    market_cap: Optional[float] = None  # ì–µì›
    market_cap_rank: Optional[int] = None  # ìˆœìœ„
    
    # ë°¸ë¥˜ì—ì´ì…˜
    per: Optional[float] = None
    eps: Optional[float] = None
    pbr: Optional[float] = None
    bps: Optional[float] = None
    roe: Optional[float] = None
    
    # ì»¨ì„¼ì„œìŠ¤
    consensus_per: Optional[float] = None
    consensus_eps: Optional[float] = None
    
    # ì™¸êµ­ì¸
    foreign_rate: Optional[float] = None  # ë³´ìœ ìœ¨ %
    foreign_shares: Optional[int] = None  # ë³´ìœ ì£¼ìˆ˜
    
    # íˆ¬ìì˜ê²¬
    analyst_opinion: Optional[float] = None  # 1~5
    analyst_recommend: Optional[str] = None  # ë§¤ìˆ˜/ë§¤ë„/ì¤‘ë¦½
    target_price: Optional[int] = None  # ëª©í‘œì£¼ê°€
    
    # 52ì£¼
    high_52w: Optional[int] = None
    low_52w: Optional[int] = None
    
    # ë°°ë‹¹
    dividend_yield: Optional[float] = None
    
    # ê¸°ì—… ìƒì„¸
    business_summary: Optional[str] = None
    establishment_date: Optional[str] = None
    ceo_name: Optional[str] = None
    revenue: Optional[float] = None
    operating_profit: Optional[float] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (None ì œì™¸)"""
        return {k: v for k, v in asdict(self).items() if v is not None}


def clean_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì •ë¦¬"""
    if not text:
        return ""
    text = re.sub(r'<[^>]+>', '', text)
    text = unescape(text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def parse_number(text: str) -> Optional[float]:
    """ìˆ«ì íŒŒì‹± (ì‰¼í‘œ, ê³µë°± ì œê±°)"""
    if not text:
        return None
    try:
        clean = text.replace(',', '').replace(' ', '').replace('\t', '').replace('\n', '').replace('\r', '').strip()
        return float(clean)
    except:
        return None


def parse_int(text: str) -> Optional[int]:
    """ì •ìˆ˜ íŒŒì‹±"""
    num = parse_number(text)
    return int(num) if num is not None else None


def parse_market_cap(text: str) -> Optional[float]:
    """ì‹œê°€ì´ì•¡ íŒŒì‹± (ì¡°/ì–µ ë‹¨ìœ„ ì²˜ë¦¬)
    
    ì˜ˆ: "50ì¡° 3,131" â†’ 503131 (ì–µì›)
    """
    if not text:
        return None
    
    text = text.strip()
    
    if 'ì¡°' in text:
        parts = text.split('ì¡°')
        trillion = parse_number(parts[0]) or 0
        billion = parse_number(parts[1]) if len(parts) > 1 else 0
        return trillion * 10000 + (billion or 0)
    else:
        return parse_number(text)


def fetch_html(url: str, encoding: str = 'euc-kr') -> Optional[str]:
    """HTML ê°€ì ¸ì˜¤ê¸°"""
    try:
        request = urllib.request.Request(url, headers=HEADERS)
        response = urllib.request.urlopen(request, timeout=15)
        return response.read().decode(encoding, errors='ignore')
    except Exception as e:
        logger.warning(f"Fetch ì‹¤íŒ¨: {url} - {e}")
        return None


def parse_coinfo_page(html: str) -> CompanyInfo:
    """
    coinfo.naver í˜ì´ì§€ íŒŒì‹± (ë©”ì¸ ë°ì´í„° ì†ŒìŠ¤)
    
    ê²€ì¦ëœ íŒ¨í„´ (2026.01.20):
    - ì‹œê°€ì´ì•¡: id="_market_sum" â†’ "50ì¡° 3,131"
    - PER: id="_per" â†’ "24.21"
    - EPS: id="_eps" â†’ "12,227"
    - PBR: id="_pbr" â†’ "1.17"
    - ì™¸êµ­ì¸ì†Œì§„ìœ¨: "29.61%"
    - íˆ¬ìì˜ê²¬: <em>4.00</em>ë§¤ìˆ˜
    - ëª©í‘œì£¼ê°€: "298,929"
    - 52ì£¼ìµœê³ /ìµœì €: "307,500" / "108,100"
    """
    info = CompanyInfo()
    
    # ===== ì‹œê°€ì´ì•¡ =====
    cap_match = re.search(r'id="_market_sum">([^<]+)</em>ì–µì›', html, re.DOTALL)
    if cap_match:
        info.market_cap = parse_market_cap(cap_match.group(1))
    
    # ì‹œê°€ì´ì•¡ ìˆœìœ„
    rank_match = re.search(r'ì½”ìŠ¤í”¼\s*<em>(\d+)</em>ìœ„', html)
    if not rank_match:
        rank_match = re.search(r'ì½”ìŠ¤ë‹¥\s*<em>(\d+)</em>ìœ„', html)
    if rank_match:
        info.market_cap_rank = int(rank_match.group(1))
    
    # ===== ë°¸ë¥˜ì—ì´ì…˜ (ID ê¸°ë°˜) =====
    # PER
    per_match = re.search(r'id="_per">([0-9,.]+)</em>', html)
    if per_match:
        val = parse_number(per_match.group(1))
        if val and 0 < val < 500:
            info.per = val
    
    # EPS
    eps_match = re.search(r'id="_eps">([0-9,.-]+)</em>', html)
    if eps_match:
        info.eps = parse_number(eps_match.group(1))
    
    # ì¶”ì • PER (ì»¨ì„¼ì„œìŠ¤)
    cns_per_match = re.search(r'id="_cns_per">([0-9,.]+)</em>', html)
    if cns_per_match:
        val = parse_number(cns_per_match.group(1))
        if val and 0 < val < 500:
            info.consensus_per = val
    
    # ì¶”ì • EPS (ì»¨ì„¼ì„œìŠ¤)
    cns_eps_match = re.search(r'id="_cns_eps">([0-9,.-]+)</em>', html)
    if cns_eps_match:
        info.consensus_eps = parse_number(cns_eps_match.group(1))
    
    # PBR
    pbr_match = re.search(r'id="_pbr">([0-9,.]+)</em>', html)
    if pbr_match:
        val = parse_number(pbr_match.group(1))
        if val and 0 < val < 50:
            info.pbr = val
    
    # BPS (PBR í–‰ì˜ ë‘ ë²ˆì§¸ ê°’)
    bps_match = re.search(r'PBR</a></th>.*?<em[^>]*>[^<]+</em>.*?<em>([0-9,]+)</em>ì›', html, re.DOTALL)
    if bps_match:
        info.bps = parse_number(bps_match.group(1))
    
    # ===== ì™¸êµ­ì¸ =====
    foreign_match = re.search(r'ì™¸êµ­ì¸ì†Œì§„ìœ¨.*?<em>([0-9,.]+)%</em>', html, re.DOTALL)
    if foreign_match:
        info.foreign_rate = parse_number(foreign_match.group(1))
    
    # ì™¸êµ­ì¸ ë³´ìœ ì£¼ìˆ˜
    foreign_shares_match = re.search(r'ì™¸êµ­ì¸ë³´ìœ ì£¼ì‹ìˆ˜.*?<em>([0-9,]+)</em>', html, re.DOTALL)
    if foreign_shares_match:
        info.foreign_shares = parse_int(foreign_shares_match.group(1))
    
    # ===== íˆ¬ìì˜ê²¬ =====
    opinion_match = re.search(r'íˆ¬ìì˜ê²¬.*?<em>([0-9,.]+)</em>\s*(ë§¤ìˆ˜|ë§¤ë„|ì¤‘ë¦½|Buy|Sell|Hold)', html, re.DOTALL)
    if opinion_match:
        info.analyst_opinion = parse_number(opinion_match.group(1))
        recommend = opinion_match.group(2)
        if recommend in ['Buy', 'ë§¤ìˆ˜']:
            info.analyst_recommend = 'ë§¤ìˆ˜'
        elif recommend in ['Sell', 'ë§¤ë„']:
            info.analyst_recommend = 'ë§¤ë„'
        else:
            info.analyst_recommend = 'ì¤‘ë¦½'
    
    # ëª©í‘œì£¼ê°€
    target_match = re.search(r'ëª©í‘œì£¼ê°€</th>.*?<em>([0-9,]+)</em>', html, re.DOTALL)
    if target_match:
        info.target_price = parse_int(target_match.group(1))
    
    # ===== 52ì£¼ ìµœê³ /ìµœì € =====
    high_low_match = re.search(r'52ì£¼ìµœê³ .*?<em>([0-9,]+)</em>.*?52ì£¼ìµœì €.*?<em>([0-9,]+)</em>', html, re.DOTALL)
    if high_low_match:
        info.high_52w = parse_int(high_low_match.group(1))
        info.low_52w = parse_int(high_low_match.group(2))
    else:
        # ëŒ€ì•ˆ íŒ¨í„´
        high_match = re.search(r'ìµœê³ \s*<em>([0-9,]+)</em>', html)
        low_match = re.search(r'ìµœì €\s*<em>([0-9,]+)</em>', html)
        if high_match:
            info.high_52w = parse_int(high_match.group(1))
        if low_match:
            info.low_52w = parse_int(low_match.group(1))
    
    # ===== ë°°ë‹¹ìˆ˜ìµë¥  =====
    div_match = re.search(r'ë°°ë‹¹ìˆ˜ìµë¥ .*?<em>([0-9,.]+)%</em>', html, re.DOTALL)
    if div_match:
        info.dividend_yield = parse_number(div_match.group(1))
    
    # ===== ê¸°ì—…ê°œìš” =====
    summary_match = re.search(r'<p>(ë™ì‚¬[^<]{10,500})</p>', html)
    if summary_match:
        info.business_summary = clean_text(summary_match.group(1))[:500]
    
    # ===== ëŒ€í‘œì/ì„¤ë¦½ì¼ =====
    ceo_match = re.search(r'ëŒ€í‘œìëª….*?<td[^>]*>([^<]+)</td>', html, re.DOTALL)
    if ceo_match:
        info.ceo_name = clean_text(ceo_match.group(1))
    
    est_match = re.search(r'ì„¤ë¦½ì¼.*?<td[^>]*>([^<]+)</td>', html, re.DOTALL)
    if est_match:
        info.establishment_date = clean_text(est_match.group(1))
    
    return info


def parse_main_page(html: str, info: CompanyInfo) -> CompanyInfo:
    """
    main.naver í˜ì´ì§€ì—ì„œ ì¶”ê°€ ì •ë³´ íŒŒì‹±
    
    - ì‹œì¥ êµ¬ë¶„ (KOSPI/KOSDAQ)
    - ì—…ì¢…
    - ROE
    """
    # ì‹œì¥ êµ¬ë¶„
    if 'kospi_link' in html or 'class="kospi"' in html.lower():
        info.market = 'KOSPI'
    elif 'kosdaq_link' in html or 'class="kosdaq"' in html.lower():
        info.market = 'KOSDAQ'
    
    # ì—…ì¢…
    sector_match = re.search(r'ì—…ì¢…[^<]*<a[^>]*>([^<]+)</a>', html)
    if not sector_match:
        sector_match = re.search(r'<em class="t_nm">([^<]+)</em>', html)
    if sector_match:
        sector_value = clean_text(sector_match.group(1))
        if sector_value and not sector_value.replace(',', '').replace('.', '').isdigit():
            info.sector = sector_value
    
    # ROE (main í˜ì´ì§€ì—ì„œ)
    roe_match = re.search(r'ROE.*?<em>([0-9,.-]+)</em>', html, re.DOTALL)
    if roe_match:
        val = parse_number(roe_match.group(1))
        if val and abs(val) < 200:
            info.roe = val
    
    # ë§¤ì¶œì•¡
    revenue_match = re.search(r'ë§¤ì¶œì•¡.*?([0-9,]+)ì–µ', html, re.DOTALL)
    if revenue_match:
        info.revenue = parse_number(revenue_match.group(1))
    
    # ì˜ì—…ì´ìµ
    profit_match = re.search(r'ì˜ì—…ì´ìµ.*?([0-9,.-]+)ì–µ', html, re.DOTALL)
    if profit_match:
        info.operating_profit = parse_number(profit_match.group(1))
    
    return info


def fetch_naver_finance(stock_code: str) -> Dict[str, Any]:
    """
    ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ê¸°ì—… ì •ë³´ ìˆ˜ì§‘ (í†µí•©)
    
    Args:
        stock_code: ì¢…ëª©ì½”ë“œ (6ìë¦¬)
        
    Returns:
        ê¸°ì—… ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    info = CompanyInfo()
    
    try:
        # 1. coinfo í˜ì´ì§€ (ë©”ì¸ ë°ì´í„° ì†ŒìŠ¤)
        coinfo_url = f"{BASE_URL}/item/coinfo.naver?code={stock_code}"
        coinfo_html = fetch_html(coinfo_url)
        
        if coinfo_html:
            info = parse_coinfo_page(coinfo_html)
            logger.info(f"[{stock_code}] coinfo íŒŒì‹±: ì‹œì´={info.market_cap}, PER={info.per}, ì™¸êµ­ì¸={info.foreign_rate}%")
        
        time.sleep(API_DELAY)
        
        # 2. main í˜ì´ì§€ (ì¶”ê°€ ì •ë³´)
        main_url = f"{BASE_URL}/item/main.naver?code={stock_code}"
        main_html = fetch_html(main_url)
        
        if main_html:
            info = parse_main_page(main_html, info)
        
        # 3. ì—…ì¢…: stock_mapping.csv ìš°ì„  ì‚¬ìš© (ë” ì‹ ë¢°ì„± ìˆìŒ)
        mapping_sector = get_sector_from_mapping(stock_code)
        if mapping_sector:
            info.sector = mapping_sector
            logger.debug(f"[{stock_code}] ì—…ì¢… from stock_mapping: {mapping_sector}")
        
        logger.info(f"[{stock_code}] ìµœì¢…: ì‹œì¥={info.market}, ì—…ì¢…={info.sector}")
        
        return info.to_dict()
        
    except Exception as e:
        logger.error(f"ë„¤ì´ë²„ ê¸ˆìœµ í¬ë¡¤ë§ ì‹¤íŒ¨ [{stock_code}]: {e}")
        return info.to_dict()


def collect_company_info_for_candidate(candidate: Dict) -> bool:
    """
    ë‹¨ì¼ ì¢…ëª©ì˜ ê¸°ì—… ì •ë³´ ìˆ˜ì§‘
    
    Args:
        candidate: nomad_candidates ë ˆì½”ë“œ
        
    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    stock_code = candidate['stock_code']
    stock_name = candidate['stock_name']
    candidate_id = candidate['id']
    
    logger.info(f"  ğŸ¢ {stock_name} ({stock_code}) ê¸°ì—…ì •ë³´ ìˆ˜ì§‘...")
    
    # ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ì •ë³´ ìˆ˜ì§‘
    info = fetch_naver_finance(stock_code)
    
    if not any(info.values()):
        logger.warning(f"  âš ï¸ {stock_name}: ê¸°ì—…ì •ë³´ ì—†ìŒ")
        return False
    
    # DB ì—…ë°ì´íŠ¸
    try:
        repo = get_nomad_candidates_repository()
        repo.update_company_info_by_id(candidate_id, info)
        
        # ìˆ˜ì§‘ëœ í•­ëª© ì¹´ìš´íŠ¸
        collected = sum(1 for v in info.values() if v is not None)
        logger.info(f"  âœ… {stock_name}: {collected}ê°œ í•­ëª© ì €ì¥")
        
        return True
        
    except Exception as e:
        logger.error(f"  ê¸°ì—…ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def collect_company_info_for_candidates(limit: int = 600) -> Dict:
    """
    ìœ ëª©ë¯¼ í›„ë³´ë“¤ì˜ ê¸°ì—… ì •ë³´ ìˆ˜ì§‘
    
    Args:
        limit: ìµœëŒ€ ì¢…ëª© ìˆ˜
        
    Returns:
        ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
    """
    logger.info("=" * 60)
    logger.info("ğŸ¢ ê¸°ì—… ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
    logger.info("=" * 60)
    
    repo = get_nomad_candidates_repository()
    
    # ê¸°ì—…ì •ë³´ ë¯¸ìˆ˜ì§‘ í›„ë³´ ì¡°íšŒ
    candidates = repo.get_uncollected_company_info(limit=limit)
    
    if not candidates:
        logger.info("ğŸ“­ ê¸°ì—…ì •ë³´ ìˆ˜ì§‘í•  í›„ë³´ ì—†ìŒ")
        print("\nğŸ“­ ê¸°ì—…ì •ë³´ ìˆ˜ì§‘í•  í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {'total': 0, 'success': 0}
    
    logger.info(f"ğŸ“‹ ê¸°ì—…ì •ë³´ ìˆ˜ì§‘ ëŒ€ìƒ: {len(candidates)}ê°œ ì¢…ëª©")
    print(f"\nğŸ“‹ ê¸°ì—…ì •ë³´ ìˆ˜ì§‘ ëŒ€ìƒ: {len(candidates)}ê°œ ì¢…ëª©\n")
    
    stats = {'total': len(candidates), 'success': 0}
    
    for i, candidate in enumerate(candidates[:limit]):
        print(f"[{i+1}/{min(len(candidates), limit)}] {candidate['stock_name']} ({candidate['stock_code']})")
        
        if collect_company_info_for_candidate(candidate):
            stats['success'] += 1
        
        time.sleep(API_DELAY)
    
    logger.info("=" * 60)
    logger.info(f"ğŸ¢ ê¸°ì—…ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {stats['success']}/{stats['total']}")
    logger.info("=" * 60)
    
    return stats


def run_company_info_collection(limit: int = 100) -> Dict:
    """
    ê¸°ì—… ì •ë³´ ìˆ˜ì§‘ ì‹¤í–‰ (ìŠ¤ì¼€ì¤„ëŸ¬ìš©)
    
    v6.5: DART ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½ (ë„¤ì´ë²„ í¬ë¡¤ë§ ëŒ€ì²´)
    """
    return collect_company_info_with_dart(limit=limit)


def collect_company_info_with_dart(limit: int = 100) -> Dict:
    """
    v6.5: DART API ê¸°ë°˜ ê¸°ì—…ì •ë³´ ìˆ˜ì§‘
    
    Args:
        limit: ìµœëŒ€ ì¢…ëª© ìˆ˜
        
    Returns:
        ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
    """
    logger.info("=" * 60)
    logger.info("ğŸ¢ ê¸°ì—… ì •ë³´ ìˆ˜ì§‘ ì‹œì‘ (DART)")
    logger.info("=" * 60)
    
    try:
        from src.services.dart_service import get_dart_service
        from src.infrastructure.repository import get_company_profile_repository
        
        dart = get_dart_service()
        profile_repo = get_company_profile_repository()
        
    except ImportError as e:
        logger.warning(f"DART ì„œë¹„ìŠ¤ ë¯¸ì„¤ì¹˜: {e}")
        # Fallback: ê¸°ì¡´ ë„¤ì´ë²„ ë°©ì‹
        return collect_company_info_for_candidates(limit=limit)
    
    repo = get_nomad_candidates_repository()
    
    # ê¸°ì—…ì •ë³´ ë¯¸ìˆ˜ì§‘ í›„ë³´ ì¡°íšŒ
    candidates = repo.get_uncollected_company_info(limit=limit)
    
    if not candidates:
        logger.info("ğŸ“­ ê¸°ì—…ì •ë³´ ìˆ˜ì§‘í•  í›„ë³´ ì—†ìŒ")
        return {'total': 0, 'success': 0, 'source': 'DART'}
    
    logger.info(f"ğŸ“‹ DART ê¸°ì—…ì •ë³´ ìˆ˜ì§‘ ëŒ€ìƒ: {len(candidates)}ê°œ ì¢…ëª©")
    
    stats = {'total': len(candidates), 'success': 0, 'source': 'DART'}
    
    for i, candidate in enumerate(candidates[:limit]):
        stock_code = candidate['stock_code']
        stock_name = candidate['stock_name']
        
        try:
            # DART ì „ì²´ í”„ë¡œí•„ ì¡°íšŒ (ìºì‹œ ì €ì¥ í¬í•¨)
            profile = dart.get_full_company_profile(
                stock_code, 
                stock_name,
                include_risk=True,
                cache_to_db=True,
            )
            
            if profile.get('success'):
                # nomad_candidates í…Œì´ë¸”ì— ê¸°ì—…ì •ë³´ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸
                basic = profile.get('basic') or {}
                financial = profile.get('financial') or {}
                
                # v6.5.1: ë„¤ì´ë²„ì—ì„œ PER/PBR/ROE ë³´ì¶© ìˆ˜ì§‘
                per, pbr, roe = None, None, None
                try:
                    naver_info = fetch_naver_finance(stock_code)
                    per = naver_info.per
                    pbr = naver_info.pbr
                    roe = naver_info.roe
                except Exception as e:
                    logger.debug(f"ë„¤ì´ë²„ PER/PBR/ROE ìˆ˜ì§‘ ì‹¤íŒ¨ ({stock_code}): {e}")
                
                repo.update_company_info_by_id(
                    candidate_id=candidate.get('id'),
                    info={
                        'market': basic.get('corp_cls', ''),
                        'sector': basic.get('induty_code', ''),
                        'ceo_name': basic.get('ceo_nm', ''),  # ceo â†’ ceo_name
                        'revenue': financial.get('revenue'),
                        'operating_profit': financial.get('operating_profit'),
                        'net_income': financial.get('net_income'),
                        # v6.5.1: PER/PBR/ROE ì¶”ê°€
                        'per': per,
                        'pbr': pbr,
                        'roe': roe,
                        'data_source': 'DART+NAVER',
                    }
                )
                stats['success'] += 1
                logger.debug(f"âœ… {stock_name} DART ìˆ˜ì§‘ ì™„ë£Œ")
            else:
                logger.debug(f"âš ï¸ {stock_name} DART ì •ë³´ ì—†ìŒ")
                
        except Exception as e:
            logger.warning(f"âŒ {stock_name} DART ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # API í˜¸ì¶œ ê°„ê²© (DARTëŠ” ë¹ ë¥´ì§€ë§Œ ì˜ˆì˜ìƒ)
        time.sleep(0.2)
    
    logger.info("=" * 60)
    logger.info(f"ğŸ¢ DART ê¸°ì—…ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {stats['success']}/{stats['total']}")
    logger.info("=" * 60)
    
    return stats


def run_company_info_collection_legacy() -> Dict:
    """
    ê¸°ì¡´ ë„¤ì´ë²„ í¬ë¡¤ë§ ë°©ì‹ (fallbackìš©)
    """
    return collect_company_info_for_candidates(limit=600)


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    )
    
    print("=" * 60)
    print("ğŸ¢ ê¸°ì—… ì •ë³´ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸: ì‚¼ì„±ì „ì
    test_codes = ["005930", "028260", "035720"]
    
    for code in test_codes:
        print(f"\n--- {code} ---")
        info = fetch_naver_finance(code)
        for k, v in sorted(info.items()):
            if v is not None:
                print(f"  {k}: {v}")
        time.sleep(1)